"","index","category","title","body","sub","sub_post_id","n_comments"
"1",0,"datascience","Weekly Entering & Transitioning Thread | 15 Mar 2020 - 22 Mar 2020","_Bleep Bloop_. Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](https://www.reddit.com/r/datascience/wiki/resources) pages on our wiki. You can also search for [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).

---

I am a bot created by the r/datascience moderators. I'm open source! You can review my [source code on GitHub](https://github.com/vogt4nick/datascience-bot).","datascience",0,2
"2",1,"datascience","What are some good Data Science master degrees in Europe","Basically, as the time says, however which degrees whose tution fees are less than 5000€/Year. I recently have been checking universities in Germany but I am curious what do you guys think


Abit of a background about me, I am 22 year Computer engineering student from Egypt, I will finish my Bachelor's degree this june, but since Data Science is not as huge as it is in the US and Europe. I thought I would get a masters degree, and save me the effort of trying to apply to jobs abroad, plus have a much stronger academic background in data science.","datascience",1,32
"3",2,"datascience","From economics to data science","So I'm about to graduate with a bachelor's degree in economics, but the last fall I developed a huge interest in data science (mainly because of econometrics) so as my classes are canceled for 2 weeks + 2 weeks of online lectures I want to dive deeper into the field of data science.

I'm in processes of creating my curriculum which I plan to follow till the end of the summer and please help me with suggestions and feedback.

**Video Courses:**

* Udemy ML A-Z (\~ 1.5 hours per day)

**Math with Textbook:**

* Linear Algebra - Youtube videos + linear algebra done right textbook (I've never taken it at my uni as it wasn't required by my major)  \~ 30 minutes per day
* ITSL textbook - (I'm comfortable with general linear models and time series which was covered through my econometrics courses) \~ 1 hour per day

**General** P**ractice:**

* Dataquest Data Scientists track (doing 1-2 missions per day) \~ 1-1.5 hours per day

What you would suggest adding/removing/replacing?","datascience",2,35
"4",3,"datascience","Kaggle M5 forecasting competition evaluation","I made a video on how to write the WRMSSE evaluation metrics into code, using a naive forecast as example. Here’s the link to it if anyone’s interested: https://youtu.be/7FwITPrBvLI

And this is the Notebook where the code is stored: https://www.kaggle.com/qcw171717/naive-baseline/

My understanding is that we are only given the level 12 series and were to infer all the information regarding higher level series. If anything in the video felt wrong to you please let me know, that would really help.","datascience",3,1
"5",4,"datascience","Modelling discount effect on sales volume","Most of my data science experience has been in the realms of NLP, recommender systems, and network analysis. I'm quite unfamiliar with using DS techniques directly for business goals; so I volunteered for a project to help me master some fundamentals. 

I have sales data for 5 products, the discount %, and the dates effective. Assume that there are many, many rows covering every product, the month effective, and the discount percentage.

For example:

    [
    (product_1, 15%, April 2019),
    (product_2, 10%, June 2019),
    (product_3, 20%, October 2019)
    ]

What are some strategies for modelling the effectiveness of discounts on products?

Because there are so many variables, I do not think that A/B testing is appropriate here. I've considered marginalizing date out, and building one  linear regression model for each product where discount is the independent var and sales volume is the dependent variable. 

However, I feel that this question is deceptively easy; perhaps it's actually an optimization problem where we're estimating the best discount price to maximize sales. For example, a $100 product might sell 4 units with 20% off and 5 units with 25% off. But without knowing the cost per item to the business, this isn't a perfect approach either. 

Thoughts?","datascience",4,0
"6",5,"datascience","COVID19 and water usage","First off, my many apologies if this is not the correct sub reddit in which to post this. I'm new at reddit. have mercy.

I was thinking that, with all the warnings due to COVID19 to wash hands at least 20 seconds, assuming a significant number of people above the norm are following that advice, there has to be an excessive amount of water usage than normal. Perhaps there are already stats on it? (My advice is to wet hands, turn water off, soap up, lather, then rinse.)

Anyway...any thoughts?","datascience",5,11
"7",6,"datascience","Need some advice for my first data science internship","My first ever data science internship starts on may this year at a big company.

I'm a CS-freshman and I'm familiar with statistics and probability theory and I've taken calculus I and II.

I have my own data science project that I created with python. I have some experience with cleaning and munging one dataset from Kaggle. I'm only familiar with linear and logistic regression when it comes to machine learning.

I have no practical experience with SQL and I've never performed data scraping.

What are your advice on how to start preparing for my internship as data scientist trainee? Should I take some MOOC's or read some related books? If so, what are the most essential for this kind of a job?","datascience",6,1
"8",7,"datascience","What do you think about Knime?","I am a Data Science student and, for one of my courses, my professor decided to focus the exam around Knime (a not too simple ML project). For my brief, albeit intense, experience, I have loathed it: it is not particularly efficient, crashes way too many times and lacks some functionality, for which I have to resort to use Python nodes. 

But maybe I am wrong and, coming from a purely Python and C++ background, I cannot see the benefits. If some of you, more experiences than me, could share their experience, maybe I could reevaluate my views. Cheers.","datascience",7,2
"9",8,"datascience","Sharing a Data Scientist Interview Case Study","","datascience",8,0
"10",82,"datascience","It’s never too early","","datascience",82,55
"11",99,"datascience","Resources for learning about Data Management/Governance? DMBOK?","Hi,

I'm changing industry to a Data Management/Governance role with no prior experience in MDM or DG

Ive been looking at resources online, books, podcasts etc. To see what I can learn before I start my new role. 

Ive stumbled across the DAMA-DMBOK book, and was wondering if anybody had read it and would they recommend it? I see it referred to as the  ""bible"" for DG

Or are there other things that I should be looking at?

Apologies if this is the wrong subreddit & thanks for your time!","datascience",99,4
"12",100,"DataScienceJobs","[Hiring] Machine Learning Engineer in Zug, Zug, Switzerland","","datasciencejobs",0,0
"13",9,"datascience","Open COVID-19 Dataset","I was frustrated with the maintenance issues in the dataset maintained by [Johns Hopkins University](https://github.com/CSSEGISandData/COVID-19) so I created an alternative crowd-sourced dataset here: https://github.com/open-covid-19/data

The data is committed directly to the repo in time-series format as a CSV file, then it gets aggregated and pushed automatically in CSV and JSON formats.

If anyone knows of any better datasets, please point them out! worldometers.info appears to have pretty good data but I can't find how to get it for my own analysis.

Edit: the dataset has changed a bit since I first posted this, now I just take the ECDC data from [their portal](https://www.ecdc.europa.eu/en/publications-data/download-todays-data-geographic-distribution-covid-19-cases-worldwide), aggregate it, and add country-level coordinates for each datapoint.

Edit 2: if you want to play with the data, you can load the sample Notebooks directly from Google Colab here: https://colab.research.google.com/github/open-covid-19/data/

Edit 3: I have renamed the dataset from ""aggregate.csv"" / ""aggregate.json"" to ""world.csv"" / ""world.json"". Sorry for the breaking change, I will try not to make any other breaking changes moving forward.","datascience",9,77
"14",10,"datascience","Is there a website like leetcode but for data scientist?","Hi as you all know leetcode is a website for software engineers where they have interview questions from Fang and can practice their skills. Is there a similar website for data scientist","datascience",10,10
"15",11,"datascience","which field in data science has the most scope and is highly paid?","","datascience",11,5
"16",12,"datascience","Question about ARIMA and VAR modelling","Dear readers,

I'm currently in my last year in Computer science, for a last project we must apply an ARIMA and a VAR model on our received data.

We have 21 data points for 200+ companies with 3 variables of intrest, my question was is it even possible to make such models? 

The goal of the model is to do forecasting. The only examples I have found about these models applied is with simple time data (which would be good for us, if we only had one company and not 200).

Sorry if it's abit vague","datascience",12,4
"17",13,"datascience","Need a dataset for a research topic. [Ideas Request]","I have a project for my MS in Data Analytics and I cant come up with a topic for the life of me.  Biggest kicker is it cant be too massive because I really only have a month to work on this, which in reality is probably 40 hours.  Im hoping for a simple enough multiple linear regression, random forest, or logistic regression. Could also be anova type analysis.  Could be anything really I just dont want to go into anything too fancy that will take 80+ hours.

I have to be able to come up with some business use case for this research, but I can probably come up with that for anything.  Ultimately it just has to be useful.

I wanted to analyze gender pay gap... but cant find find anything with # of children or number of years in the workforce or really anything significant to work off of on an individual basis.

Then I wanted to do child abuse, but the datasets are insane.. like 10000 fields insane... and you are aupposed to use fancy weights and software because of the study design.  So thats out.

Other topics that arent allowed are employee attrition, customer churn, and most banking/credit topics.  

Thanks!","datascience",13,3
"18",14,"datascience","Is there something like Project Euler but for machine learning specifically?","Hello all, I've really enjoyed solving the problems on https://projecteuler.net/ recently for personal pleasure and to learn more about mathematics/algorithms. 

For those unfamiliar with Project Euler it has many different mathematical problems many of which are unsolvable by brute force with a programming language. It forces you to think about things in the most efficient way possible and find solutions which are not obvious at first. After you solve the problem you can view a forum thread for that specific problem in which other people post their code for their solutions. It's a lot of fun seeing how your algorithm compares to others and learning ways which your algorithm can be improved. 

I was just wondering if something similar to this exists for machine learning specifically? I'm hoping to try out some different machine learning models in a non-competitive relaxed environment and also have ability to see how others solved the same problem. It would also be great if my progress was tracked and there are achievements (Just like Project Euler!).","datascience",14,20
"19",15,"datascience","Is it a bad idea to try to predict the stock market with linear regression?"," Reasons being the underlying theoretical function that generates the stock price is constantly changing due to human behavior so your model will only be accurate for a short amount of time, unlike the relation of height vs age where the fluctuation is limited by biological restrictions.","datascience",15,20
"20",16,"datascience","r/LearnCybersecurity (New Subreddit)","","datascience",16,0
"21",17,"datascience","Identifying Bot Commenters on Reddit using Benford's Law","","datascience",17,3
"22",18,"datascience","Are there laws like the three laws of robotics to help Data-Scientists govern their behaviour?","I realise the topic is complex and can easily lead to (over) simplification. But something like:

First law: Information about people shall not be used to harm individuals or groups. Neither through active use, nor through inactivity. 

Second law: Information about people shall not be stored without them being aware of it? 

Third law: Information about people shall not be transferred without them being aware of it?","datascience",18,3
"23",19,"datascience","Thinkpad T430 vs X1 Carbon 7"," 

Thoughts on:

Thinkpad T430: i7-3840QM 4 cores, 16gb ram, nvs5400m, 1080p AND X1 Carbon 7: i7-10710U 6 cores, 16gb ram, 1080p ?

I will be using the laptop for prototyping ML and Data Analysis using Python and PowerBi.

Thank you","datascience",19,7
"24",20,"datascience","How do you create your own Data Science blog","I’ve wanted to create my own blog for some time. I intend to create posts about what I’m currently busy in Data Science, as algorithms, datasets, etc.

The thing is that I’m pretty good when it’s come to programming and algorithms but I have no clue how to set up a blog. Most websites out there just explain how to do a « normal » blog but I’d like to know if there exists a way to easily create a blog where I can add codes, dynamic images, codes again, etc.

What kind of blog do you use for your Data Science activities?","datascience",20,3
"25",94,"datascience","Does anyone have the data for the average age of deaths from the recent outbreak?","(The other flairs would not work)

I see all types of data but not this (I dont need any rate of anything just this data) I appreciate your help if you could.

Im referring to Come Open Virus Identify Data nine teen 

(I asked the same question in askreddit but it was immediately downvote out of sight for reason I dont understand so im hoping not saying he who should not be name will give me better chance)

Thank you.","datascience",94,2
"26",101,"DataScienceJobs","[Hiring] Data Scientist/Senior Data Scientist – Defence & Security in London, United Kingdom","","datasciencejobs",1,0
"27",21,"datascience","Data science in Recessionary periods","Some professions in some sectors do OK during recessionary periods. 

- For example if you're an engineer working for a public utility company delivering water and power (because people always need water and electricity). 

- People in healthcare industries also do OK (people always get sick). 

- If you work for a bank, as long as you're front office (revenue generating) and not middle office or back office (cost centers), your jobs will be save.

**What about data scientists?**

We know the recession is coming and it will be pretty bad. Central banks have run out of ammo since interest rates are so low. The only cheap tricks they have is doing QE's so we don't know how long this recession will last. Learning from Japan, it's highly possible we will go bad for a really long time. 

Since data science as a profession is a new thing and since most of the time data scientists is non-revenue generating, what do you guys think will happen in this upcoming recession/depression?

What are your takes on the following professions in different industries:

- data scientists (R&D)

- data engineers

- data analysts (aka: data scientists type A, or FAANG type data scientists)

- BI

- machine learning engineers

I can start: 

If you're any of the above within healthcare, you will surely be OK (data scientists have worked in healthcare sectors for a long time, and they're called statisticians). If you're in retail, perhaps you better have enough emergency funds.

**Edit:** I'd like to take the discussion a step further. An organization will keep you around as long as your value is greater than your costs. 

So my next question is:**What would you need in terms of skills, knowledge, ability, etc so that your value is higher than your costs (so that your organization will keep you)?**","datascience",21,21
"28",22,"datascience","Creating a discord channel for those interested in becoming a data analyst. Will do weekly data visualisation projects with peer to peer code reviews.","","datascience",22,92
"29",23,"datascience","What is the recommended partition size for linux?","Hi, I want to set up a Ubuntu Linux virtual machine via Parallels Desktop for Mac. What is the recommended partition size for doing Data Science work?","datascience",23,5
"30",24,"datascience","Data science and the Corona virus","Do you guys know of any project/s that needs help with data science or software development that can help in any way with the Corona virus?","datascience",24,16
"31",25,"datascience","How do you quantify fun in games?","I am working on a personal assignment where I am trying to bucket casual games on app store in a 3x3 matrix of fun vs profitability. Profitability could be divided into high, medium, low, based on ads served on the game, and in-game purchases. But how would you quantify fun? I guess how engaging the game is would decide how fun the game is, but would it be as simple as dividing it into high-medium-low, same as profitability?

Waiting eagerly for your thoughts.","datascience",25,7
"32",26,"datascience","NVIDIA's GTC 2020 - The World's Biggest AI & Deep Learning Conference - Best of all, registration for GTC Digital is free*","","datascience",26,2
"33",27,"datascience","Australian Career Guide advice","Australian currently studying CS & DS at UWA (Perth). Had a horrible first 2 years (5 subjects failed, horrible WAM & GPA) due to personal problems and now taking an extra year to graduate. Thinking of doing a Masters of Data Science program at either Monash or USyd. 

Was wondering whether this is a bad career option? Would it be better for me to go for a grad position for a few years then do my Masters?

I’m also really new to the idea of Machine learning and careers of that sort. If I want to pursue a ML eng career, would it be a requirement to have a SWE background? 

I’m overall not 100% sure how to pursue this career path and choose a proper Big Data job, as I’ve read most companies parade many jobs as Data Science. Also things in Australia could be very different to the US, so I was wondering if anyone else had anymore tips specifically for Australians.","datascience",27,3
"34",28,"datascience","An example of why communication skills matter more than technical skills","By using simple stats, nice charts and good story telling this guy has probably helped the fight against Coronavirus more that Google with its Deepmind https://medium.com/@tomaspueyo/coronavirus-act-today-or-people-will-die-f4d3d9cd99ca","datascience",28,17
"35",29,"datascience","Plotting with Python - Matplotlib OOP interface - any good guides to this?","

I'm looking for a decent guide on using Matplotlib with the OOP interface,
and the only issue is that as i've not really used it much previously, and
some tutorials seem to be a mixture of the ""matlab"" style and OOP style.

Pretty simple request - but if anyone who uses Matplotlib regularly with OOP
syntax could suggest a decent tutorial to go through that'd be appreciated.","datascience",29,12
"36",30,"datascience","Day in the Life of a Data Analyst [video]","Follow me for a day in my life as a Data Analyst! I know this is the Data Science subreddit. I am actually on my Data Science team at work and do some Data Science work, but have the title of Data Analyst. I have been meaning to make this video for a while so I’m glad to finally have it finished. Hope you enjoy it! 

Link:
https://youtu.be/qzZU6LAtIig","datascience",30,0
"37",31,"datascience","Ten Research Challenge Areas in Data Science","","datascience",31,0
"38",32,"datascience","Searching for a data/process/workflow 3D visualization tool with ability to connect with a database","Hello there,

as title says is there a visualization tool in 3D space which for workflows or processes which I can connect to databases (like oracle)?","datascience",32,6
"39",33,"datascience","[Survey] What Data Science course do you want to learn next?","Hi again - I am taking a quick 30 sec. survey from a random sample set of data science learners to understand their learning expectations. 

If you are interested, please feel free to fill your choice of course and also pl. feel free to circulate within your group/network. (survey is not mandatory - Pl. fill only if you are interested). 

Thanks in advance for your feedback!

[https://docs.google.com/forms/d/1wRmmrlIyanpwxbb0-heheI-vCGV4LyMXnapm\_9DgOvI](https://docs.google.com/forms/d/1wRmmrlIyanpwxbb0-heheI-vCGV4LyMXnapm_9DgOvI/edit)","datascience",33,0
"40",34,"datascience","Please give some tips on HireVue Interview.","I have a HireVue Interview which I am planning to attempt on Monday. Any tips or suggestions would be highly appreciated. Please share your experience.","datascience",34,2
"41",35,"datascience","Are there benchmarks for the tf-idf statistic?","","datascience",35,0
"42",95,"datascience","Recommendations for a good course that involves using python?","Hi I am looking to complete a data science course that uses python and not R. I know the JHU courserea certification is popular but the problem is it uses R. Is there a similar certification or course that uses python and is highly recommend or valuable like the JHU certification. Thanks for reading looking forward to your replies!!","datascience",95,2
"43",126,"DataScienceJobs","[Hiring] Data Quality Specialist in Singapore, Singapore","","datasciencejobs",26,0
"44",36,"datascience","How would you preprocess features like these?","The label is a probability that an event will happen and the features are past events that could or not be correlated to the label. A huge number of zeros in the features is due to filling NANs with 0. My goal here is more or less understand those dispersions and if I should remove or filter those data points for a regressor to perform well.

The data is highly imbalanced, with many more labels equal to zero than not, but still is a honest representation of reality.

Any ideas or important steps to take given the number of zeros, imbalance or distribution will help.

&#x200B;

https://preview.redd.it/mf7i2zrwvjm41.png?width=1416&format=png&auto=webp&s=e0c68503f6a56e2d52b7a122b13efd3fcb0747a1

https://preview.redd.it/yis0myhwvjm41.png?width=1416&format=png&auto=webp&s=10c9d50d4a0ad12dec163978300f82985b8188f9

https://preview.redd.it/a2g4u1awvjm41.png?width=1378&format=png&auto=webp&s=2d4ed7927214f1fafa5300c1196859b4dadfa35a

https://preview.redd.it/9wzdkyyvvjm41.png?width=1374&format=png&auto=webp&s=47b76af6dd50f3feec52b249b8353d33941ac19b","datascience",36,2
"45",37,"datascience","Validation/test set confusion","I just finished up coding a Nueral Network for a project and I am having some confusion. I have a 3 segmented partition {train, validation, test/hold-out.

How should I be using my validation set exactly? I thought I should be using this as a stopping criteria for training...and then use the test set to get a predictive accuracy. Or should I be using validation set to tune number of nodes/layers after allowing the model to fit with the training data alone? 

I have been reading a lot on this today and Hve thoroughly confused myself.","datascience",37,1
"46",38,"datascience","Companies: All Your Data Are Belong to Us","","datascience",38,0
"47",39,"datascience","List something you 've learned on the job","Can you guys list something you learned on the job but not during your BSc, MSc or PhD (education in general)? I am curious to see what industry ""does"" to data scientists.

I ll start first:

1. Accuracy of the model has to be reasonable but don't spend too much time iterating. Shipping it on time is more important
2. I spend more time cleaning / prepping data than training models","datascience",39,13
"48",40,"datascience","Created my first time series chart using Plotly with foreign exchange dataset. Dataset obtained from Kaggle","","datascience",40,21
"49",41,"datascience","Eat the News: Extract Article Text from News Feeds Around the Globe","","datascience",41,0
"50",42,"datascience","How “capable” were you in your first ever Data Analyst/Scientist position?","Although I know that even the most advanced DA/DS utilizes Google and other resources on a daily basis, I’m wondering how efficient or capable you guys were in general in your first ever position. Was your educational background enough to have you perform the daily tasks of your position without any handholding (aside from necessary guidance to understand the company’s standards and best practices)? Or was there a good amount of “coaching” from either teammates or your direct supervisor to get into the groove of things?","datascience",42,8
"51",43,"datascience","Internship Opportunities for 11th Grade Students","Hey, I’m currently a senior  year student in India. I’m looking to intern in the domain of data science / Machine Learning from 15th April onwards. 

My previous experience consists of various online courses, and a paid internship as a data scientist at NIBE AB that I did over the course of my junior year summer. PM me for more info!

Best,
M","datascience",43,8
"52",44,"datascience","Masters opinions","Hi! I’m 49 yrs old. Worked in finance 24 years and got bored.
I have been accepted at:

Msc of applied data science at University of Canterbury (New Zealand)

Msc Artificial Intelligence and applications at University of Strathclyde (Scotland)

Any insights on which program could be better for me will be greatly appreciated.

Thanks!","datascience",44,13
"53",45,"datascience","Data base design a useful class?","Guys, I have an option of taking a data base design class next semester? Do you think it's a good class to take if I want to get into the field of data science/ analytics. Here are some of the topics that will be covered in the class:

Students learn a systematic approach to database development using entity-relationship models, normalisation and relational database design. Students will use this approach to identify and define business information requirements, create entity relationship models and transform the requirements into an initial database design.

1. Explain systems integration
   1. Define the term systems integration
   2. Define the term systems integration
   3. Describe various systems development modeling tools
   4. Explain how these tools support the problem solving process
2. Summarize the process of database development
   1. Define key terms
   2. Explain the purpose (benefits) of database design
   3. Discuss the evolution of database design
   4. Describe the phases of database design
3. Analyze user information requirements
   1. Demonstrate importance of effective interviewing skills in the gathering of user requirements
   2. Demonstrate the ability to produce accurate and comprehensive documentation
   3. Utilize facilitation techniques to seek information from data users
   4. Identify business rules which underlie entity relationships
   5. Formulate a data dictionary with all appropriate components
4. Transform business information requirements to an entity relationship model
   1. Describe the benefits of data modeling
   2. Distinguish between popular notation conventions
   3. Identify and model entities
   4. Distinguish between attributes and entities
   5. Identify attributes (composite, multivalued and attribute domains)
   6. Assign unique identifiers to entities
   7. Describe the various types of possible relationships between entities
   8. Analyze and model relationships
   9. Normalize Data Models
   10. Resolve M:M Relationships
   11. Model Hierarchical Data and Recursive Relationships
   12. Model Roles with Relationships
   13. Model Entity Supertypes and Subtypes
   14. Model Exclusive Relationships
   15. Model Data Over Time
   16. Model complex Relationships
5. Convert ER diagrams to relational tables
   1. Apply basic conversion rules
   2. Map simple entities to tables
   3. Map Attributes to Columns
   4. Map unique identifiers to primary keys
   5. Map relationships to foreign keys
   6. Choose arc options
   7. Choose subtype options
6. Normalize tables in a relational database
   1. Define each of the five normal forms
   2. Maximize application maintainability by applying the principles of normalization
   3. Recognize Unnormalized Data
   4. Convert to first, second, and third normal Form
   5. Understand the fourth and fifth normal form
   6. Discuss normalizing during Data Modeling
7. Perform advanced database design functions
   1. Recognize when to generate artificial keys
   2. Understand the issues involved in specifying foreign keys and indexes
   3. Describe how referential integrity related to business data needs
   4. Specify referential integrity
   5. Design indexes
   6. Establish views
   7. Denormalize the database design","datascience",45,2
"54",46,"datascience","fixing pandas df output on macos terminal/iterm2","Hi, When displaying a pandas dataframe using df.to_string(), it seems like the terminal doesn't look at the size of the window and use that to determine how much space it has to display the results. As a result, it ends up looking like a blob of text compared to the gnome terminal on ubuntu which formats it properly. Does anyone know how to display the output properly? Using to_string(), as I want a display of all columns. Thanks!","datascience",46,3
"55",47,"datascience","Which city provides the best salary vs living costs ratio for a Data Scientist?","Just a social experiment since I can't find much on the internet: which city provides the best ratio in terms of high salary for a data scientist and low living costs, so you can save up the most money","datascience",47,9
"56",127,"DataScienceJobs","[Hiring] Computer Vision Research Engineer in Singapore, Singapore","","datasciencejobs",27,0
"57",128,"DataScienceJobs","Introduction to Regression Analysis & Its Approaches","Regression analysis is an algorithm of machine learning that is used to measure how closely related independent variables relate to a dependent variable. [Read More](https://www.janbasktraining.com/blog/introduction-to-regression-analysis/)

https://preview.redd.it/c1gkletj1ll41.jpg?width=1176&format=pjpg&auto=webp&s=a02bd693ffe3f9a0ac263e0c5783dcd85da0e00b","datasciencejobs",28,0
"58",129,"DataScienceJobs","[Hiring] Research Engineer, Acceleration in San Francisco, CA","","datasciencejobs",29,0
"59",48,"datascience","ML in Portfolio Optimisation & Backtest Overfitting (Python)","# ML in Portfolio Optimisation & Backtest Overfitting

We have just released [MlFinLab](https://github.com/hudson-and-thames/mlfinlab) version 0.7.0 which now includes the following:

## Portfolio Optimisation:

We expand on the family of Hierarchical Risk Parity optimizers by including the HERC and HCAA algorithms by Thomas Raffinot.

1. [Raffinot, Thomas, The Hierarchical Equal Risk Contribution Portfolio (August 23, 2018)](https://ssrn.com/abstract=3237540)
2. [Raffinot, Thomas, Hierarchical Clustering Based Asset Allocation (May 2017)](https://ssrn.com/abstract=2840729)
3. [Python implementation](https://mlfinlab.readthedocs.io/en/latest/implementations/portfolio_optimisation.html#hierarchical-clustering-asset-allocation-hcaa)

## Backtest Statistics

In order to fight backtest overfitting we have [implemented](https://mlfinlab.readthedocs.io/en/latest/implementations/backtest_statistics.html) the following:

* Probabilistic Sharpe Ratio
* Deflated Sharpe Ratio
* Minimum Track Record Length

**The Sharpe Ratio Efficient Frontier** *by* David H. Bailey *and* Marcos Lopez de Prado [available here](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1821643). *It provides a deeper understanding of Sharpe ratios implemented and minimum track record length.*

A big thank you to [Aditya Vyas](https://www.linkedin.com/in/aditya1702/) and [Illya Barziy](https://www.linkedin.com/in/illya-barziy-ba9292b1/), respectively.","datascience",48,0
"60",49,"datascience","Do a lot of companies do 100% online interviews now?","So that you don't even have to travel on-site, even for the ""final"" interview?

Also, do you think this virus thing will crush the job market for data science in the coming month?

&#x200B;

thanks","datascience",49,3
"61",50,"datascience","Data science stack question","Do big companies use Azure Devops or Gitlab CI?","datascience",50,2
"62",51,"datascience","How big data or data science can be used in political relations?","I got entrance to Phd in political sciences (international relations). I just want to to know how big data or data science can be used in analyzing international relations. For example relations between two states, analyzing conflicts like ethnic conflicts or civil wars.

Or do you have any sources for me to get more information?

Thanks","datascience",51,1
"63",52,"datascience","Searches of data science topics","","datascience",52,90
"64",53,"datascience","TensorFlow Developer Certificate - TensorFlow","","datascience",53,3
"65",54,"datascience","Data Science & Analytics Job Market in Germany","","datascience",54,0
"66",55,"datascience","If you'd recommend one ML book what it would be?","as a headline says. Just if you have to pick one, doesn't matter if it's an introduction or for more experienced users. What is that one book you'd recommend?","datascience",55,5
"67",56,"datascience","How drastic does a MS affect opportunity and pay?","I'll be graduating with a degree in environmental engineer with a minor in physics and computer science. 

I've applied and am considering going to grad school in either DS or CS with a focus on AI or DS.

I'm curious if all your thoughts on how much this would affect future opportunities? 

I've notice it's a bit difficult to get interviews for data science internships as engineering major even so with previous internship experience in the field. 

If I were able to get a full time data scientist position would that be more impactful than a MS? 

What do you guys think?","datascience",56,1
"68",57,"datascience","Is LOOCV really high variance?","In *Elements of Statistical Learning*, the authors write

>What value should we choose for K? With K = N [LOOCV], the cross-validation estimator is approximately unbiased for the true (expected) prediction er- ror, but can have high variance because the N “training sets” are so similar to one another. The computational burden is also considerable, requiring N applications of the learning method.

Computational burden is becoming less and less of an obstacle, which leaves variability as a reason not to perform LOOCV.  I've realized that ESL doesn't provide any references for this claim, and I'm ashamed to say I've just accepted it by virtue of having names like Hastie and Tibshirani on the cover.  There aren't even any simulations to substantiate the claim!

A colleague and I had a disagreement on CV scheme, which lead to me being shown [this](https://stats.stackexchange.com/questions/61783/bias-and-variance-in-leave-one-out-vs-k-fold-cross-validation/252031#252031) thread on Cross Validated. Seems like (at least from the simulations provided) that LOOCV can be provide unbiased estimates with comparable variability to K-Fold, flying in the face of ESL.

Does anyone know where the rationale for LOOCV being high variance came from, or know of simulations that show it to be high variance? Is this just one of those things we believe because other people believed it?","datascience",57,3
"69",58,"datascience","Hortonworks blog post: airline delays.","I am looking for an archived version of the hortonworks blog on predicting airline delays. I know it is quite old, but it is somewhat famous for walking through the experiment end to end. I want to get a feel for thought processes, rather than tools and technology. I've heard this is a good resource for that. Unfortunately it looks like their blog is gone after their merger with Cloudera.

To that end, any other good publications that might substitute are welcome, as long as they focus on scientific thought and are end-to-end. ","datascience",58,0
"70",59,"datascience","IBM Data Science Professional Certificate","Hi,I am 17 years old and I am looking forward to studying data science,I figured to better convince universities I am ambitious and certain of my decision and for the love of it I have decided to take some online specilization first in python and then I saw that IBM made it's online specializations free for the first month so I decided to enroll in one,but it's really not well made the links don't work the lectures are all over the place with bad explanations and the value is just not there,I have already finished 4 courses out of the 9,I feel bad leaving it because it's nice to have it for my resume or something but it's honestly a waste of time.What should I do ? If you have any advice on my journey to learning the and preparing to be a data scientist please do tell.

Thank you in advance.","datascience",59,11
"71",96,"datascience","When to not choose the highest accuracy model","Hi all,

I've come across a small dilemma in my work while creating a churn prediction model.

So the idea is that I'm trying to perform a binary classification to predict churn (0 = churn, 1 = no churn). The model is trained on data of churned observations and non-churned observations. I've managed to build models with extensive hyper-parameter tuning that can achieve \~95-98% testing accuracy. 

The problem is that if a model is always right in this case it would be unusable - it will correctly predict all unchurned observations as unchurned, and all churned observations as churned. So to see unchurned observations at-risk of churning, a less accurate model (in terms of recall) may be more useful.

My question: Are there reasons you would pick a less accurate model outside of computation cost, and interpretability? Would it be sensible to choose a less accurate model here?","datascience",96,19
"72",60,"datascience","Has anyone here completed the UC San Diego Edx Micro Masters Program in Data Science?","I am particularly interested in the third-course, Machine Learning Fundamentals. Does this class have as much math as the previous course, Probability and Statistics in Data Science using Python, which I am nearly finished with?  




I have enjoyed the Probability and Statistics course. However, the advertised Effort: 10–12 hours per week, has been a considerable underestimation due to my need to refresh my calculus skills, it’s been 20 years! I have done quite well in the course and am confident it will translate to an A. With that said, I won’t have the same time to dedicate Machine Learning Fundamentals this spring, if it requires as much catching up on the side. I am not worried about the programming. I volunteer as a coding club teacher (python/data science course) for middle and high school students, which includes projects using SciKit Learn, Karas, and Tensor Flow.




Thanks!



PS I am happy to answer any questions about the first two courses, if anyone is interested.","datascience",60,4
"73",61,"datascience","Do you think his series of courses is worth taking","I'm a software developer professionally but I am interested into transitioning into a career in data science.

My company has a pretty decent training budget and my manager suggested I go find some training in the field.

One of the post secondary schools in my city has the following program: https://www.nait.ca/coned/data-science. It is 6 weekend courses with 84 hours of classroom time. Do you think the content sounds relevant, and would that plus 9 years as a software developer (no computer science degree, just a 2 year diploma from a trade school) make me hirable?","datascience",61,3
"74",62,"datascience","A quick introduction to Data Science!","","datascience",62,0
"75",63,"datascience","UK Data Science & Analytics Job Market","","datascience",63,3
"76",64,"datascience","When to use ARIMA model vs linear regression (or any kind of regression)","I am trying to forecast time series of product sales, I started approaching the problem by implementing the ARIMA model, I iterated over all the possibilities of the models parameters (p, d, q) and picked the one with least RMSE, problem is the forecast is not as good as I wanted it to be, so I started studying other ways of prediction, like regression.

After plotting my data in a cumulative plot, I noticed that most of the time series I had are fairly linear, so probably I can fit a linear regression model on them.

What should I use in my case, ARIMA model or linear regression, and what does ARIMA model has to offer than regression does not, for it to compensate for being more complicated.

Here is a screenshot of my ARIMA forecast, and cumulative plot:

[373 is the RMSE of the time series forecast, blue is prediction, red is test data](https://preview.redd.it/2y5cyczem9m41.png?width=1338&format=png&auto=webp&s=39e427c77d9a1636167af79dfa04ceb65e9ef15f)","datascience",64,8
"77",65,"datascience","Classifier suspiciously always gets 99%","I am training classifiers and no matter what model I try I get very high Accuracy & precision scores.

Suspiciously high scores on the train and test sets that do not work as well on unseens data.

I can also seemingly change the accuracy to whatever I want it to be by tuning parameters.

Is this expected?

How do I proceed?","datascience",65,5
"78",66,"datascience","A random idea for tracking Coronavirus","Testing is a huge problem in the US because there's no testing in the US. Tracking is impossible in any direct sense. 

If you could access data related to general number of flu cases or something similar, you could potentially detect anomalies. Especially if you had very localized data. I'd guess that if it's not being tested, it's just being misdiagnosed/recorded as something else. Like if someone goes to the hospital with flu like symptoms, they probably just write it down as the closest thing matching the symptoms. I would hypothesize if that Coronavirus is spreading in areas served by specific hospitals, you may be able to see it as peaks in similiar illnesses. 


I don't know the signal to noise ratio though and if any data is available at all. I have some data science experience but none of the access to such information. I haven't been able to find a public source either.

It's also possible there could be other potential ways to get some signal, like social media or something like that. All ideas are welcome.

Edit: There's also other people probably thinking about this as well. I'm not aware of who they are though.","datascience",66,3
"79",67,"datascience","I created a very basic model in Google Sheets of the Coronavirus outbreak in the US until March 9","","datascience",67,1
"80",68,"datascience","Nordic Probabilistic AI School (ProbAI) — June 8-12, 2020","You are welcome to apply for the Nordic Probabilistic AI School (ProbAI) 2020 being held on June 8-12 in **Trondheim (Norway)**.

[**APPLY NOW**](https://probabilistic.ai/application) — The application deadline is March 26, but we recommend an early application.

## About ProbAI 2020

The mission of the 2nd Nordic Probabilistic AI School (ProbAI) remains unchanged. We aim to serve state-of-the-art expertise in probabilistic machine learning and artificial intelligence to the public, students, academia and industry.

Particularly, our objective is to bring an intermediate to advanced level summer school with a focus on probabilistic machine learning. We cover topics such as probabilistic models, deep generative models, latent variable models, inference with sampling and variational approximations, and probabilistic programming and tools.

The ProbAI 2020 is organized by the [Norwegian Open AI Lab](https://www.ntnu.edu/ailab) and hosted by the [Norwegian University of Science and Technology](https://www.ntnu.edu/) (NTNU) in Trondheim.

## COVID-19 Update

**Currently, we have no plans of cancelling the Nordic Probabilistic AI School.**

Please be assured that we are closely monitoring the situation around the 2019 novel coronavirus (COVID-19), and we are following the advice of local, national and international health authorities.

Should the status change, we will inform you through all available communication channels.

## Program

Together with the intentionally small team of invited lecturers, we hope to provide an efficient and quality knowledge transfer through:

* **carefully designed curriculum**,
* **tight cooperation** between our lecturers,
* a mix of **theoretical lectures** and some **hands-on tutorials**,
* extra time for participants with our **teaching assistants** at hand,
* an **innovative lecture room** ([R2](https://roundme.com/tour/214005/view/589158/)) that allows for a close collaboration between the students and lecturers.

## Keynote and Talks

* [Max Welling](https://staff.fnwi.uva.nl/m.welling/) (University of Amsterdam) — Keynote
* [Evrim Acar Ataman](https://scholar.google.com/citations?user=eQKaErAAAAAJ) (Simula Research Lab) — Tensor Factorizations for Physical, Chemical, and Biological Systems
* [Atılım Güneş Baydin](https://scholar.google.com/citations?user=GWBSOj4AAAAJ) (University of Oxford) — Probabilistic Programming, Machine Learning, and Physics
* [Keith L. Downing](https://www.ntnu.edu/employees/keithd) (NTNU) — Bio-Inspired AI
* [Mihaela Rosca](https://scholar.google.com/citations?user=MxkDwD0AAAAJ) (DeepMind) — VAE/GAN

## Lectures

* [Arto Klami](https://scholar.google.com/citations?user=v8PeLGgAAAAJ) (University of Helsinki) — Variational Inference and Optimization
* [Andrés R. Masegosa](https://scholar.google.no/citations?user=J1zoY7AAAAAJ) (University of Almería) — Probabilistic Programming and Variational Inference
* [Didrik Nielsen](https://scholar.google.com/citations?user=-sbw1JIAAAAJ) (Technical University of Denmark) — Normalizing Flows and PixelCNN
* [Thomas Dyhre Nielsen](https://scholar.google.com/citations?user=6fWF0CgAAAAJ) (Aalborg University) — Probabilistic Programming and Variational Inference
* [Francisco Ruiz](https://scholar.google.com/citations?user=khgtYMgAAAAJ) (DeepMind) — Variational Inference with Implicit and Semi-Implicit Distributions
* [Antonio Salmerón](https://scholar.google.com/citations?user=41enG0oAAAAJ) (University of Almería) — Probabilistic Modeling
* [Çağatay Yıldız](https://scholar.google.fi/citations?user=dNloPBUAAAAJ&hl=en) (Aalto University) — ODE2VAE

*More to be announced.*

## Registration

The registration fee includes all courses, coffee breaks, lunches and banquet.

* Students (including PhD) → 2500 NOK \~ 250 EUR
* Academia → 5000 NOK \~ 500 EUR
* Industry → 10000 NOK \~ 1000 EUR

We can offer only a limited number of **scholarships** aimed for applicants from developing countries and under-represented groups.

## Contact

* Email: [hello@probabilistic.ai](mailto:hello@probabilistic.ai)
* Website: [https://probabilistic.ai](https://probabilistic.ai)
* Twitter: [https://twitter.com/probabilisticai/](https://twitter.com/probabilisticai/)
* Facebook: [https://www.facebook.com/probabilisticai/](https://www.facebook.com/probabilisticai/)

The organizing team: Heri Ramampiaro, Helge Langseth, Tárik S. Salem, Eliezer de Souza da Silva, Marianne Lyseng, Ludvig Killingberg.","datascience",68,2
"81",69,"datascience","Machine Learning Project - Data Science Movie Recommendation System Project in R !!","","datascience",69,1
"82",70,"datascience","Advanced Pandas (PandasVault) previously removed from r/learnpython because of moderator difficulties but a great resource nonetheless.","Here is the post I saw. [https://www.reddit.com/r/learnpython/comments/fg9tqg/advanced\_pandas\_10\_github\_repo\_learn\_with\_more/All](https://www.reddit.com/r/learnpython/comments/fg9tqg/advanced_pandas_10_github_repo_learn_with_more/All) 

The functions have been compared and tested with alternatives, only the fastest equivalent functions have been developed and included in this package. 

The package has more than 20 wrapped functions and 100 snippets. Adapted for the Pandas 1.0 release.

\-- [https://github.com/firmai/pandasvault/blob/master/README.md](https://github.com/firmai/pandasvault/blob/master/README.md) (Readme)

\-- [https://colab.research.google.com/drive/1TRKHPGfQnE2yw6\_VPBJZ3nZ8lIPQYiuP](https://colab.research.google.com/drive/1TRKHPGfQnE2yw6_VPBJZ3nZ8lIPQYiuP) (Colab)","datascience",70,1
"83",71,"datascience","should I get a PhD in computer vision?","I am applying to do a computer vision masters at the university of surrey UK ([**MSc Computer Vision, Robotics and Machine Learning**](https://www.surrey.ac.uk/postgraduate/computer-vision-robotics-and-machine-learning-msc-2018)). Postmasters, I am considering a PhD in the subject. I was wondering.

1. how hard is a PhD? 
2. what is the attrition rate? 
3. how is life after completing a computer vision PhD?

Thank you","datascience",71,1
"84",97,"datascience","Describing a long tail distribution","I am having trouble finding a good way to fit a long tail dataset to a distribution. 
I would like to do something like have a mean, median and std put into a function and have it generate random points modeled in this way. Any libraries or tricks anyone can suggest?","datascience",97,6
"85",98,"datascience","When to use statistical tests?","Hello all, I'm wondering when do you want to use statistical tests in your data analysis and feature engineering?

The most recent project I'm working on I used a Chi-squared test for categorical variables and ANOVA for some numerical categories versus my target categorical variable (musical genre).

To be honest though, I'm not fully clear on when or why I should use these tests.","datascience",98,34
"86",130,"DataScienceJobs","[Hiring] Machine Learning Engineer in Pittsburgh, PA, USA","","datasciencejobs",30,0
"87",72,"datascience","What is the closest Python equivalent of R's dbplyr?","Most people who use R for data science are familiar with its [dplyr](https://dplyr.tidyverse.org/) package. [Dbplyr](https://db.rstudio.com/dplyr/) allows users to work with remote data stored in databases as if it was in-memory data. Basically, it translates dplyr verbs into SQL queries. Crucially, it has two enormous advantages over simply sending out SQL queries through a connection:

&#x200B;

>The most important difference between ordinary data frames and remote database queries is that your R code is translated into SQL and executed in the database, not in R. When working with databases, dplyr tries to be as lazy as possible:  
>  
>It never pulls data into R unless you explicitly ask for it.  
>  
>It delays doing any work until the last possible moment: it collects together everything you want to do and then sends it to the database in one step.

&#x200B;

I'm looking for a similar package for Python. So far, I've found two packages which do something akin to the ""verb-to-SQL"" translation of dbplyr: [Blaze](https://github.com/blaze/blaze) and [Ibis](https://github.com/ibis-project/ibis) (I've actually found them through [this r/datascience post](https://www.reddit.com/r/datascience/comments/7w0ap8/the_dplyr_r_package_has_an_explain_function_that/)). Blaze appears to have been more popular than Ibis, but seems to have gone almost completely stale some years ago, while Ibis is in active development. I haven't yet been able to figure out if they offer the same ""laziness"" of dbplyr, so if anyone could clear that out for me, it would be greatly appreciated. Between Blaze and Ibis, which one would you recommend? Additionally, if anyone knows of some better alternative that I haven't mentioned, please share it.","datascience",72,58
"88",73,"datascience","Top 5 Reasons To Use R language For Data Science","","datascience",73,6
"89",74,"datascience","Implementing statistical test neural networks","I am starting to work on a project where I have to compare the output of standard statistical test such as Chi square test to a neural network that emulates the same test. The idea is to build a neural network from scratch. Is this an acceptable path or should I just try to build a network with library like keras? I am looking for help and see if anyone has any ideas to share.","datascience",74,1
"90",75,"datascience","How do you prevent overfitting when building a model?","I was asked this question in an interview, and gave what I thought was a solid answer, but the interviewer was looking for something different.  How would you all answer this question?","datascience",75,13
"91",76,"datascience","Categorical or numerical for yes/no classification modeling?","Building some classification models in R (rattle) and my target is a binary yes/no variable.  About 15 of my variables are numeric and about 5 (including my target) are categorical. Is there any benefit in transforming my target yes/no variable to numerical?   Better to leave as categorical?   Probably using SVM, Random Forest, Boost and Net Neural modeling to compare for best accuracy (and other results).  Untimely trying to predict most Yes’ while limiting Type II errors as best as possible.","datascience",76,1
"92",77,"datascience","Favorite ""engineering notebook tools"" for DS/ML?","I want to improve my notebook practices for engineering/data science/machine learning. I've used very simple text editors or notes software in the past, but would like to get more organized. What are your favorite tools?

Emacs + org mode seems very popular, I'm uncertain how easy and quick it is to use day-to-day (to write down meeting minutes, insert graphs, etc.). Using Jupyter notebooks solely is hard to search/index. 

I'd like the input from the data science/machine learning community. I primarily use MATLAB/Python and Jupyter notebooks, which make it extremely easy to share results ans graphs with non-technical colleagues. 

Thanks!","datascience",77,0
"93",78,"datascience","Question about Accomplishments at Work","Hi All,

I'm currently about 7 months into my first DS role with a large corporation. I have been learning a ton including big data technologies, engineering, new software, and new languages. This has been great for my development and really improved my skills and I'm very grateful for it (and my manager!).

However, I feel as that I don't actually have any ""accomplishments"" in terms of modelling and deployment. Our company is late to the data analytics/science scene and we are running a new DS shop. We can never fully complete a project and implement anything as whatever new thing is keeping an executive up at night trumps whatever our current project is. Multiple projects have been pushed to the side in my time here even ones with actual cost savings.

For example, I was able to develop a scoring engine for my first project here that would result in 5-8m in savings a month. Our VP was excited by this number but was too uncomfortable/unfamiliar with data science and machine learning to let us implement it. We tried explaining everything to him as best as we could but to no avail. We can easily do this with docker and other tools with a little bit of help with the IT group. I'm not saying everyone is like this but it seems as though you're limiting what we were hired to do. 

So many projects come in and then get pushed off that we can't even get halfway through one of them. However, I have developed a cool ML engineering pipeline for our projects which we all use which I'm very proud of, but with regards to models and actual deployment, I have nothing.

My manager has said it takes time to get DS shops up and running in unfamiliar places but I feel like I won't have anything to show for on a resume other than the pipeline/new things I've learned (which I'm not discounting at all). I guess I'm really trying to get at the fact that we can save time/money by implement models but it's like we'll never get there.

Like I mentioned though, my mentor here has been more than great to me and what I've learned so far will benefit me for years to come. I just wish we would be able to finish out projects and get stuff implemented for the business.

Any feedback or advice from the community would be greatly appreciated!

Thank you!","datascience",78,10
"94",79,"datascience","How to make data viz websites? Links provided","So I'm looking at some college courses. I'm already a data analyst with some working knowledge of python. I was thinking about taking a local python course but I realized I really want to be able to create a data viz website. 

These are incredible but here's some ideas. [https://brusselsairportinnumbers.brusselsairport.be](https://brusselsairportinnumbers.brusselsairport.be)

[http://www.brandlovescore.com/blackfriday2017/#bf](http://www.brandlovescore.com/blackfriday2017/#bf)

So what does this mean for my study track? Should I take python and a basic web dev course? Should I take a javascript course instead of python? I don't know where to start!","datascience",79,6
"95",80,"datascience","Coursera Pi Day Promo - Data Science Specialization and Certs at $3.14","Hey everyone, heres a quick heads up, Coursera is running Pi day promo. Select Data Science specialization and certs available at just $3.14 for the first month. 
Consider looking at the [participating programs](https://www.google.com/amp/s/onlinecoursesgalore.com/coursera-pi-day-promo/amp/)","datascience",80,16
"96",81,"datascience","Using PIL to Resize non-image Files?","I am working on a research project involving brain wave data. The goal is to classify (1,0) each ""image."" The problem is essentially an image classification problem, where I could use a CNN, but it's not clean at all like most CNN examples online. The files that I have are tsv's (100+ trials per participant with a 1, 0 label on each), and I have stacked them all into one pickle file with each having the participant ID and trial ID attached.

I want to feed them through a CNN, but almost examples online deal with equal-sized images. My data aren't of equal size, and they aren't images. I'm wanting to use PIL to make each file the same size, but is PIL even the correct way of doing so since I don't have image files?","datascience",81,0
"97",83,"datascience","Is 2-3 hours of studying per day enough?","Hi,

I am 35 yr old aspiring Data Analyst from the UK and currently working through DataQuest's 'Data Analyst with Python Path'.  I've spent around 30 hours into the platform in the past couple of weeks.

I have no background in Data Analysis (I only have a diploma in accountancy and degree in Psychology) with my past employment being mostly in sales, debt collection and complaint handling.

Every day I'm putting in 2-3 hours into DataQuest and despite feeling like I am making some progress, it's feels slow (even though I am going through the material quicker than DataQuest's projected timescales) and my knowledge of the topics fickle.

**Is 2-3 hours per day enough for someone serious in breaking into Data Analytics?**

I'm currently between employment contracts and so I have LOTS of time on my hands.

If I'm honest, I feel like I am slacking. However, because all the material is new and challenging (DataQuest known for it's difficulty), I don't think I can do much more than this per day without resenting the learning project.

**Do I need to man up and do more or is there something I can do passively each day to reinforce topics I've already covered in DQ? Like read theoretical books or watch videos.**

Thanks!

Beresford","datascience",83,5
"98",84,"datascience","Should I use GitHub as a place to backup my codes?","I have a bunch of computer codes on simple artificial intelligence concepts like the A* search, BFS, DFS, etc. 

I am actually trying to create a place where employers or other institutes (I'm applying for a master's course in data science) can look at what I have done so far in support of my application form.

Would it be a good idea to create a repository on GitHub and upload all of my source codes and attach the link to my application?

P.s. - I have a very vague idea of what GitHub actually is, and I'm still trying to figure out it's uses and advantages.","datascience",84,12
"99",85,"datascience","Any interest in a Slack group?","There are a few different branches of data science (NLP, medical data science) and analytics (business intelligence, etc) communities on reddit and it might be nice to set up a Slack space so different people can have discussions or share ideas or start projects? 


I'd just be concerned about splitting the discussion topics away from the subreddits but thought I'd throw the idea out there

Edit: On second thought, I forgot Slack has limitations on message history if you don't pay for the service...","datascience",85,1
"100",86,"datascience","Anyone know of any simple deduping projects using Apache Arrow, Parquet etc?","Looking for something minimal, imagining this as the first layer of an append-only system where you make the compromise to store only never-before-seen records (within a partition say). You lose information about ""flip-flops"" but this is a good compromise in most polling/scraping entrypoints to a persistent data-acrrual system.  


Not a whole lot conceptually but would be nice to know if folks are doing this and a minimal even log viewer on top.  


I am also interested if anyone is doing something like this on IPFS or Orbit-db. I don't know that start all yet, but the possibility of sharing data pulling across trusted peers is extremely interesting for obvious reasons.","datascience",86,8
"101",87,"datascience","What is the role of R / Python in a world with Tableau/SAC/DOMO, etc…","Obviously, I am very new to the DS world, and trying to figure out where to spend my time learning. As I struggle through learning R, I question if my time would be better spent learning my company’s own analysis software (FWIW, I work for a (giant) software company, and have been here for the past 20 years).

So, in a world where I can create a chart by dragging/dropping fields, or run a statistical analysis by highlighting a few columns and pressing a button, what is the advantage of learning R or Python?

Is it akin to how some people are just married to the command line, and others prefer a GUI, or is there more to it than that?

Sorry if this is a boneheaded question…as you can tell I’m still wrapping my head around some of this stuff.","datascience",87,23
"102",88,"datascience","Book/Videos that demonstrates business side of data science","Sorry if the question is vague, I am new to this field

Recently developed RFM and CLV functions from retail dataset, and it motivated me to seek other valuable information that can be derived from transactions/purchases

Any recommendations where to get  the mentioned knowledge would be very much appreciated","datascience",88,19
"103",89,"datascience","March 25, Free Talk with AI/ML Legend Michael I. Jordan: ""The Decision-Making Side of Machine Learning: Computational, Inferential, and Economic Perspectives""","March 25, join Michael I. Jordan, one of the most influential people in the history of machine learning, statistics, and artificial intelligence, for the free ACM TechTalk, ""[The Decision-Making Side of Machine Learning: Computational, Inferential, and Economic Perspectives](https://webinars.on24.com/acm/jordan?partnerref=red).""

Much of the recent focus in ML has been on the pattern-recognition side of the field. This talk will focus instead on the decision-making side, where many fundamental challenges remain. Some are statistical in nature, including the challenges associated with multiple decision-making, and some are algorithmic, including the challenge of coordinated decision-making on distributed platforms. Others are economic, involving learning systems that must cope with scarcity and competition. Jordan will present recent progress on each of these fronts.","datascience",89,0
"104",90,"datascience","How is the Assisted Modeling feature of Alteryx?","I think it's currently in Beta - looks interesting but wanted to hear from others,b if it's really useful or more of a half-working gimmick? And if there are any other competitive solutions out there?","datascience",90,3
"105",91,"datascience","How do I compute this percentage from the available data? Is this a linear regression? Data science project.","I just came up with a data science-y project idea but I need help with the math side of it.

I will take studies that have found a correlation between cannabis use in undeveloped brains and decreased cognitive capacity and for the sake of this example I will input 2 variables: average frequency of consumption and quantity consumed. I will take this through a python script and I will output a mathematical function that connects two percentages: the probability (first percentage) X% that you will be Y% less capable than the average non-smoker person in either short-term memory, attention span, etc.

The problem is I know literally no statistics so I'm kinda struggling with the math side. Is this what you'd call a linear regression? What is the actual algorithm for outputting this mathematical function? I first thought I would have to just do some sort of arithmetic mean but it got more complicated when you had more values. For example I can have this data set (a bigger sample would give more accuracy but I'm gonna give a sample of 3 so this example is easier)

Let f be the average frequency of use in days: how much days do they wait in between smoke sessions

Let q be the average quantity they consume in each session (in grams or whatever unit of measure, doesn't matter).

User 1: f = 7, q = 1

User 2: f = 14, q = 1.2

User 3: f = 3, q = 0.5

Each user will also have a variable representing how much less capable they are than the average person on a certain mental task. In reality I'm probably gonna have a list of variables for each user so I compute a separate mathematical function for each mental ability (memory, attention span, etc.) but for the sake of this example let's say they have just one more variable representing how worse they are from the average person at attention span. Let it be a.

User 1: a = 0.2 (20%)

User 2: a = 0.1

User 3: a = 0.3

Now I have to use all this data to compute a mathematical function f : S -> [0;1], S = {f, q, p | f, q are from R+, p is from [0;1] } which takes in the percentage of probability that the output is gonna happen as well as f and q and outputs the percentage decrease in attention span from the normal person (basically a). Now that I think of it, it should work in reverse too, inputting the percentage decrease and outputting the probability that will happen so this function also has to be *bijective*. Actually it's not bijective per se, because I just reverse a and p. I add a in the domain set ""S"" and take out p in the output. Anyway...

Now what I need help with is computing the larger function that takes in two variables and outputs the function f. And that larger function is fed before two *lists* of variables to have the proper data. That will be the script I will write. I'm stumped, because it's taking in three lists of variables and outputs 2. If it was just two outputting 1 it would be easier, for example:

User 1: f = 7, a = 0.3

User 2: f = 14, a = 0.1

User 3: f = 3, a = 0.5

It's way easier to do it now, having to output just a. If I input 7, 14 or 3 I know what I'm going to get. If I output anything else between 3 and 14 I just have to find out the relation between the two closest variables. From 14 to 7, f halved and a tripled. This would mean that (most likely) if f quarters then a would be multiplied by 1.5, if f is divided by 3 a would be multiplied by 4.5 etc. That's for any variable between 14 and 7. Between 3 and 7 I do the same with the other data. Is this a correct approach? Either way if you also have to add the output p besides the output a I'm stuck. Then you also add the input q and I'm even more stuck. 

So what do I have to do ?

I know how to compute derivatives and to work with matrices and determinants in case that is needed.","datascience",91,8
"106",92,"datascience","understanding propensity score matching","so my layman's term of propensity score matching is that it allows you to do an 'apples to apples' comparison.

So for example, if I have 2 groups of people:

last year: 100 of 200 people who buy,  
this year: 200 of 500 people who buy.

if I want to compare the customers from this year and last year, I can use propensity scoring and it'll match customers from this year and last year so I can do better comparison. So for example, if this year, there is a very very unique person, I may want to throw that person out for comparison.

reading the match package in R, the first step is to do a logistic regression to get the probability of buying. My confusion is that they keep referring that 'probability' to propensity.

Is propensity just another word for probability? if so, why are we matching by propensity? shouldn't we match by features? i,e race to race, gender to gender, etc.

I dont think I follow the logic of how matching by probability creates the 'apples to apples' comparison.","datascience",92,16
"107",93,"datascience","Who Won Super Tuesday's Media Coverage. Based On Data","","datascience",93,0
"108",286,"MachineLearning","[R] A Survey on The Expressive Power of Graph Neural Networks","","machinelearning",86,1
"109",102,"DataScienceJobs","I am hopeless in my job search. Would you mind taking a look at my resume to see if you have any suggestions?","&#x200B;

A little background about me - I am a first-generation Bangladeshi American and the first to attend a college. While pursuing my higher education (A.S in Computer Science, B.S in Applied Mathematics, M.S in Data Science), I worked as a bartender for 7 years to support my family in NYC. 

I have graduated in December and I have been applying since the start of the year. However, I have received only one phone screening.  I do not have any formal work experience. Before starting college, I took a break from studies and worked at a fraud prevention company as an office administrator. One of my tasks was to collect data and that's how I became interested in the field of Data Science. 

If you guys could look at my resume and tell me how I can improve my chances of getting hired, I would appreciate it a lot. It has been a while since I have worked. I feel hopeless and I don't want to go back to working as a bartender after working so hard to get my degrees. I am even being denied of internships. 

Once again, thank you so much for your time. I humbly appreciate it. 

&#x200B;

https://preview.redd.it/82883yre4jm41.png?width=764&format=png&auto=webp&s=ef598f39228b0847313a88d082a33ba285c56b29","datasciencejobs",2,19
"110",103,"DataScienceJobs","Are companies going to slow recruitment given the coronavirus situation?","With so many companies 100% WFH right now and the economy looking pretty shaky, are companies going to hold off on recruitment for DS jobs? Interested to hear from those involved with recruitment in the Bay Area particularly. Thanks.","datasciencejobs",3,9
"111",104,"DataScienceJobs","[Hiring] Machine Learning Engineer in Austin, TX","","datasciencejobs",4,0
"112",105,"DataScienceJobs","[Hiring] Big Data Engineer in San Francisco or Austin","","datasciencejobs",5,0
"113",106,"DataScienceJobs","Data Science & Analytics Job Market in Germany","","datasciencejobs",6,0
"114",107,"DataScienceJobs","Seeking summer internship opportunities in USA","Hi everyone. I’m currently pursuing my master’s degree in Data Science at Illinois Institute of Technology, Chicago. I’m looking for internship opportunities in summer. Please get back to me if you have any leads. 
Here is a link to my LinkedIn profile:
https://www.linkedin.com/in/sohansputhran","datasciencejobs",7,4
"115",108,"DataScienceJobs","[Hiring] Machine Learning Software Development Eng. in Santa Clara, California / Austin, Texas","","datasciencejobs",8,0
"116",109,"DataScienceJobs","UK Data Science & Analytics Job Market","","datasciencejobs",9,0
"117",110,"DataScienceJobs","Seeking Internship position for Data Analytics in Europe","I am currently doing MSc in Data Engineering in Jacobs University, Bremen, Germany. I am looking for Internship position of Data Analyst, offering skills in statistical modelling techniques, machine learning techniques used for NLP and Computer Vision in Europe. Comment below if anyone would like to help me. Thank you.","datasciencejobs",10,0
"118",111,"DataScienceJobs","Clearance holders","If you have a clearance and are looking for data science jobs, the company I work for is hiring at all levels, but especially junior. 

Hit me up if you are interested.","datasciencejobs",11,7
"119",112,"DataScienceJobs","[Hiring][Internship] Machine Learning Intern in Bucharest, RO","","datasciencejobs",12,0
"120",113,"DataScienceJobs","[Hiring] Analytics Associate at Priorities USA - Washington, DC","","datasciencejobs",13,0
"121",114,"DataScienceJobs","Remote data science role for a new cs grad","Hello all, do as a CS graduate I have been given an impressive offer for a new grad like me. However I am still assessing a remote work at home job at the beginning of my career. The company is startup and my responsibilities looks significant for my leaning and personal dev. However I just think about working remote for at least a year without going crazy(I am an introvert but occasionally likes socializing). Anybody has any experiences doing remote as their first job? How to remain sane and other best remote practices to do?","datasciencejobs",14,6
"122",115,"DataScienceJobs","[Hiring][Full Time, Temporary] Senior Project Scientist (Two Positions) in Norfolk, VA","","datasciencejobs",15,0
"123",116,"DataScienceJobs","[Hiring] Software Engineer, Machine Learning (Remote)","","datasciencejobs",16,2
"124",117,"DataScienceJobs","Recently certified in data science","Coming to my profile, I done my PGP course in Data Analytics with applied practical knowledge and more strong in deep learning where image processing and building network with detailed architecture..My projects are like human activity recognition using mobile sensor data to predict the user is in which position and some statistical related project on class imbalance datasets.
As of I well skilled with advance technologies in Analytics and done with my graduation in 2018
If any jobs in INDIA for a fresher.. Kindly reply to my post ......waiting with excitement
And Thanks","datasciencejobs",17,1
"125",118,"DataScienceJobs","Hi All! I’m looking for Data Science opportunities across US. Will be graduating in May. Any leads for jobs or feedback to improve my resume are highly appreciated! TIA :)","","datasciencejobs",18,8
"126",119,"DataScienceJobs","8 Jobs Hiring Now!","&#x200B;

|Company Name|Title|City|
|:-|:-|:-|
|[Wells Fargo](https://www.adzuna.com/land/ad/1479281346?v=8D5AA6F6775098E2BAB233A704ADBFD49269BBE2&utm_source=hallimjolken&utm_medium=ppc&partnerb=1&chnlid=1040)|[Data Science Team Lead - Wells Fargo Internal Audit - Quantitative Analytics Specialist 4](https://www.adzuna.com/land/ad/1479281346?v=8D5AA6F6775098E2BAB233A704ADBFD49269BBE2&utm_source=hallimjolken&utm_medium=ppc&partnerb=1&chnlid=1040)|[Tempe](https://www.adzuna.com/land/ad/1479281346?v=8D5AA6F6775098E2BAB233A704ADBFD49269BBE2&utm_source=hallimjolken&utm_medium=ppc&partnerb=1&chnlid=1040)|
||||
||||
|[Emonics LLC](https://click.appcast.io/track/3ilhcgb?cs=hj6&exch=6q&bid=7g-BOD3yIyJl4P4ikp9YSg==&ob=Qr-jsEQpDHhy0x61V8PjDg==)|[Data Science](https://click.appcast.io/track/3ilhcgb?cs=hj6&exch=6q&bid=7g-BOD3yIyJl4P4ikp9YSg==&ob=Qr-jsEQpDHhy0x61V8PjDg==)|[Bay County](https://click.appcast.io/track/3ilhcgb?cs=hj6&exch=6q&bid=7g-BOD3yIyJl4P4ikp9YSg==&ob=Qr-jsEQpDHhy0x61V8PjDg==)|
|[Regeneron Pharmaceutical](https://click.appcast.io/track/3aflhri?cs=hj6&exch=5i&bid=RjisTn_QvJ_s6s7uxZBkFw==&ob=TWDTvsbu7sS1cze_iMIzNg==)|[Senior Manager (Data Modeling/Data Science/Analytics)](https://click.appcast.io/track/3aflhri?cs=hj6&exch=5i&bid=RjisTn_QvJ_s6s7uxZBkFw==&ob=TWDTvsbu7sS1cze_iMIzNg==)|[Tarrytown](https://click.appcast.io/track/3aflhri?cs=hj6&exch=5i&bid=RjisTn_QvJ_s6s7uxZBkFw==&ob=TWDTvsbu7sS1cze_iMIzNg==)|
||||
||||
|[Lockheed Martin Corporation](https://click.appcast.io/track/3ilah1x?cs=hj6&exch=4r&bid=4uL3Mqbnb3wOHQb9DD7Rng==&ob=3thMwcmdPA8XiBta5rysHQ==)|[Manager, Data Science Analytics / Data Scientist Manager](https://click.appcast.io/track/3ilah1x?cs=hj6&exch=4r&bid=4uL3Mqbnb3wOHQb9DD7Rng==&ob=3thMwcmdPA8XiBta5rysHQ==)|[North East Dallas](https://click.appcast.io/track/3ilah1x?cs=hj6&exch=4r&bid=4uL3Mqbnb3wOHQb9DD7Rng==&ob=3thMwcmdPA8XiBta5rysHQ==)|

Hey guys, here are some recent job openings , feel free to comment here if you have any questions, I'm at the community's disposal! If you encounter any problems with any of these job openings please let me know that I will modify the table accordingly. Thanks!","datasciencejobs",19,4
"127",120,"DataScienceJobs","Hi Guys! I have been looking out for Data Analyst/ Data Science roles for a couple of months now. I have been getting no interview calls and at this point I am desperate to find a full time job.","","datasciencejobs",20,24
"128",121,"DataScienceJobs","[Hiring] Machine Learning Engineer in San Francisco, CA","","datasciencejobs",21,0
"129",122,"DataScienceJobs","[Hiring][Internship] Machine Learning Researcher, Intern (2020) in Pittsburgh, PA, USA","","datasciencejobs",22,0
"130",123,"DataScienceJobs","[Hiring] Data Scientist in New York, New York","","datasciencejobs",23,2
"131",124,"DataScienceJobs","[Hiring] Data Engineer in Boston, MA, US","","datasciencejobs",24,0
"132",125,"DataScienceJobs","[Hiring] Data & AI Architect, IBM Cork in Cork, UK","","datasciencejobs",25,0
"133",131,"DataScienceJobs","Amazon BIE Salaries-L4/L5 @Seattle?","Does anyone have any idea about the band? I do not have an offer yet but I have been asked this before the interview. I do not have other offers in hand.

What would be the range for TC base, stock,sign-on wise?

&#x200B;

Would really appreciate your help","datasciencejobs",31,0
"134",132,"DataScienceJobs","[Hiring] Machine Learning Engineering Manager in Pittsburgh, PA, USA","","datasciencejobs",32,0
"135",133,"DataScienceJobs","Any advice would be really helpful. Can’t figure out where my life is going even with good education. I feel like I’m wasting my time searching for job in Australia. I feel like ripping myself for spending too much money on education","","datasciencejobs",33,3
"136",134,"DataScienceJobs","[Hiring] Research Scientist, Data Science in Boston, MA, US","","datasciencejobs",34,0
"137",135,"DataScienceJobs","[Hiring] Head of Artificial Intelligence & Machine Learning Research in Toronto, ON, CA","","datasciencejobs",35,0
"138",136,"DataScienceJobs","[HIRING] Senior Machine Learning Engineer (Can work remotely from anywhere in the world)","WalletHub is hiring Senior Machine Learning Engineer. Link : [https://www.youtube.com/watch?v=MslrVQrkWRU](https://www.youtube.com/watch?v=MslrVQrkWRU)","datasciencejobs",36,0
"139",137,"DataScienceJobs","[Hiring] Senior Machine Learning Engineer, Core ML in San Francisco","","datasciencejobs",37,0
"140",138,"DataScienceJobs","[Hiring] Senior Data Scientist / ML Engineer in Zurich or Berlin","It’s for a unicorn travel tech company and can be based on a marketing team or a core team. Depending on your preference and ambitions. 

Drop me a message and I can go through more details","datasciencejobs",38,0
"141",139,"DataScienceJobs","[Hiring] Staff Data Scientist, Ads in New York","","datasciencejobs",39,0
"142",140,"DataScienceJobs","[HIRING] Data Scientists (Can work remotely from anywhere in the world)","Kraken is hiring experienced 'Data Scientists'. Link : [https://www.youtube.com/watch?v=4GpMnyR2-T0](https://www.youtube.com/watch?v=4GpMnyR2-T0)","datasciencejobs",40,1
"143",141,"DataScienceJobs","[Hiring][Internship] Data Science Intern in San Francisco, CA","","datasciencejobs",41,1
"144",142,"DataScienceJobs","Looking for visa sponsorship senior data scientist position in UK/US","Dear Recruiters,

My work in 1min video-  [VideoResume](https://drive.google.com/open?id=1TgTVroGndgiERtWbqLesDB05DfF6vE5t)

I am a motivated professional with innovation proficiency and extensive Principal Data Scientist experience. Recently, I learned of an opening for the Senior Data Scientist role and I was compelled to contact you with my interest. I believe that my professional background and industrialist drive make me an ideal candidate for this opportunity.

As a person who thrives in high-pressure and fast-paced situations, I strive for positive results through the application of my Computer Vision and Deep Learning abilities. Additionally, I possess expertise in Design Architect and an aptitude for optimizing performance and motivating colleagues. In any position, I am able to visualize success and identify innovative and effective strategies for achieving it.

I have artfully balanced workplace objectives and productive relationships, inspiring strategies and insightful suggestions to achieve a competitive business edge. My team-building and problem-solving strengths have enabled my professional growth. I have enclosed my resume for your review. I will try and contact you within the week to discuss the next steps in your hiring process. I appreciate your time and consideration of my candidacy for your Senior Data Scientist Position.

&#x200B;

[Resume](https://drive.google.com/open?id=1N50FBSZB0ncr7bj5M6OU2EyZb1hob8bx)

&#x200B;

Sincerely,

Rahul

Tripathi","datasciencejobs",42,15
"145",143,"DataScienceJobs","[Hiring] Data Scientist (Business Transformation Consultant) in Singapore","","datasciencejobs",43,0
"146",144,"DataScienceJobs","Financial Planning and Analysis to Data Science","Hey guys, 
I’ve currently been in the financial planning and analysis role for about 5 years now and I deal with a lot of data, but its rather clean data. I’ve been thinking about pursuing a masters in either statistics or data analytics here in NYC. I want to be able to manipulate larger sets of raw data and make sense of it and create value out of it, hence why I would like to pursue this path. Has anyone done the same switch or recommend any schools in specific? 
I’m currently looking at Baruch (heavily leaning towards Baruch),NYU (MSQM), Fordham, Columbia, Duke (online). I’ve seen a couple of LinkedIn profiles with Data Scientists as their title, having graduated from the previously mentioned schools and the companies they work for seem pretty solid. 
Thanks for reading.","datasciencejobs",44,0
"147",145,"DataScienceJobs","[Hiring] Data Scientists, AI/ML Engineers, Data Architects & SWE’s (Remote)","","datasciencejobs",45,0
"148",146,"DataScienceJobs","[Hiring] Computer Vision SW Engineer in Hillsboro, OR US","","datasciencejobs",46,0
"149",147,"DataScienceJobs","[Hiring] Computer Vision and Deep-Learning Algo Team Lead in Haifa, IL","","datasciencejobs",47,0
"150",148,"DataScienceJobs","[Hiring] Machine Learning Scientist – Machine Translation in Seattle, Washington","","datasciencejobs",48,0
"151",149,"DataScienceJobs","[Hiring] Senior Data Scientist in North Palm Beach, Florida","","datasciencejobs",49,0
"152",150,"DataScienceJobs","[Hiring] Data Science Manager at Center for Policing Equity - Washington, DC","","datasciencejobs",50,0
"153",151,"DataScienceJobs","[Hiring][Internship] 2020 Internship – Data Analytics & Data Science (H2) in Singapore (Marina One)","","datasciencejobs",51,0
"154",152,"DataScienceJobs","[Hiring] Data Scientist Lead in Singapore (Cecil Court)","","datasciencejobs",52,0
"155",153,"DataScienceJobs","DATA scientist, New Grad, ZS associates","Hello,

I received an onsite interview for ZS associates, data scientist role. May anyone ehre please help me as to how should I go abiut preparing it and what to expect?

Thanks!","datasciencejobs",53,1
"156",154,"DataScienceJobs","[Hiring] Manager, Data Science in San Mateo, CA","","datasciencejobs",54,0
"157",155,"DataScienceJobs","Data Science, Analytics - guidance","Anyone willing to offer guidance or point me in the direction of a company hiring data analysts/any analytics role/willing to train a junior data scientist? Career goal is to be a data scientist but I know I'm going to have to start from the bottom. I'm very eager to put in the time and learn, I'm just not having any luck finding a company willing to give me a chance. I'd greatly appreciate any help/advice!

YOE: 2 yrs as an associate technical consultant at SAS (BS Statistics graduate)","datasciencejobs",55,0
"158",156,"DataScienceJobs","[Hiring] Linux Big Data Engineer in London, UK","","datasciencejobs",56,0
"159",157,"DataScienceJobs","[Hiring] Data Scientist II in Peoria, IL, United States","","datasciencejobs",57,0
"160",158,"DataScienceJobs","Startup wants me to pay for their product before they've even hired me","So, I'm through to the last of a 4 stage interview with a media company. One of the founders I spoke to has suggested that I can subscribe to their product (with a 50% discount). To me it seems a little bit stingy that they wouldn't offer it to me for free (at least as a trial). They have mentioned it a few times throughout the process and so I am starting to wonder if they're implying I won't get the job otherwise. From what I can tell, they don't have a huge userbase. Anyone else experienced this?

EDIT
Huge thanks to all the comments. Didn't expect this much response!","datasciencejobs",58,18
"161",159,"DataScienceJobs","[Hiring][Internship] 2020 Summer Data Science Intern in Mountain View, United States","","datasciencejobs",59,0
"162",160,"DataScienceJobs","[Hiring] Senior Data Scientist in Santa Clara, California","","datasciencejobs",60,0
"163",161,"DataScienceJobs","Recent Master graduate with degree in Data Science Looking for roles in the DC Metro Area","Hello all,

I am currently looking for roles in the DC Metro Area. I have applied many times to different companies online and no luck. Can anyone provide any tips to get to, and pass, the interview phases? Thank you!","datasciencejobs",61,4
"164",162,"DataScienceJobs","Data Science Case Interview","Hi everyone! 

I have an interview with ZS associates and would appreciate some insights regarding preparations for data science case interview round. Where can I find relevant material to study the entire process of solving cases from data clenaing to model deployment?

Thank you","datasciencejobs",62,0
"165",163,"DataScienceJobs","[Hiring] Senior Insights Analyst in San Mateo, CA","","datasciencejobs",63,0
"166",164,"DataScienceJobs","[Hiring] PostDoc Researcher – Graph Representation Learning and Explainable AI in Dublin, Ireland","","datasciencejobs",64,0
"167",165,"DataScienceJobs","Data Science Interview Prep for FAANG","Hi,

I want to get advice/suggestion on my study plan for FAANG Data Science interviews. Please go through my study plan comment if you feel I'm missing something important or doing something irrelevant ? I have few specific questions listed at the bottom.

I'm also looking for study buddies, so DM me if you are in same boat and interested in studying together. We can share daily progress, interview each other and most importantly motivate to study lol.

**Background**I'm working as a Data Scientist with a tech consulting firm. My project experience has been around building production ready customer churn/retention models using classification and time series ensembles. Prior to full time role, I did my Masters in Information systems (Focus on statistics and machine learning).

**Study Plan**I had set a 6 months study goal for myself starting from Jan, 2020. On average I study 25-30 hours a week outside my full time job.

**Progress made**I have covered following MOOCs till now

1. Statistics & Probability - Introduction to probability Stats 110x, Harvard [https://projects.iq.harvard.edu/stat110/home](https://projects.iq.harvard.edu/stat110/home)
2. Linear Algebra & Calculus - Mathematics for Machine Learning [https://www.coursera.org/specializations/mathematics-machine-learning](https://www.coursera.org/specializations/mathematics-machine-learning)
3. Machine Learning - [https://mlcourse.ai](https://mlcourse.ai/) (great resource, highly recommended! )
4. **Currently learning**Deep Learning - Andrew Ng course ([https://www.coursera.org/specializations/deep-learning](https://www.coursera.org/specializations/deep-learning))

**Next steps**

1. I'm planning to get more hands on from now. My goal is to compete in atleast 5 Kaggle competitions in next 2 months.
2. I am fairly comfortable with SQL, planning to solve all leetcode right questions before interviews.

**Questions**

1. I'm interested in expanding my NLP skillset. I have done one chatbot project in school but not touched NLP in last one year. I would like to do couple of mini projects with NLP involved which can help me during the interviews. Please suggest, how should I go about it?
2. Considering I'm aiming for FAANG, Data structures/Algos will be part of at least one technical interview. Now the issue is, I haven't taken DSA courses in school (no CS background ), but I'm fairly comfortable with python.How should I prepare for the coding interviews at FAANG? I don't want to jump into leetcode without building fundamentals. Please suggest, effective strategy.
3. I see many Data Scientist at FAANG are only focused on product analytics (SQL, visualization, ETL) and most of Machine Learning work is done by Research Scientists.I had considered Data Scientist, Analytics (FB position) kind of roles but I'm quite inclined towards Machine Learning (mathematics side).Since my background is neither too coding heavy nor too mathematics/research heavy, I want to get suggestions what other steps should I take in order to improve my candidacy as DS at FAANG.

Thanks in advance","datasciencejobs",65,0
"168",166,"DataScienceJobs","[Hiring][Internship] Internship in Natural Language Processing (NLP) in London, UK","","datasciencejobs",66,0
"169",167,"DataScienceJobs","[Hiring] Machine Learning Engineer, Monetization in New York, NY","","datasciencejobs",67,0
"170",168,"DataScienceJobs","[Hiring] Data Engineer in San Francisco, CA","","datasciencejobs",68,0
"171",169,"DataScienceJobs","[Hiring] Data & Analytics Director at Fwd.us - San Francisco, CA","","datasciencejobs",69,0
"172",170,"DataScienceJobs","[Hiring] Machine Learning Lead in Hong Kong (relocation offered)","","datasciencejobs",70,0
"173",171,"DataScienceJobs","[Hiring] Data Scientist (Transport/Food/Marketplace) in Singapore (Marina One)","","datasciencejobs",71,0
"174",172,"DataScienceJobs","Data scientist - renewable energy provider","","datasciencejobs",72,0
"175",173,"DataScienceJobs","[Hiring] Data Scientist / Machine Learning – Twitch Prime in Seattle, Washington","","datasciencejobs",73,0
"176",174,"DataScienceJobs","[Hiring] Junior Data Engineer at Global Strategy Group - New York, NY","","datasciencejobs",74,0
"177",175,"DataScienceJobs","[Hiring] Post-doctoral research Big Data Mineral Exploration in Stanford University, USA","","datasciencejobs",75,0
"178",176,"DataScienceJobs","[Hiring] Data Analyst at CommonLit - Washington, DC","","datasciencejobs",76,0
"179",177,"DataScienceJobs","[Hiring] Post-doctoral research position in Stanford University, USA","","datasciencejobs",77,0
"180",178,"DataScienceJobs","[Hiring] Data Engineer, Analytics at Castlight Health - San Francisco, CA","","datasciencejobs",78,0
"181",179,"DataScienceJobs","[Hiring] Senior Data Scientist, Digital Growth and Commerce (DGC) in Markham, Ontario, CA","","datasciencejobs",79,0
"182",180,"DataScienceJobs","[Hiring] Technical Founder","","datasciencejobs",80,0
"183",181,"DataScienceJobs","[Hiring] Data Engineer – Fraud Detection in New York, USA","","datasciencejobs",81,0
"184",182,"DataScienceJobs","[Hiring] Senior Machine Learning Inference Engineer in Santa Monica, CA, US","","datasciencejobs",82,0
"185",183,"DataScienceJobs","[Hiring] Prediction and Behavior Modeling Research Scientist in Boston, MA, US","","datasciencejobs",83,0
"186",184,"DataScienceJobs","[Hiring] Imaging Scientist – Autonomous Driving in Singapore, Singapore","","datasciencejobs",84,0
"187",185,"DataScienceJobs","[Hiring] Data Engineering Manager in Denver, Colorado","","datasciencejobs",85,0
"188",186,"DataScienceJobs","[Hiring] Senior Decision Scientist in Denver, Colorado","","datasciencejobs",86,0
"189",187,"DataScienceJobs","[Hiring] Machine Learning Engineer, Merchant Intelligence (Remote)","","datasciencejobs",87,0
"190",188,"DataScienceJobs","[Hiring] Enterprise Data – Data Science Solutions Architect, Hong Kong in Hong Kong","","datasciencejobs",88,0
"191",189,"DataScienceJobs","[Hiring] Digital Analytics Manager at Emily's List - Washington, DC","","datasciencejobs",89,0
"192",190,"DataScienceJobs","[Hiring] Sr. Deep Learning Software Architect in Austin, Texas, US","","datasciencejobs",90,0
"193",191,"DataScienceJobs","Data Scientist / Data Engineering Salaries","I'm a Full Stack engineer at the moment (10 yoe) and I'm going to be wrapping up a masters degree focused on data science within the next year.  Consequently I've started looking at salaries for positions in the data science realm, and they all strike me as quite a bit lower than what I'm currently earning, and much lower than what I discuss with recruiters.

I've looked at salaries for Data Engineer, Data Scientist, and Machine Learning Engineer.

I'm currently located in Denver, not interested in moving.

Anyone have any experience for what I should expect a market like Denver to command regarding data science salaries?","datasciencejobs",91,3
"194",192,"DataScienceJobs","[Hiring] Software Engineer, AI & Fairness in Seattle, WA","","datasciencejobs",92,0
"195",193,"DataScienceJobs","Looking for data analyst/entry level data scientist opportunities preferably in California, US (my 2~ years of experience is in the Philippines but I'm a US citizen). Resume feedback/advice is highly appreciated!","","datasciencejobs",93,7
"196",224,"MachineLearning","[P] Deadline extended for the FDA Open Data Adverse Event Anomalies Challenge","The [Gaining New Insights by Detecting Adverse Event Anomalies Using FDA Open Data Challenge](https://go.usa.gov/xdFKk) submission period has been extended to May 18th. Thank you so much to those of you that have already submitted to the challenge. We are extremely excited to review your work! 

If you have any questions about the challenge, please feel free to post them in this thread and we will respond as quickly as possible.","machinelearning",24,1
"197",194,"DataScienceJobs","Only one offer on the table but not sure.","Hi,

I would like to get some opinions from you guys on this. A bit of background is that basically I've been offered a Data Scientist role but it's more in deploying models/ML DevOps than actually doing the model prototyping / proof of concept stuff. My previous role was a Data Engineer / Data Science combo job. I just can't seem to land a pure DS role - perhaps because I only have a Bachelors degree in Maths and not Masters /PhD.

Should I still consider taking it anyway ? It's probably a higher salary than I'll get in a pure DS role with my lack of sufficient education level but I would rather be happy. I also feel the pure DS roles use more soft skills which is really important to me. Should note that I do have a number of interviews for pure DS roles coming up but I won't be able to hold off making a decision on this offer long enough, they need an answer in the next couple of days.

Am I squandering a good opportunity?

TLDR;
- been offered a well paid ML deployment /DevOps role
- background and interest much more lies with maths / stats than Engineering
- can't seem to get a pure Data Science role (model development / experiments and prototyping) although still in interview process for some 
- is role still worth consideration?","datasciencejobs",94,2
"198",195,"DataScienceJobs","Sainsbury's offer","Just wanted some thoughts from someone that has worked for knows someone that's worked for them in a DS role or something in tech. I am happy with the salary offered but need thoughts on the rest. Any thoughts would great. Didn't see much on Glassdoor specifically from Data Scientists.","datasciencejobs",95,0
"199",196,"DataScienceJobs","[Hiring] Data Scientist / Machine Learning – Twitch Prime in Madrid, Spain","","datasciencejobs",96,0
"200",197,"DataScienceJobs","[Survey] Donating of fitness data for public good (All welcome)","Hi there,

I’m about to finish up my master and ask for your support for the survey. It’d be awesome if you could fill out my survey. It should not take longer than 10 minutes. 

[https://www.esurveycreator.co.uk/s/donatingforpublicgood](https://www.esurveycreator.co.uk/s/donatingforpublicgood)

Thank you in advance.","datasciencejobs",97,0
"201",198,"DataScienceJobs","[Hiring] Senior Data Scientist - Shopify's Retail Data Science Team in Toronto, Canada","Hi there,

We're looking for a couple senior data scientists to join Shopify's retail data science team. It's a small team - 6 of us, currently - split between product (focusing on our hardware and software) and go-to-market (sales/marketing/support etc). 

I've been here 2 years myself and can say it's a pretty incredible place to work. We hire from an international talent pool, so don't hesitate to reach out if you're interested.

More details here, or feel free to DM me directly: [https://www.shopify.ca/careers/senior-data-scientist-multiple-roles-e6a7b8](https://www.shopify.ca/careers/senior-data-scientist-multiple-roles-e6a7b8)","datasciencejobs",98,2
"202",199,"DataScienceJobs","[Hiring] Associated Director of Data Engineering at Indivisible - DC or remote","","datasciencejobs",99,0
"203",200,"MachineLearning","[D] Machine Learning - WAYR (What Are You Reading) - Week 83","This is a place to share machine learning research papers, journals, and articles that you're reading this week. If it relates to what you're researching, by all means elaborate and give us your insight, otherwise it could just be an interesting paper you've read.

Please try to provide some insight from your understanding and please don't post things which are present in wiki.

Preferably you should link the arxiv page (not the PDF, you can easily access the PDF from the summary page but not the other way around) or any other pertinent links.

Previous weeks :

|1-10|11-20|21-30|31-40|41-50|51-60|61-70|71-80|81-90|
|----|-----|-----|-----|-----|-----|-----|-----|-----|
|[Week 1](https://www.reddit.com/4qyjiq)|[Week 11](https://www.reddit.com/57xw56)|[Week 21](https://www.reddit.com/60ildf)|[Week 31](https://www.reddit.com/6s0k1u)|[Week 41](https://www.reddit.com/7tn2ax)|[Week 51](https://reddit.com/9s9el5)|[Week 61](https://reddit.com/bfsx4z)|[Week 71](https://reddit.com/d7vno3)|[Week 81](https://reddit.com/f1f0iq)|||||||
|[Week 2](https://www.reddit.com/4s2xqm)|[Week 12](https://www.reddit.com/5acb1t)|[Week 22](https://www.reddit.com/64jwde)|[Week 32](https://www.reddit.com/72ab5y)|[Week 42](https://www.reddit.com/7wvjfk)|[Week 52](https://reddit.com/a4opot)|[Week 62](https://reddit.com/bl29ov)|[Week 72](https://reddit.com/de8h48)|[Week 82](https://reddit.com/f8fs6z)||
|[Week 3](https://www.reddit.com/4t7mqm)|[Week 13](https://www.reddit.com/5cwfb6)|[Week 23](https://www.reddit.com/674331)|[Week 33](https://www.reddit.com/75405d)|[Week 43](https://www.reddit.com/807ex4)|[Week 53](https://reddit.com/a8yaro)|[Week 63](https://reddit.com/bqlb3v)|[Week 73](https://reddit.com/dkox1s)||
|[Week 4](https://www.reddit.com/4ub2kw)|[Week 14](https://www.reddit.com/5fc5mh)|[Week 24](https://www.reddit.com/68hhhb)|[Week 34](https://www.reddit.com/782js9)|[Week 44](https://reddit.com/8aluhs)|[Week 54](https://reddit.com/ad9ssz)|[Week 64](https://reddit.com/bw1jm7)|[Week 74](https://reddit.com/dr6nca)||
|[Week 5](https://www.reddit.com/4xomf7)|[Week 15](https://www.reddit.com/5hy4ur)|[Week 25](https://www.reddit.com/69teiz)|[Week 35](https://www.reddit.com/7b0av0)|[Week 45](https://reddit.com/8tnnez)|[Week 55](https://reddit.com/ai29gi)|[Week 65](https://reddit.com/c7itkk)|[Week 75](https://reddit.com/dxshkg)||
|[Week 6](https://www.reddit.com/4zcyvk)|[Week 16](https://www.reddit.com/5kd6vd)|[Week 26](https://www.reddit.com/6d7nb1)|[Week 36](https://www.reddit.com/7e3fx6)|[Week 46](https://reddit.com/8x48oj)|[Week 56](https://reddit.com/ap8ctk)|[Week 66](https://reddit.com/cd7gko)|[Week 76](https://reddit.com/e4nmyk)||
|[Week 7](https://www.reddit.com/52t6mo)|[Week 17](https://www.reddit.com/5ob7dx)|[Week 27](https://www.reddit.com/6gngwc)|[Week 37](https://www.reddit.com/7hcc2c)|[Week 47](https://reddit.com/910jmh)|[Week 57](https://reddit.com/auci7c)|[Week 67](https://reddit.com/cj0kyc)|[Week 77](https://reddit.com/eb4lxk)||
|[Week 8](https://www.reddit.com/53heol)|[Week 18](https://www.reddit.com/5r14yd)|[Week 28](https://www.reddit.com/6jgdva)|[Week 38](https://www.reddit.com/7kgcqr)|[Week 48](https://reddit.com/94up0g)|[Week 58](https://reddit.com/azjoht)|[Week 68](https://reddit.com/cp1jex)|[Week 78](https://reddit.com/ehbfst)||
|[Week 9](https://www.reddit.com/54kvsu)|[Week 19](https://www.reddit.com/5tt9cz)|[Week 29](https://www.reddit.com/6m9l1v)|[Week 39](https://www.reddit.com/7nayri)|[Week 49](https://reddit.com/98n2rt)|[Week 59](https://reddit.com/b50r5y)|[Week 69](https://reddit.com/cvde5a)|[Week 79](https://reddit.com/entcxy)||
|[Week 10](https://www.reddit.com/56s2oa)|[Week 20](https://www.reddit.com/5wh2wb)|[Week 30](https://www.reddit.com/6p3ha7)|[Week 40](https://www.reddit.com/7qel9p)|[Week 50](https://reddit.com/9cf158)|[Week 60](https://reddit.com/bakew0)|[Week 70](https://reddit.com/d1g1k9)|[Week 80](https://reddit.com/euctyw)||

Most upvoted papers two weeks ago:

/u/aifordummies: [https://arxiv.org/pdf/2002.09571.pdf](https://arxiv.org/pdf/2002.09571.pdf)

Besides that, there are no rules, have fun.","machinelearning",0,17
"204",201,"MachineLearning","[D] Advanced courses update","We have a [PhD level or Advanced courses](https://www.reddit.com/r/MachineLearning/comments/51qhc8/phdlevel_courses/) thread in the sidebar but it's three year old now. There were two other 7-8 month old threads ([1](https://www.reddit.com/r/MachineLearning/comments/cae59l/d_advanced_courses_update/), [2](https://www.reddit.com/r/MachineLearning/comments/cjnund/d_what_are_your_favorite_videos_lectures_on/)) but they don't have many quality responses either. 

So, can we have a new one here?

To reiterate - CS231n, CS229, ones from Udemy etc are not advanced. 

Advanced ML/DL/RL, attempts at building theory of DL, optimization theory, advanced applications etc are some examples of what I believe should belong here, much like the original sidebar post.

You can also suggest (new) categories for the courses you share. :)

- - -

Here are some courses we've found so far. 

ML >> 

* [Learning Discrete Latent Structure - sta4273/csc2547 Spring'18](https://duvenaud.github.io/learn-discrete/)
* [Learning to Search - csc2547 Fall'19](https://duvenaud.github.io/learning-to-search/)
* [Scalable and Flexible Models of Uncertainty - csc2541](https://csc2541-f17.github.io/)
* [Meta-Learning - ICML 2019 Tutorial](https://sites.google.com/view/icml19metalearning) , [Metalearning: Applications to Data Mining - google books link](https://books.google.com/books?id=DfZDAAAAQBAJ&printsec=copyright&redir_esc=y#v=onepage&q&f=false)
* [Fundamentals of Machine Learning Over Networks - ep3260](https://sites.google.com/view/mlons/home)
* [Topics in Deployable ML - 6.S979](https://people.csail.mit.edu/madry/6.S979/)
* [Machine Learning on Graphs - cs224w](http://web.stanford.edu/class/cs224w/)
* [Probabilistic Graphical Methods - 10-708](https://www.cs.cmu.edu/~epxing/Class/10708-20/)
* [Mining Massive Data Sets - cs246](http://web.stanford.edu/class/cs246/index.html)
* [Bayesian Data Analysis](https://github.com/avehtari/BDA_course_Aalto)
* [Advanced Machine Learning Systems - cs6787](https://www.cs.cornell.edu/courses/cs6787/2019fa/) - lecture 9 and onwards discuss hardware side of things
* [Machine Learning for Sequential Decision Making Under Uncertainty - ee290s/cs194](https://inst.eecs.berkeley.edu/%7Eee290s/fa18/resources.html)
* [Interactive Learning - cse599](https://courses.cs.washington.edu/courses/cse599i/20wi/)

ML >> Theory

* [Statistical Machine Learning - 10-702/36-702 with videos](https://www.stat.cmu.edu/~ryantibs/statml/), [2016 videos](https://www.youtube.com/playlist?list=PLTB9VQq8WiaCBK2XrtYn5t9uuPdsNm7YE)
* [Statistical Learning Theory - cs229T/stats231 Stanford Autumn'18-19](http://web.stanford.edu/class/cs229t/)
* [Statistical Learning Theory - cs281b /stat241b UC Berkeley, Spring'14 ](https://www.stat.berkeley.edu/%7Ebartlett/courses/2014spring-cs281bstat241b/)
* [Statistical Learning Theory - csc2532 Uni of Toronto, Spring'20](https://erdogdu.github.io/csc2532/)


DL >>

* [Deep Learning and Bayesian Methods - summer school](http://deepbayes.ru), videos available for 2019 version
* [Deep Unsupervised Learning - cs294](https://sites.google.com/view/berkeley-cs294-158-sp20/home)
* [Deep Multi-task and Meta learning - cs330](https://cs330.stanford.edu/)
* [Topics in Deep Learning - stat991 UPenn/Wharton](https://github.com/dobriban/Topics-in-deep-learning) *most chapters start with introductory topics and dig into advanced ones towards the end. 
* [Deep Generative Models - cs236](https://deepgenerativemodels.github.io/)
* [Deep Geometric Learning of Big Data and Applications](https://www.ipam.ucla.edu/programs/workshops/workshop-iv-deep-geometric-learning-of-big-data-and-applications/?tab=overview)

DL >> Theory

* [Topics Course on Deep Learning - stat212b](http://joanbruna.github.io/stat212b/)
* [Analyses of Deep Learning - stats385](https://stats385.github.io/), [videos from 2017 version](https://www.researchgate.net/project/Theories-of-Deep-Learning)
* [Mathematics of Deep Learning](http://www.vision.jhu.edu/teaching/learning/deeplearning19/)
* [Geometry of Deep Learning](https://www.microsoft.com/en-us/research/event/ai-institute-2019/)

RL >>

* [Deep Reinforcement Learning - cs285](http://rail.eecs.berkeley.edu/deeprlcourse/)
* [Advanced robotics - cs287](https://people.eecs.berkeley.edu/%7Epabbeel/cs287-fa19/)
* [Reinforcement Learning - cs234](https://web.stanford.edu/class/cs234/), [videos for 2019 run](https://www.youtube.com/playlist?list=PLoROMvodv4rOSOPzutgyCTapiGlY2Nd8u)
* [Reinforcement Learning Summer School 2019: Bandits, RL & Deep RL](https://rlss.inria.fr/program/)

Optimization >> 

* [Convex Optimization I - ee364a](http://stanford.edu/class/ee364a/), has quite recent [videos](https://www.youtube.com/playlist?list=PLdrixi40lpQm5ksInXlRon1eRwq_gzIcw) too. 
[Convex Optimization II - ee364b](http://web.stanford.edu/class/ee364b/), [2008 videos](https://www.youtube.com/watch?v=U3lJAObbMFI&list=PL3940DD956CDF0622&index=20)
* [Convex Optimization and Approximation - ee227c](https://ee227c.github.io/)
* [Convex Optimization - ee227bt](https://people.eecs.berkeley.edu/%7Eelghaoui/Teaching/EE227BT/index.html)
* [Variational Methods for Computer Vision](https://vision.in.tum.de/teaching/ws2013/vmcv2013), might not be super relevant to ML but functional optimization is a thing too ;)
* [Advanced Optimization and Randomized Algorithms - 10-801](http://www.cs.cmu.edu/%7Esuvrit/teach/index.html), [videos](https://www.youtube.com/playlist?list=PLjTcdlvIS6cjdA8WVXNIk56X_SjICxt0d)

Applications >> Computer Vision

* [Computational Video Manipulation - cs448v](https://magrawala.github.io/cs448v-sp19/)
* [Advanced Topics in ML: Modeling and Segmentation of Multivariate Mixed Data](http://www.vision.jhu.edu/teaching/learning/learning10/)

Applications >> Natural Language Processing

* [Natural Language Processing with Deep Learning - cs224n](http://web.stanford.edu/class/cs224n/) (* not sure if it belongs here, people working in NLP can help me out)
* [Neural networks for NLP - cs11-747](http://www.phontron.com/class/nn4nlp2020/schedule.html)
* [Natural Language Understanding - cs224u](https://web.stanford.edu/class/cs224u/), [video](https://www.youtube.com/playlist?list=PLoROMvodv4rObpMCir6rNNUlFAn56Js20)

Applications >> 3D Graphics 

* [Machine Learning for 3D Data - cs468](http://graphics.stanford.edu/courses/cs468-17-spring/schedule.html)
* [Geometric Deep Learning](http://geometricdeeplearning.com/) - Not a course but the website links a few tutorials on Geometric DL
* [Deep Learning for Computer Graphics - SIGGRAPH 2019](https://geometry.cs.ucl.ac.uk/creativeai/)
* [Machine Learning for Machine Vision as Inverse Graphics - csc2547 Winter'20](http://www.cs.utoronto.ca/~bonner/courses/2020s/csc2547/) 

---

Edit: Upon suggestion, categorized the courses. There might be some misclassifications as I'm not trained on this task ;). Added some good ones from older (linked above) discussions.","machinelearning",1,76
"205",202,"MachineLearning","[N] Global officials call for free access to Covid-19 research for both humans and AI","# [Global Officials Call for Free Access to Covid-19 Research](https://www.wired.com/story/global-officials-call-free-access-covid-19-research/)

>Government science advisers from the US and 11 other countries Friday called on scientific publishers to make all research related to the coronavirus and Covid-19 more freely available.  
>  
>In an open letter, the advisers, including White House Office of Science and Technology Policy director Kelvin Droegemeier, asked the publishers to make data available through [PubMed Central](https://www.ncbi.nlm.nih.gov/pmc/), a free archive of medical and life science research, or through other sources such as the [World Health Organization's Covid database](https://www.who.int/emergencies/diseases/novel-coronavirus-2019/global-research-on-novel-coronavirus-2019-ncov). The other countries whose officials signed the letter are: Australia, Brazil, Canada, Germany, India, Italy, Japan, New Zealand, Singapore, South Korea, and the UK.  
>  
>The letter calls for publishers to make information available **in both human and machine-readable formats**. In other words, instead of just PDFs of scanned documents, publishers should offer data in formats, such as spreadsheets, that **artificial intelligence software and other computer systems can use.**","machinelearning",2,22
"206",203,"MachineLearning","Neural Networks are Surprisingly Modular","","machinelearning",3,9
"207",213,"MachineLearning","[N] Weekly AI News Podcast hosted by Stanford AI Lab PhDs","Hi there ML subreddit. Just sharing a [link to this podcast we just launched](https://aitalk.podbean.com/) as part of the larger [Skynet Today](https://www.skynettoday.com/) project to clarify to the public what's silly clickbait / overhyped about AI and what is worth paying attention to. Turns out there are a lot of developments with AI out there in the real world every week, so even if you are a fellow researcher / familiar with AI this may be of interest to you!

Open to feedback! (but be gentle, this is our first try at this, need practice)

Oh and, for convenience here's RSS link: [https://feed.podbean.com/aitalk/feed.xml](https://feed.podbean.com/aitalk/feed.xml)  
Working on getting it on ITunes and Google podcasts !  
","machinelearning",13,12
"208",370,"MachineLearningJobs","[Hiring] Engineering Manager, Data Engineering","","machinelearningjobs",70,0
"209",204,"MachineLearning","[Project] Milkdrop AI","Would anyone be interested in creating an open-source machine learning project focused on Milkdrop? The basic idea is that it would analyze a group of Milkdrop presets and then output new presets, preferably with some guidance from the user.

While being an interesting ML challenge that would need to generate valid code, it would also be useful for performers and VJ's.

**A few possible approaches:**  
\--- Generate new Milkdrop presets  
\--- Find similarity between Milkdrop presets  
\--- Walk between groups of Milkdrop presets  
\--- Use the mash-up technique (of the Milkdrop editor) to combine only select sections of code  
\--- Automatically categorize Milkdrop presets  
\--- A preset editor which suggests lines of code

The average Milkdrop preset is about 15 kilobytes and can be opened in a text editor. So the presets are human readable. Also the code of a single preset is organized into groups: *initialization code, per\_frame equations, per\_vertex equations, warp shader, composite shader*.

Open-source Milkdrop projects to build on:  
[https://github.com/projectM-visualizer/projectm](https://github.com/projectM-visualizer/projectm)  
[https://github.com/mvsoft74/BeatDrop](https://github.com/mvsoft74/BeatDrop)

=====

**Dataset curated by hand**

I've spent the last 7 months curating a best-of collection of Milkdrop presets. I went through 52,000 presets and selected only the best 9,795 Milkdrop presets. Includes screenshots of each preset.  
[https://thefulldomeblog.com/2020/02/21/nestdrop-presets-collection-cream-of-the-crop/](https://thefulldomeblog.com/2020/02/21/nestdrop-presets-collection-cream-of-the-crop/)

The presets have been organized into 11 category folders: *Dancer, Drawing, Fractal, Geometric, Hypnotic, Particles, Reaction, Sparkle, Supernova, Waveform, Transition*. Within each of these category folders the presets have been further organized into 183 various subcategory folders.

Full transparency, I'm part of the NestDrop team. I'd like to breath some life into preset creation.  
[http://www.nestimmersion.ca/nestdrop.html](http://www.nestimmersion.ca/nestdrop.html)","machinelearning",4,0
"210",205,"MachineLearning","[R] Is it possible to do research on your own?","I am an undergrad and it's really difficult for me to get into labs. Is it possible for me to read up on the requisite literature and just work on a problem on my own? Will this hurt my chances if and when I try to publish that research?","machinelearning",5,34
"211",206,"MachineLearning","[Discussion] Is MIT Open Course 6.867 Machine Learning still relevant after 14 years?","[https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-867-machine-learning-fall-2006/](https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-867-machine-learning-fall-2006/)

The curriculum was taught in 2006. I was wondering if the concepts would still be relevant today or am I better off using my spare time reading a more recent textbook?

**Here are the topics covered in the course:**

1	Introduction, linear classification, perceptron update rule	

2	Perceptron convergence, generalization	

3	Maximum margin classification	

4	Classification errors, regularization, logistic regression	Problem set 1 out

5	Linear regression, estimator bias and variance, active learning	

6	Active learning (cont.), non-linear predictions, kernals	Problem set 1 due

7	Kernal regression, kernels	Problem set 2 out

8	Support vector machine (SVM) and kernels, kernel optimization	

9	Model selection	Problem set 2 due

10	Model selection criteria	

11	Description length, feature selection	Problem set 3 out 3 days before Lec #11

12	Combining classifiers, boosting	

13	Boosting, margin, and complexity	

14	Margin and generalization, mixture models	

15	Mixtures and the expectation maximization (EM) algorithm	

16	EM, regularization, clustering	Problem set 4 due

17	Clustering	

18	Spectral clustering, Markov models	Problem set 5 out

19	Hidden Markov models (HMMs)	

20	HMMs (cont.)	

21	Bayesian networks	

22	Learning Bayesian networks	Problem set 5 due

23	Probabilistic inference","machinelearning",6,28
"212",207,"MachineLearning","[D] Is there ever a reason to use multiple activation functions in a deep neural network?","So as the title says. I'm learning about neural networks and thought about if there ever is a reason to use multiple activation functions. Either a different function per layer or even different functions in the same layer. I tried googling it but i couldn't find a clear answer.

\*\*EDIT\*\* Mods feel free to remove if this doesn't belong in this forum.","machinelearning",7,23
"213",208,"MachineLearning","[R] Unshuffling Data for Improved Generalization","","machinelearning",8,3
"214",209,"MachineLearning","[D] Can TF-IDF be replaced by modern transformers?","I'm trying to tackle the problem of authorship attribution. What I've found so far is that solutions that work pretty well are the solutions based on TF-IDF, n-grams and BoW (CountVectorizer). I hope to raise the accuracy by deploying BERT or any of existing transformers. Can any of transformers be a substitute for TF-IDF? I'd like to combine the word embeddings with SVM to raise the accuracy but struggle to do so.
I also had a question about possible architectures for this task. Will LSTM fit here?","machinelearning",9,3
"215",210,"MachineLearning","[Research] [Project] Memory Vs Depth in Neural Networks: exploratory comparison","A small exploratory experiment I did  on the trade-off between memory and depth in neural networks. I tried to  make case that a reasoning network can perform well on static data,  compared with a feed forward network. Would love to hear your feedback  and comments about it.

[https://sites.google.com/view/omar-mohammed/experiments-on-the-side/memory-vs-depth-in-neural-networks-exploratory-comparison?authuser=0](https://sites.google.com/view/omar-mohammed/experiments-on-the-side/memory-vs-depth-in-neural-networks-exploratory-comparison?authuser=0)","machinelearning",10,0
"216",211,"MachineLearning","[N] Fast and Easy Infinitely Wide Networks with Neural Tangents - New open-source software library","[https://ai.googleblog.com/2020/03/fast-and-easy-infinitely-wide-networks.html](https://ai.googleblog.com/2020/03/fast-and-easy-infinitely-wide-networks.html)

>One of the key theoretical insights that has allowed us to make progress in recent years has been that increasing the width of DNNs results in more regular behavior, and makes them easier to understand. A number of recent results have shown that DNNs that are allowed to become infinitely wide converge to another, simpler, class of models called [Gaussian processes](https://distill.pub/2019/visual-exploration-gaussian-processes/). In this limit, complicated phenomena (like Bayesian inference or gradient descent dynamics of a convolutional neural network) boil down to simple linear algebra equations. \[...\]  


>Unfortunately, deriving the infinite-width limit of a finite network requires significant mathematical expertise and has to be worked out separately for each architecture studied. Once the infinite-width model is derived, coming up with an efficient and scalable implementation further requires significant engineering proficiency. Together, the process of taking a finite-width model to its corresponding infinite-width network could take months and might be the topic of a research paper in its own right.  
>  
>To address this issue and to accelerate theoretical progress in deep learning, we present [Neural Tangents](https://arxiv.org/abs/1912.02803), a [new open-source software library](https://github.com/google/neural-tangents) written in JAX that allows researchers to build and train infinitely wide neural networks as easily as finite neural networks.","machinelearning",11,36
"217",212,"MachineLearning","Data visualisation in Python for NLP projects [R]","Hi,

I am looking for any interesting Python libraries for visualisation of NLP projects. I have found and used scattertext but I am looking for something more interactive. Any help appreciated.","machinelearning",12,7
"218",371,"MachineLearningJobs","[Hiring] Research Engineer – Artificial Intelligence","","machinelearningjobs",71,0
"219",372,"MachineLearningJobs","[Hiring] Software Engineer, Machine Learning – New York","","machinelearningjobs",72,0
"220",214,"MachineLearning","[D] Instance segmentation of people","Hi!
I am approaching the instance segmentation field to detect people in real-time. I have found these architectures:
- YOLACT / YOLACT++: https://github.com/dbolya/yolact
- Centermask / Centermask2: https://github.com/youngwanLEE/centermask2

But they are both in PyTorch. I will eventually need to deploy my model on a server and I have read that TensorFlow/Keras is a better solution for production machine learning. Also, they are trained on COCO (80 objects, including person), but I only need to detect people.
So my concerns are:
- How do you handle the PyTorch -> Tensorflow/Keras conversion? Is it better to rewrite the code (spending a lot of time) or is there a way to easily convert the model from one format to the other?
- Do you think that retraining the model only on the person class will improve the accuracy? Or is it useless?","machinelearning",14,3
"221",215,"MachineLearning","[R] Out-of-Distribution Generalization via Risk Extrapolation (REx)","","machinelearning",15,2
"222",216,"MachineLearning","[D] Researcher/Professor possibly using Wikipedia for personal gain","I was trying to read about Natural Gradient Descent today, and found the Wikipedia section[1] to read just like an ad for a different technique[2]. I thought to myself that surely it must be a big deal to be in the Wikipedia article of SGD alongside RMSProp and Adam, but it turned out to be a paper for 2015 with 21 citations (not that citations are the measure of good science, but the maximally optimistic light would still be that it would be too early to include that along the canonical optimization algorithms of the field).

This seemed fishy to me so I did some digging. It was added to the Wikipedia article on Febuary 2017 [3], which at the time, the paper appears to have had 0 citations[4], by user Vp314 [5] on Wikipedia, which also happened to be the author's gmail username [6]. Furthermore the only edits that user has done on Wikipedia are related to adding their technique to the Wikipedia page on SGD [5]: one to add the original section[7], one to make a minor correction, and one to re-add that section[8] (in April 2018) after it was deleted with the comment ""Removed a recent extension which has been hardly cited by anyone in the academic community. Its appearance in Wikipedia made it look like an established technique, which is not"" [9].

My instincts are what this person has done is wrong and taking advantage of Wikipedia, but I would love to hear some other perspectives (and maybe get a little less angry). Is there a defensible reason to do so?

[1] https://en.wikipedia.org/wiki/Stochastic_gradient_descent#Natural_Gradient_Descent_and_kSGD

[2] https://arxiv.org/abs/1512.01139

[3] https://en.wikipedia.org/w/index.php?title=Stochastic_gradient_descent&diff=prev&oldid=765131100

[4] https://scholar.google.com/scholar?start=0&hl=en&as_sdt=0,5&sciodt=0,5&cites=14583315928670424345&scipsc=

[5] https://en.wikipedia.org/wiki/Special:Contributions/Vp314

[6] https://arxiv.org/pdf/1512.01139.pdf

[7] https://en.wikipedia.org/w/index.php?title=Stochastic_gradient_descent&diff=prev&oldid=765131100

[8] https://en.wikipedia.org/w/index.php?title=Stochastic_gradient_descent&diff=prev&oldid=837946813

[9] https://en.wikipedia.org/w/index.php?title=Stochastic_gradient_descent&diff=prev&oldid=831521717","machinelearning",16,70
"223",217,"MachineLearning","Machine learning to find a cure for the corona virus? [Discussion]","I was wondering if it would be possible to use machine learning to find a cure for the corona virus. By possibly using the DNA (and corresponding translation into proteins) of different know viruses accompanied by the antibodies known to neutralize them as the training data. Then using the obtained neural network to find antibodies for the corona virus. Are there any papers or areas of research that delve further into this? If so I would love to hear about them. Also what is your opinion, is something like this feasible?","machinelearning",17,1
"224",218,"MachineLearning","[Discussion] Multi Arm Bandit fed with batched data","Hello,

I have been reading about MAB to apply it to my use case which is digital advertising.
I have 5 adverts that I'm showing to people and I'm collecting the events of each adverts (I collect the number of clicks and impression for each ads in real time)
 
I wanted to use something like MAB to smartly start showing more and more the advert that performs the best the based on the number of clicks and impression (CTR)

So it looks like MAB can be a perfect fit for this, however after reading a whole bunch of paper on MAB and its algorithm they all have in common that the the algo process every single impression one by one.

Since I'm collecting a lottt of data I'm aggregating it in real time and spitting the number of clicks and impression for each advert every 5 minutes (Sliding window style) I don't know if particular click has yielded a click or not.

Now... let's take for example the UCB-1 algorithm. In all the paper I have read the algo has in input a tab with all the Arms and a '1' or a '0' as reward.
In my case I do not have the break down of if a particular 'impression' resulted in a click or not. 
All what I have is the total number clicks and impression over a certain period of time.

So my question is, is it possible to use aggregated (batched?) data with algorithm such as UCB-1, Thompson Sampling etc.. to solve my problem? 
Would it be correct to 'loop' through the total number of impression and 'guess' the reward by for example taking a binomial value using the CTR of an ad? 

At the moment my algo looks roughly like this:


    totalImpression = the sum of all the ads impression combined
    for impression in range(0, totalImpression):
       ad = 0
       max_upper_bound = 0
       for i in range(0, ads):
           if (numbers_of_selections[i] > 0):
               avg_ctr = sums_of_reward[i] / numbers_of_selections[i]
               delta_i = math.sqrt(2 * math.log(impression+1) / numbers_of_selections[i])
               upper_bound = avg_ctr + delta_i
           else:
               upper_bound = 1e400
           if upper_bound > max_upper_bound:
               max_upper_bound = upper_bound
               ad = i
       ads_selected.append(ad)
       numbers_of_selections[ad] += 1
       trueCTROfTheSelectedAd = the true CTR calculted using the input observed data for the selected ad
       reward = int(np.random.binomial(1, trueCTROfTheSelectedAd, size=1))`
       sums_of_reward[ad] += reward
       total_reward += reward

the ad that got the highest reward is the one that will be shown to the people


Thanks!","machinelearning",18,8
"225",219,"MachineLearning","[P] Request-based autoscaling for inference workloads","We've just released [Cortex v0.14](https://github.com/cortexlabs/cortex), which includes a new event-based autoscaler that scales based on how many incoming requests your API is receiving.

I wrote up a report on how we built it and the many failed first-tries: [https://towardsdatascience.com/implementing-request-based-autoscaling-for-machine-learning-workloads-feb41572956](https://towardsdatascience.com/implementing-request-based-autoscaling-for-machine-learning-workloads-feb41572956)

Counting requests is, surprisingly, very hard.","machinelearning",19,4
"226",220,"MachineLearning","[D] Activation Function as Attention","Hi, 

Today I realized that neural activation function is a speical kind of attention machanism. For sigmoid, it amplified the center part (near zero) . For relu, it focus on the right part (>0).  Attention is all you need! Just concept level improvement, but maybe we can make use of this view in future.","machinelearning",20,4
"227",221,"MachineLearning","[D] Question Answering for Semi-Structured text.","I am currently working on a system to generate answers for customer questions based on the help topic documents I have. The documents are not highly structured but rather have a weak structure. Topics can have subtopics and each topic/subtopic would have a title and some text associated with them. The task is to produce a specific answer given a question. The solution should be reusable i.e the documents from which these answers need to be extracted could change based on the customer. 

I have looked into knowledge base based questions answering systems but those knowledge bases are quite structured(triplets of (subject, predicate, and object).  

I am currently looking for a technique which takes advantage of this weak structure and also is not tightly coupled with document set. 

Any references or papers related to this are highly appreciated. 

TIA.","machinelearning",21,0
"228",222,"MachineLearning","[D] Deep RL for highly stochastic environments","Is there any deep RL algorithm focusing on (or working well in) highly stochastic environments? Or is there any paper discussing the limitation of current approaches? Both DQN and double DQN seem to fail in stochastic environments and most benchmark simulation environments are not stochastic.","machinelearning",22,7
"229",223,"MachineLearning","[N] Paperspace is offering substantial free GPU resources to any team working on COVID-19 related research.","DM for more info.","machinelearning",23,9
"230",373,"MachineLearningJobs","[Hiring] Software Engineer, Machine Learning","","machinelearningjobs",73,0
"231",225,"MachineLearning","help with COVID19? [D]","Hi, fellow ML/DL researcher here. Is there any way for us to help if our labs/companies/... etc are not involved in the efforts? Are there public datasets or something we can play with that could contribute to inventing a cheaper/faster diagnostic tool?","machinelearning",25,6
"232",226,"MachineLearning","[P] StyleGAN2 notes on training and latent space exploration","[This post](https://medium.com/@5agado/stylegan-v2-notes-on-training-and-latent-space-exploration-e51cf96584b3) is a collections of notes and results collected while training multiple StyleGAN models and exploring the learned latent space. It is meant to provide insight or starting point for discussions for other people out there with similar interests and intents","machinelearning",26,1
"233",227,"MachineLearning","[P] Need to classify text into a sequence of hierarchical labels. Essentially piping output from fastText into a short RNN. Has this pattern been explored before? Are there papers or examples I can look into?","Let me clarify this with an example of an imagined script snippet classifier input and output:

in/out structure = snippet -> (category, subcategory, snippet label, language, region reference)

input:  ""folks heres the story all about how my life got flipped....\[continues\]""   
output: (""Story"", ""monologue"", ""musical monologue"", ""english"", ""philadelphia"")

I basically want to use some simple n-gram linear classifier like fastText to softmax generate the category, then link that answer to the labels applied to subsequent positions, like with LSTM cells or something.

Ever seen anything like this?  Thanks guys!

&#x200B;

&#x200B;

Some additional details/constraints (feel free to skip):  
The sequence isn't purely hierarchal, otherwise I could just predict the last label and infer the path.  The problem is that it's not an acyclic hierarchy.  For example, another valid output might have been (""Song"", ""monologue"", ""musical monologue"", ""english"", ""philadelphia"").  It \*is\* still a sequence semantically as certain sequence patterns would not be valid.  For example (Story > product description > feature list) would never be accepted and should have been labeled as (Non narrative > product description > feature list).  choices in one position of the sequence constrain choices in other positions.","machinelearning",27,4
"234",228,"MachineLearning","[D] Question on latent space clustering methods of Autoencoders for anomaly detection","Autoencoders are sometimes used for anomaly detection. Two methods used are loss difference (taking the reconstruction error and using that to determine if it is an anomaly, which I understand) and latent space clustering methods, which I do not understand.

In latent space clustering, you train the AE on the inlier data only, then train some second model on the **latent representations** of the outliers vs the latent representations of the standard data, which theoretically should be different and easy to classify, even with some linear model. My question for this is, why would this work, and is this a reliable technique? 

When encoding some signal (lets say we're working with images of peoples' faces, and the outlier pictures have some yellow dot in the background), the best encoding format would learn the variations of the features of just the inlier data - so for this example it would encode things like skin tone, eye location, etc. of just the regular faces. If we are learning just the variations in the inlier data, isn't there no real reason for the latent space of the outliers to be any different than the latent space of the inliers, since the varying factors of the outliers are not learned at all? Essentially what I can't wrap my head around is that the factor that makes a signal an outlier does not have to be a varying factor in the inlier group, and thus there doesn't really need to be a reason to learn it at all. 

This is actually the reason that loss difference methods work, where the AE learns the structure of the inlier data and fails to reconstruct some outlier properly, and when the reconstruction error spikes, one can properly conclude that there is an outlier.

Even if the outlier factor has something to do with a learned inlier feature (example, large eyes taking up 50% of head in outlier group vs inliers being regular headshots), isn't there still no real reason the latent space should be any different? The sub-signal that makes the entire signal (lets say sub-image of an image) an outlier still just gets thrown through the standard calculation for an inlier signal, and can output as whatever - there is no reason the latent representation specifically has to be distinct from the inlier representation for this, especially when it hasn't trained on this trait before. It can just ""fold"" this over the inlier manifold and project as just a regular point just fine. How come I see these methods come around sometimes? Thanks for the help.","machinelearning",28,4
"235",229,"MachineLearning","[P] AI for AI (artificial insemination) — Deep Topological Analysis for sensor data","Hi there,

We've built a system to analyse complex data from user activities, sensors or texts using Deep Learning and Topological Data Analysis. Working with a number of clients I've faced a very interesting use case for time-series segmentation. Here I wanted to share our findings and results with you. An article Towards Data Science: [https://towardsdatascience.com/ai-for-ai-artificial-insemination-deep-topological-analysis-for-sensor-data-9fceccb59bf](https://towardsdatascience.com/ai-for-ai-artificial-insemination-deep-topological-analysis-for-sensor-data-9fceccb59bf)

Comments and questions are welcome ;)","machinelearning",29,3
"236",230,"MachineLearning","[D] How long does it normally take you to fully understand a research paper?","The title is pretty much the post.

Reading research papers is pretty much a daily part of my routine, but sometimes I really doubt my own self because it takes me so long just to understand one paper, whereas I see other people who can read it once (maybe even skim through it) and get the hang of what's going on.

Sometimes it takes me even a full day reading one paper.

Does anyone else struggle with this? What are some tips that you could give me? Thanks.","machinelearning",30,15
"237",231,"MachineLearning","[R] Using a thousand optimization tasks to learn hyperparameter search strategies","","machinelearning",31,2
"238",232,"MachineLearning","[D] Finding the most similar documents - Different approaches","Hi,   
Task:   
Given a large number of documents (>1million) each with >9k words, find similar ones given a document. For example, given a document A it has to find 10 similar documents to A. NO labels are given, completely unsupervised. 

&#x200B;

Here is a couple of ways I was thinking of going about it: 

1) Generate TF-IDF vectors for each document, find similar ones to A with cosine similarity/euclidian distance. 

2) Using doc2vec generating embeddings and again find the similarity. 

3) Using something like BERT to generate the embeddings and finding similarity. The problem here I believe is that BERT can only take in 510 words at a time, bu the docs contain on average >9k. 

&#x200B;

What do you'll think is the best approach? What other approaches could I try?   


PS: This is for a production system, so the time taken to compute has to be >10s on a small-mid machine.","machinelearning",32,8
"239",233,"MachineLearning","[R] More Efficient NLP Model Pre-training with ELECTRA","[https://ai.googleblog.com/2020/03/more-efficient-nlp-model-pre-training.html](https://ai.googleblog.com/2020/03/more-efficient-nlp-model-pre-training.html)","machinelearning",33,4
"240",243,"MachineLearning","[D] anyone here doing MMM (marketing mix media)?","Hi all. I work on the data team of a media science department of a big company. I'm doing some basic data engineering, writing SQL and building ETLs in Scala + EMR Spark.

I took graduate level statistics and have done some regressions - multivariate, logistic, etc. but haven't done in production. I get the basics of the business side of MMM but I would love to learn the modeling of it.

Can anyone describe what specifically I need to know for MMM, in addition to running regressions? I am thinking this would get some good experience.","machinelearning",43,0
"241",267,"MachineLearning","[Discussion] Does Apple Music's lyrics feature use machine learning?"," The actual lyrics can be copied off of some lyrics site. But the fact that it highlights the progress word by word is amazing to me. Surely, this is not done manually by an employee, considering the huge amount of songs?","machinelearning",67,6
"242",234,"MachineLearning","[D] Exploring Gender Imbalance in AI: Numbers, Trends, and Discussions","UK-based innovation foundation Nesta conducted a large-scale analysis of gender diversity in AI research using publications from arXiv and estimated that only 13.83% of AI paper authors are women, and the proportion of AI papers co-authored by at least one woman has not improved since the 1990s.

As of 2015, women made up only 18% of computer science majors in the US — a decline from a high of 37% in 1984, according to a National Academies of Sciences, Engineering, and Medicine 2018 report.

Why are the numbers so alarming? Does that mean existing methods have all failed to contend with the uneven distribution of power?

Read more: [Exploring Gender Imbalance in AI: Numbers, Trends, and Discussions](https://medium.com/syncedreview/exploring-gender-imbalance-in-ai-numbers-trends-and-discussions-33096879bd54)

To celebrate Women's History Month and highlight the contributions of women in the AI industry, we are inviting female AI researchers to share their recent research works with our global readers. Share your research simply by clicking [here](http://bit.ly/33aC4jw). : )","machinelearning",34,2
"243",235,"MachineLearning","[D] What would you call object detection in time series","I'm currently looking for deep learning methods that do object detection on time series. This means I want to find sections in a time series that correspond to a certain class, without simply sliding a classifier over all time steps. Until now I was not able to get the right search terms for google scholar. Does anyone of you have a clue what to look for?","machinelearning",35,15
"244",236,"MachineLearning","[D] TensorFlow now has a certification. Do you think that'd help people with future employment or graduate admissions? Why, or why not?"," [https://www.tensorflow.org/certificate](https://www.tensorflow.org/certificate)","machinelearning",36,5
"245",237,"MachineLearning","[D] Chinese Researchers Use CNNs to Classify 3000-Year-Old Oracle Bone Scripts","A group of Chinese researchers applied a multi-regional convolutional neural network (CNN) to classify oracle bone rubbings. Their study has been [published](https://ieeexplore.ieee.org/document/9004518/keywords#keywords) by journal *IEEE Computer Graphics and Applications*.

Read more: [Chinese Researchers Use CNNs to Classify 3000-Year-Old Oracle Bone Scripts](https://medium.com/syncedreview/chinese-researchers-use-cnns-to-classify-3000-year-old-oracle-bone-scripts-b3404e3771d7)","machinelearning",37,4
"246",238,"MachineLearning","[D] Looking for 1-2 people to form a reading group for ESL","Looking for 1-2 people to form a reading group for ESL

Hey all, I'm looking for 1-2 people, who already have a sufficiently strong mathematical background to start reading Elements of Statistical Learning, and are interested in forming a reading group to go through half to three quarters of the book this upcoming summer (starting ~10 may or so) with a commitment level of about 5-10 hours a week.

I believe a small group would be more effective in holding one another accountable, and more efficient in facilitating discussion.

Let me know if you are interested!

EDIT: If I had to choose between depth and breadth, I would choose depth","machinelearning",38,17
"247",239,"MachineLearning","[D] OCR for financial documents","Financial institutions require a ton of man power to do simple tasks like data entry. This not only consumes resources, but also is a bottleneck for following processes. In this blog we discuss how modern techniques like deep learning and OCR can help automate the process.

&#x200B;

[https://nanonets.com/blog/ocr-financial-documents/?utm\_source=reddit&utm\_medium=social&utm\_campaign=ocr-financial-document&utm\_content=ml](https://nanonets.com/blog/ocr-financial-documents/?utm_source=reddit&utm_medium=social&utm_campaign=ocr-financial-document&utm_content=ml)","machinelearning",39,0
"248",240,"MachineLearning","[Project] I've compiled weather/climate date for the confirmed COVID19 infection sites, if anyone wants it","Hello there.

 

I'm not a machine learning guy (perhaps one day!), but it was suggested to me that some of you may want a crack at this data.

Using JHU's time\_series\_19-covid-Confirmed.csv csv format, and going back to 1/1/20, using Dark Sky's API, I went and grabbed the following pieces of data for each day for each site:

* Cloud cover
* Dew point
* Relative humidity
* Ozone
* Precipitation probability
* Air pressure
* Sunrise time
* Sunset time
* Max temperature
* Min temperature
* UV index
* Wind speed

These are all recorded as CSV files in the /csv folder.

If any of you want to use this to take a crack at trying to figure out if any of these factors play into the spread of the virus, by all means, please do so. You can correlate my values with JHU's numbers in terms of rate of spread and all that from their repository that I branched off of. The big caveat here is that I'm just a guy, and none of my data have been audited or validated or anything, but at least it's something, I guess.

&#x200B;

 [Here is my git repository](https://github.com/imantsm/COVID-19)","machinelearning",40,57
"249",241,"MachineLearning","[D] SimCLR PyTorch implementation","Recently, the SimCLR framework was proposed by Chen et al., a contrastive unsupervised learning algorithm which does not need complex architectures or a memory bank to learn useful visual representations.

I have implemented the paper in PyTorch, which allows anyone with an off-the-shelf GPU to train and evaluate the model. When using a larger ResNet model and larger batch sizes, mixed-precision training can be used (still evaluating its impact on final results)

[https://github.com/Spijkervet/SimCLR](https://github.com/Spijkervet/SimCLR)","machinelearning",41,17
"250",242,"MachineLearning","[N] ML in Portfolio Optimisation & Backtest Overfitting: MlFinLab 0.7.0","# ML in Portfolio Optimisation & Backtest Overfitting

We have just released [MlFinLab](https://github.com/hudson-and-thames/mlfinlab) version 0.7.0 which now includes the following:

## Portfolio Optimisation:

We expand on the family of Hierarchical Risk Parity optimizers by including the HERC and HCAA algorithms by Thomas Raffinot.

1. [Raffinot, Thomas, The Hierarchical Equal Risk Contribution Portfolio (August 23, 2018)](https://ssrn.com/abstract=3237540)
2. [Raffinot, Thomas, Hierarchical Clustering Based Asset Allocation (May 2017)](https://ssrn.com/abstract=2840729)
3. [Python implementation](https://mlfinlab.readthedocs.io/en/latest/implementations/portfolio_optimisation.html#hierarchical-clustering-asset-allocation-hcaa)

## Backtest Statistics

In order to fight backtest overfitting we have [implemented](https://mlfinlab.readthedocs.io/en/latest/implementations/backtest_statistics.html) the following:

* Probabilistic Sharpe Ratio
* Deflated Sharpe Ratio
* Minimum Track Record Length

**The Sharpe Ratio Efficient Frontier** *by* David H. Bailey *and* Marcos Lopez de Prado [available here](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1821643). *It provides a deeper understanding of Sharpe ratios implemented and minimum track record length.*

A big thank you to [Aditya Vyas](https://www.linkedin.com/in/aditya1702/) and [Illya Barziy](https://www.linkedin.com/in/illya-barziy-ba9292b1/), respectively.","machinelearning",42,0
"251",266,"MachineLearning","[N] Due to concerns about COVID-19, ICLR2020 will cancel its physical conference this year, and instead host a fully virtual conference.","From their [page](https://iclr.cc/Conferences/2020/virtual):

# ICLR2020 as a Fully Virtual Conference

Due to growing concerns about COVID-19, ICLR2020 will cancel its physical conference this year, instead shifting to a fully virtual conference. We were very excited to hold ICLR in Addis Ababa, and it is disappointing that we will not all be able to come together in person in April. This unfortunate event does give us the opportunity to innovate on how to host an effective remote conference. The organizing committees are now working to create a virtual conference that will be valuable and engaging for both presenters and attendees. 

Immediate guidance for authors, and questions about registration and participation are given below. We are actively discussing several options, with full details to be announced soon. 

## Information for Authors of Accepted Papers

All accepted papers at the virtual conference will be presented using a pre-recorded video. 

All accepted papers (poster, spotlight, long talk) will need to create a 5 minute video that will be used during the virtual poster session.

In addition, papers accepted as a long-talk should create a 15 minute video.

We will provide more detailed instructions soon, particularly on how to record your presentations. In the interim, please do begin preparing your talk and associated slides. 

Each video should use a set of slides, and should be timed carefully to not exceed the time allocation. The slides should be in widescreen format (16:9), and can be created in any presentation software that allows you to export to PDF (e.g., PowerPoint, Keynote, Prezi, Beamer, etc). 

## Virtual Conference Dates

The conference will still take place between April 25 and April 30, as these are the dates people have allocated to attend the conference. We expect most participants will still commit their time during this window to participate in the conference, and have discussions with fellow researchers around the world. 

## Conference Registration Fee

The registration fee will be substantially reduced to 50 USD for students and 100 USD for non-students. For those who have already registered, we will automatically refund the remainder of the registration fee, so that you only pay this new reduced rate. Registration provides each participant with an access code to participate in sessions where they can ask questions of speakers, see questions and answers from other participants, take part in discussion groups, meet with sponsors, and join groups for networking. Registration furthermore supports the infrastructure needed to host and support the virtual conference. 

## Registration Support 

There will be funding available for graduate students and post-doctoral fellows to get registration reimbursed, with similar conditions to the Travel Support Application. If you have already applied for and received a travel grant for ICLR 2020, you will get free registration for ICLR 2020. The Travel Application on the website will be updated soon, to accept applications for free registration, with the deadline extended to April 10, 2020. 

## Workshops

We will send details for workshops through the workshop organisers soon, but it is expected that these will follow a similar virtual format to the main conference.

https://iclr.cc/Conferences/2020/virtual","machinelearning",66,57
"252",244,"MachineLearning","[P] Chapter 8 Model Serving and Monitoring","The draft of Chapter 8 Model Serving and Monitoring of my upcoming Machine Learning Engineering book is now online. It discusses such aspects as properties of the model serving runtime, model serving modes, best practices of model serving in real-world, and model monitoring.

It's an early draft, so please leave your comments and suggestions directly in the chapter file (a shared PDF on dropbox). Drafts of all chapters available [on the book's website](http://www.mlebook.com/) and will remain there and be updated after the publication.

The book is distributed on the ""read first, buy later"" principle which means that anyone can read the book online, on the book's own website, and then buy it if the reading was pleasant and the book was useful.

I look very much for volunteers to read it and suggest corrections and improvements.

https://preview.redd.it/8tqyfxpty5m41.png?width=900&format=png&auto=webp&s=d25553500449aaca11cdc1efc74d4d2b1abee88a","machinelearning",44,6
"253",245,"MachineLearning","[News] M5 Forecasting Competition","Hi,

Last week 5th edition of Makridakis Forecasting Cometitions (https://en.wikipedia.org/wiki/Makridakis_Competitions) started on Kaggle. 
There are actually two of them: point forecast accuracy
https://www.kaggle.com/c/m5-forecasting-accuracy/overview
and prediction intervals (quantiles)
https://www.kaggle.com/c/m5-forecasting-uncertainty/overview

The data is a bit sparse (retail) and with many levels of hierarchy. The first (""accuracy"") competition requires fully coherent forecast across all the hierarchy levels.

The pool of money is $100K and there is almost 4 months to go. Good luck!","machinelearning",45,0
"254",246,"MachineLearning","[D] Variational Autoencoders - why do we sample from the prior?","I had a small question about Variational Autoencoders (VAEs). **After** we have trained a VAE model, why do we sample from the prior (usually zero-mean unit-std gaussian) instead of sampling from the aggregated posterior to generate examples.

I know that calculating the aggregated posterior would require getting the expectation from lots of p(z|x) but wouldn't this be the right thing to do?

Thanks!

Edit: For clarity by aggregated posterior I'm referring to q(z) = E(q(z|x)) where the expectation is under x~p(data).","machinelearning",46,25
"255",247,"MachineLearning","[D] What are some of the challenges you face when solving real-world computer vision problems?"," 

Engineers/Researchers who work on computer vision tasks that run inference on real-world data (e.g. images from a user's mobile phone) - what are some of the challenges you currently face?

Here's a poll to make things easier (I'll share the results here later).  
[https://forms.gle/aCeRY7eojU3AGTx8A](https://forms.gle/aCeRY7eojU3AGTx8A)

Also, feel free to start a discussion below if you want feedback/solutions.","machinelearning",47,2
"256",248,"MachineLearning","[R] Can I teach a chatbot to learn what an idea or concept is?"," I’ve been thinking a lot about NLP and deep learning in chatbots lately and have a question that I can’t get out of my head so here it goes. One of the main problems in machine learning is that you are very restricted by your input data and you have to feed your algos a lot of data to generate good conversation flow but even some of the best examples I’ve seen have very obvious flaws and hard-coded rules that drive conversations.

I want to understand whether it’s possible to build a general chatbot that you can talk to about anything without having to feed in loads of data about different topics but instead allow the AI to learn new concepts from the user (if you’ve seen the movie ‘Her’, you’ll get where I’m going with this). By concepts, I mean general ideas and definitions of ideas like the concept of a telephone or love. However, I don’t mean AGI, but simply an ability for the user to train the algorithms understanding of a concept.

I’ve been playing around with the Replika app which has done a pretty good job, but they use an RNN at the heart of their chatbot and some hard-coded conversation rules which restrict the adaptability to the user of their bot.

**So my idea is as follows:**

Aside from your RNN/ANN layers which you’ll need for a good chatbot no doubt, could you build in segues for the AI to develop conceptual understanding of topics based on the user’s definition of these concepts?

I’ve mapped out some high-level components that could be used to form an understanding of a concept that NLP and RNNs can then use in later conversations (maybe some topic modelling, clustering, graph analysis to define links between concepts will help).

By defining the purpose, application, environment, boundaries and motivations of a concept which the bot would ask the user questions about, you can mimic a bot's artificial understanding.

&#x200B;

https://preview.redd.it/t4k35tclybm41.jpg?width=1854&format=pjpg&auto=webp&s=af05902c02e618b33cdee39d0e914b54604e327d

 So, in an example I would see this working as follows: 

&#x200B;

https://preview.redd.it/knwb5sznybm41.jpg?width=1858&format=pjpg&auto=webp&s=91fa869c6a7e030b8982679383e19f1eb74a5963

 Any thoughts whether this could work?","machinelearning",48,5
"257",249,"MachineLearning","[R] Lagrangian Neural Networks","","machinelearning",49,3
"258",250,"MachineLearning","[R] Creating task-agnostic embeddings for nodes in a (Knowledge) Graph","&#x200B;

[Node embeddings created with RDF2Vec](https://preview.redd.it/8tjvnvwqk7m41.png?width=839&format=png&auto=webp&s=07a52cda3f4cfdfdde03ce1de185f8df573ba027)

We recently released pyRDF2Vec 0.0.3!

&#x200B;

RDF2Vec is an unsupervised technique that builds further on Word2Vec,  where an embedding is learned per word by either predicting the word  based on its context (Continuous Bag-of-Words (CBOW)) or predicting the  context based on a word (Skip-Gram (SG)). To do this, RDF2Vec first  creates ""sentences"" which can be fed to Word2Vec by extracting walks of a certain depth from the Knowledge Graph.

&#x200B;

In addition to extract random walks and applying weisfeiler-lehman relabeling, as proposed by the original work, we provide 6 alternative walking strategies (and allow to combine several of them). A comparison of these strategies will be out soon!

&#x200B;

Repository: [https://github.com/IBCNServices/pyRDF2Vec](https://github.com/IBCNServices/pyRDF2Vec)

RDF2Vec Paper: [https://madoc.bib.uni-mannheim.de/41307/1/Ristoski\_RDF2Vec.pdf](https://madoc.bib.uni-mannheim.de/41307/1/Ristoski_RDF2Vec.pdf)

&#x200B;

If you have any questions, problems running the code, or an interesting use case. Get in touch with us!","machinelearning",50,0
"259",251,"MachineLearning","[D] does anyone else feel like they have no idea what they are doing?","Title pretty much says it all but for all of you working in industry do you just have this feeling that you really do not know what you are doing, you put together an idea but have no idea if it’ll actually work?","machinelearning",51,37
"260",252,"MachineLearning","[R] Deep Learning approaches to automated clinical coding (extreme multi-label classification)","We have spent the last 6-months working with researchers from Maharaj Nakorn Chiang Mai Hospital  using clinical data to predict ICD10 codes. Clinical coding is a back-office activity in most hospitals that enables diseases and treatments to be standardised for billing & epidemiology purposes.

Our approach leverages deep learning, combining data from pathology, pharmacy, radiology and admissions to classify episodes of care to one or more of the 12,000 ICD10 codes.

[https://growingdata.com.au/automated-ai-approaches-to-clinical-coding-a-case-study/](https://growingdata.com.au/automated-ai-approaches-to-clinical-coding-a-case-study/)  


We would love the opportunity to discuss our approaches with the community","machinelearning",52,0
"261",253,"MachineLearning","[D] Does anyone have experience using anomaly detection tools?","There are a few anomaly/outlier detection tools available in the market. For example - tools like Anodot which detects an anomaly in any time-series data - Loomsystems, which detects anomaly in log data.

Do you folks find such tools useful - why/why not?

If yes, what is your primary use case for such tools?","machinelearning",53,3
"262",254,"MachineLearning","[R] Update code: Transformer for Graph Classification","We update the implementation of our U2GNN as described in our paper: [Universal Self-Attention Network for Graph Classification](https://arxiv.org/abs/1909.11855) where we leverage on the ***transformer*** self-attention network. Our U2GNN achieves new highest accuracies on most of 9 well-known benchmark datasets in both the supervised and unsupervised training settings, using the same 10-fold cross-validation scheme, against the up-to-date unsupervised and supervised baselines. More importantly, we suggest that future GNN-based approaches should focus on the unsupervised training setting to improve graph classification performance. Our code is available at: [https://github.com/daiquocnguyen/U2GNN](https://github.com/daiquocnguyen/U2GNN)","machinelearning",54,1
"263",255,"MachineLearning","[N] UPDATE: Nordic Probabilistic AI School (ProbAI) — June 8-12, 2020","You are welcome to apply for the Nordic Probabilistic AI School (ProbAI) 2020 being held on June 8-12 in **Trondheim (Norway)**.

[**APPLY NOW**](https://probabilistic.ai/application) — The application deadline is March 26, but we recommend an early application.

## About ProbAI 2020

The mission of the 2nd Nordic Probabilistic AI School (ProbAI) remains unchanged. We aim to serve state-of-the-art expertise in probabilistic machine learning and artificial intelligence to the public, students, academia and industry.

Particularly, our objective is to bring an intermediate to advanced level summer school with a focus on probabilistic machine learning. We cover topics such as probabilistic models, deep generative models, latent variable models, inference with sampling and variational approximations, and probabilistic programming and tools.

The ProbAI 2020 is organized by the [Norwegian Open AI Lab](https://www.ntnu.edu/ailab) and hosted by the [Norwegian University of Science and Technology](https://www.ntnu.edu/) (NTNU) in Trondheim.

## COVID-19 Update

**Currently, we have no plans of cancelling the Nordic Probabilistic AI School.**

Please be assured that we are closely monitoring the situation around the 2019 novel coronavirus (COVID-19), and we are following the advice of local, national and international health authorities.

Should the status change, we will inform you through all available communication channels.

## Program

Together with the intentionally small team of invited lecturers, we hope to provide an efficient and quality knowledge transfer through:

* **carefully designed curriculum**,
* **tight cooperation** between our lecturers,
* a mix of **theoretical lectures** and some **hands-on tutorials**,
* extra time for participants with our **teaching assistants** at hand,
* an **innovative lecture room** ([R2](https://roundme.com/tour/214005/view/589158/)) that allows for a close collaboration between the students and lecturers.

## Keynote and Talks

* [Max Welling](https://staff.fnwi.uva.nl/m.welling/) (University of Amsterdam) — Keynote
* [Evrim Acar Ataman](https://scholar.google.com/citations?user=eQKaErAAAAAJ) (Simula Research Lab) — Tensor Factorizations for Physical, Chemical, and Biological Systems
* [Atılım Güneş Baydin](https://scholar.google.com/citations?user=GWBSOj4AAAAJ) (University of Oxford) — Probabilistic Programming, Machine Learning, and Physics
* [Keith L. Downing](https://www.ntnu.edu/employees/keithd) (NTNU) — Bio-Inspired AI
* [Mihaela Rosca](https://scholar.google.com/citations?user=MxkDwD0AAAAJ) (DeepMind) — VAE/GAN

## Lectures

* [Arto Klami](https://scholar.google.com/citations?user=v8PeLGgAAAAJ) (University of Helsinki) — Variational Inference and Optimization
* [Andrés R. Masegosa](https://scholar.google.no/citations?user=J1zoY7AAAAAJ) (University of Almería) — Probabilistic Programming and Variational Inference
* [Didrik Nielsen](https://scholar.google.com/citations?user=-sbw1JIAAAAJ) (Technical University of Denmark) — Normalizing Flows and PixelCNN
* [Thomas Dyhre Nielsen](https://scholar.google.com/citations?user=6fWF0CgAAAAJ) (Aalborg University) — Probabilistic Programming and Variational Inference
* [Francisco Ruiz](https://scholar.google.com/citations?user=khgtYMgAAAAJ) (DeepMind) — Variational Inference with Implicit and Semi-Implicit Distributions
* [Antonio Salmerón](https://scholar.google.com/citations?user=41enG0oAAAAJ) (University of Almería) — Probabilistic Modeling
* [Çağatay Yıldız](https://scholar.google.fi/citations?user=dNloPBUAAAAJ&hl=en) (Aalto University) — ODE2VAE

*More to be announced.*

## Registration

The registration fee includes all courses, coffee breaks, lunches and banquet.

* Students (including PhD) → 2500 NOK \~ 250 EUR
* Academia → 5000 NOK \~ 500 EUR
* Industry → 10000 NOK \~ 1000 EUR

We can offer only a limited number of **scholarships** aimed for applicants from developing countries and under-represented groups.

## Contact

* Email: [hello@probabilistic.ai](mailto:hello@probabilistic.ai)
* Website: [https://probabilistic.ai](https://probabilistic.ai)
* Twitter: [https://twitter.com/probabilisticai/](https://twitter.com/probabilisticai/)
* Facebook: [https://www.facebook.com/probabilisticai/](https://www.facebook.com/probabilisticai/)

The organizing team: Heri Ramampiaro, Helge Langseth, Tárik S. Salem, Eliezer de Souza da Silva, Marianne Lyseng, Ludvig Killingberg.","machinelearning",55,4
"264",256,"MachineLearning","[R] How to train your neural ODE","","machinelearning",56,2
"265",257,"MachineLearning","[D] Are Q-learning, pathwise derivatives, and policy gradients all secretly doing the same thing?","After reading up on SAC and taking the time to digest the idea of deep energy-based models in RL, I have to ask: why can we not view all RL algorithms as learning to approximate an energy-based model where the energy is defined by the return? From this view, it looks like all RL algorithms are actually using the same loss functions (either cross-entropy or KL-divergence), and are slight algorithmic variations (i.e. online vs offline) for minimizing the same fundamental quantities.

I've put together an argument [here](https://www.scribd.com/document/451369629/Some-stuff) that derives the policy gradient loss function from the definition of cross-entropy, and then shows that pathwise derivative algorithms like DDPG can be viewed as doing the same thing. From there, I briefly look at the q-learning loss function, and show how we can extract a policy gradient update from it.

Is my reasoning and working here correct, or have I misunderstood something? If is correct, is this something that is reasonably common knowledge in the field? It begs the question of why certain algorithms should dramatically outperform one another, especially in cases where most of the other algorithmic choices are the same. Furthermore, it also begs the question of why the composition used in the soft q-learning paper can't be applied to all RL algorithms.

Feedback, corrections, and discussion all greatly appreciated!","machinelearning",57,11
"266",258,"MachineLearning","[R] Synthesized Paired Data Boosts Facial Manipulation","A research group from the Moscow Institute of Physics and Technology (MIPT) and Russian Internet giant Yandex have proposed a novel image-to-image translation model that uses synthesized input data to enable a “paired” training approach. The model outperforms existing methods in image manipulation and offers researchers a possible solution to the scarcity of paired datasets.

Quick read: [Synthesized Paired Data Boosts Facial Manipulation](https://medium.com/syncedreview/synthesized-paired-data-boosts-facial-manipulation-3ccad02cb0a9)

You can find the original paper [here](https://arxiv.org/pdf/2003.03581.pdf). The project on [Github](https://github.com/EvgenyKashin/stylegan2-distillation).","machinelearning",58,0
"267",259,"MachineLearning","[Project] A Simple Serverless Reporting Endpoint Based on Jupyter Notebooks","Greetings ML folks!

I wanted to let you know about an open-source project I just released called [nb\_to\_html](https://github.com/skyline-ai/nb_to_html). This is a simple app that wraps GitHub API, Papermill and nbconvert to create an HTTP endpoint for parameterized execution of notebooks with HTML response.

Given that you already have the algorithms and data lake to support answering questions with notebooks, sometimes, answering research questions could mean loading your models and libraries into a notebook and preparing a report in 10 minutes.

But what happens when the same question arises tomorrow, for a different parameter (say for a different stock or market)? What if the client wants to get the report on a daily basis?

Since Jupyter Notebook’s UI is practically HTML, we thought that it would be great to be able to just send some business clients a link to a simple HTML rendition of the result of a dynamic notebook execution.

This concept allows the data scientist to really quickly leverage their existing skills to create dynamically generated reports that are sharable, without knowing anything about web servers.

Further, since the trigger is a simple HTTP endpoint receiving query string parameters, it’s trivial to schedule a cron job to send dynamically-generated reports.

This is not a ""notebook scheduling platform"", it's a small app with low-SLA requirements that could help you scribble notebooks in a few minutes and send them as reports to whomever it may concern.

Check it out on this [Medium post](https://medium.com/@_orcaman/a-simple-serverless-reporting-endpoint-based-on-jupyter-notebooks-4cf3e1d15ebe) and if you like it, there are already a few enhancements waiting for keen developers on the [issues section on GitHub](https://github.com/skyline-ai/nb_to_html/issues) :-)","machinelearning",59,1
"268",260,"MachineLearning","[D] Having trouble conveying machine learning roadmap/milestones within a traditional ""do x for y weeks, get z% benefit"" corporate roadmap","Hey there.

Been a freelance/ML lead for a long while, but this is a new one for me--  the company I'm doing work for wants me to provide a very traditional roadmap with milestones for my machine learning initiatives with very discrete ""work on this project with this results for X weeks, with.the projected result/goal of z% improvment on automation of a process.""

The current culture is very new to ML, which I knew coming in and which I know I don't have to tell you has a very non-tradional development cycle and hypothesis/model driven approach where in you assert things and then try and test if the data will allow you to make those predictions in a way that fits the business.  I don't feel comfortable ascribing percentage efficiency adjustments to my projects, as it's literally a shot in the dark-- even if the model is amazing, the results may translate poorly in to production, etc.

I've also been presented with the current company roadmap which implies that I should only be working on projects that will have the biggest impact-- for example, why would you work on this project that takes 8 weeks if you're only gonna get 2% improvement in our current process.  It's very traditionally deterministic, and the ML I am doing (and in general) is difficult to encapsulate within that type of reporting (not impossible, just hard.)  I am going to basically say as much, but I would love to be able to offer a new approach for our ML process while doing so-- and I was wondering how you have dealt with this in your company/startup, as I could use some advice.

I have to convey properly that this type of work is very much hypothesis-driven based on the data, and less deterministic than making updates to the webpage that will make it load 20% faster-- but also that we don't know anything about what patterns we can extract or automate without actually trying it.

So my plan is to introduce a paradigm wherein the basis of what I am doing is rooted within the data itself, not in what projects I think will yield the biggest result necessarily (even though that's the goal) but essentially what do I think I can do with the data that we have, in a way that makes our processes more efficient. I'm struggling with how best to convey this in a way they will understand and agree with, otherwise, I will be forced to try and bend the ML dev and result process in a manner in which it doesn't naturally fit and I want to avoid that.

I couldn't find too many other posts on this in the subreddit, even though I have seen some great posts on how best to fit ML dev in to a traditional agile/sprint environment and how to create your own.

Cheers everybody.

\--Ox

edit: formatting

edit 2: Lots of great responses so far, thank you-- this is a great community","machinelearning",60,16
"269",261,"MachineLearning","[R] Reinforcement Learning with Convolutional Reservoir Computing","","machinelearning",61,4
"270",262,"MachineLearning","[D] I need some help with deploying an LSTM model in production","Hi, So im building a speaker identification application which takes in input as streams from voice calls . I have created a model using keras which works for full audio files now i need to deploy it on cloud to be tested at production grade level. I initially thought to deploy it simply on Kubernetes 

But the issue is that since the model is LSTM and the data comes in streams (Which i cant save for a long time), as the call is going on I need to keep the model state for each call . This means I need to create a different instance of a model for each call to process which leads to scalling problems  as i need to keep provisioning resources with increase in calls.

Also how to handle failure of pods in this case ?

&#x200B;

Note: currently im streaming the data using mini chunks by kafka

How to handle this and how practicle is this approach?","machinelearning",62,5
"271",263,"MachineLearning","[D] How do you call the data set without labels?","In literature, we have the ""training set"", the ""validation set"" (or ""development set"") and the ""test set"". However, we sometimes have to refer to the data set without labels (i.e. data for predictions in the future).

I'm not able to find an established name for it in literature. Some names I've found are:

* Application set
* Prediction set
* Live set

How do you call that kind of data set?","machinelearning",63,3
"272",264,"MachineLearning","[R] ReZero is All You Need: Fast Convergence at Large Depth","","machinelearning",64,17
"273",265,"MachineLearning","[D] What is your favourite (free) labelling tool?","Hey all,

I've found 

[Prodigy](https://prodi.gy/)

but not excited by its payment structure. 

Any other suggestions?","machinelearning",65,8
"274",268,"MachineLearning","[D] How does the current version of MLflow stack up against Kubeflow?","What I've gathered from my own research is that Kubeflow is ""better"" with more features and flexibility, but requires more knowledge and thus can have a steeper learning curve.

Does this sound about right? Would love to hear any personal experiences people have had with either or both.","machinelearning",68,3
"275",269,"MachineLearning","TensorFlow Dev Summit Live Stream starts today (9:00AM PST) [News]","The TersorFlow teams goes over features and what's next for the platform. They also have tech talks and learning resources.

&#x200B;

 [https://www.youtube.com/watch?v=HlBGYxO8RaU&feature=youtu.be](https://www.youtube.com/watch?v=HlBGYxO8RaU&feature=youtu.be) ","machinelearning",69,5
"276",270,"MachineLearning","[D] How up to date is ""Artificial Intelligence - A modern approach""?","I'm a computer science and math student interesting in machine learning and general computer science. How up to date is this book and is it worth reading?","machinelearning",70,11
"277",271,"MachineLearning","[P] Pico-CNN v1.0 - Deploy your Networks on Embedded Systems and IoT Devices","We just released v1.0 of our Deep Learning inference framework Pico-CNN for embedded systems and IoT devices.

Github: [https://github.com/ekut-es/pico-cnn](https://github.com/ekut-es/pico-cnn)

Pico-CNN is completely written in C and only uses standard C libraries. It allows for hassle free deployment of CNNs onto embedded devices since only a standard C compiler is required. Pico-CNN supports import of previously trained ONNX models (using Python on a host) to generate C code and compile scripts for the trained network. Go ahead and deploy your networks on embedded systems.

We succuessfully deployed the following neural networks using Pico-CNN:

 * LeNet
 * MNIST Multi-Layer-Perceptron (MLP)
 * MNIST Perceptron
 * AlexNet
 * VGG-16
 * VGG-19
 * MobileNet-V2
 * Inception-V3
 * Inception-Resnet-V2
 * TC-ResNet-8

In upcoming releases we are focusing on performance improvements for heterogenous embedded multi-core platforms.","machinelearning",71,6
"278",272,"MachineLearning","[R] Contrastive Representation Distillation","","machinelearning",72,4
"279",273,"MachineLearning","[N] Neural Magic sues Facebook over open-sourcing their ""fast CNNs on CPUs"" technology as part of PyTorch"," [https://www.americaninno.com/boston/inno-news-boston/neural-magic-sues-facebook-for-publishing-trade-secrets/](https://www.americaninno.com/boston/inno-news-boston/neural-magic-sues-facebook-for-publishing-trade-secrets/) 

Long story short, Facebook scooped the first non-founder employee and had him reimplement the key acceleration technology, which is now part of PyTorch (""Glow"" I think?)","machinelearning",73,60
"280",274,"MachineLearning","[D] What SOA Single channel image classifier architectures are there?","Hey guys so I’m working on classifying some grey scale image. I’ve built my own custom architecture to achieve this and I’m getting good results. I’d like to compare it versus other classifiers. I’ve tried to use VGG16 however it doesn’t support single channel images.","machinelearning",74,3
"281",275,"MachineLearning","[R] Reservoir memory machines","","machinelearning",75,1
"282",276,"MachineLearning","[D] Generating a semantic categorical hierarchy from a corpus of freeform text?","I have the following use case, for which I'm looking for references and possible approaches. I'm aware that it is kind of a long shot, and whoever implemented would probably sell it as a for profit solution, given both it's specificity and its complexity. 

The problem can be described as follows: 

I want to take a very large collection of text documents, and generate a hierarchical representation of these documents in the following way: 

Imagine that the texts in question are a large collection of books. I want these books organized in a hierarchy of 4 levels, based on increasing semantic granularity of the categories. 

&#x200B;

https://preview.redd.it/o4ee893bp0m41.jpg?width=2340&format=pjpg&auto=webp&s=4c2b05dba46170b508b0cc401a3c722e5e8cb6bc

&#x200B;

  
The purpose of the model is to train it on a new corpus, and then be able to assign any new documents to the correct sub-genre, and by to the correct parent nodes above it as well. But my problem is semi-supervised in two ways: 

&#x200B;

* Only the number of levels in the hierarchy are known. The number of nodes at each level is not known before hand, but there are bounds on the number of nodes in each layer: We want a given layer to have a reasonably larger number of nodes than the layer above it, and a reasonably smaller number of nodes than the layer below it. This is the case because it is possible that there values for that layer that weren't captured when the labels were recorded for the train set. In our book example, examples of Cyberpunk and Space Opera were properly labeled, but there were several Military Science Fiction novels that were missed during the labeling process, and we're hoping that the algorithm can learn based on the semantics, that they fall under the SciFi genre, but should be in their own new category. This new node can happen at any level in the hierarchy, for example it may turn out that several of the books were neither ""Fiction"" nor ""Non-fiction"",  but were actually instruction manuals. In real life, books could likely fall under more than one genre, but I can ignore that in my use case and assume that each child has only one parent. 

&#x200B;

* Moreover, not all the books in the training set are labeled: I am hoping (again, this is a stretch) that the model can figure out when to place a child node under an existing parent node, and when to create a new node for that child, all while respecting the upper limit on the number of nodes, AND that the new node is a semantically meaningful category. This actually imposes an third constraint: That if a new node is created, its on the same level of semantic granularity as the other nodes on the level, e.g. an new sub-genre under sci-fi can't be ""near future space adventures with elements of digital steampunk and radical feminism"", either create a node called ""feminist sci-fi"" or just put it under ""space opera"" or ""cyberpunk"", depending on which element is more prevalent in the text. This means that the model should learn the proper level of semantic granularity from the existing labels.

New nodes are only created during training - we assume that the training corpus contains all the relevant categories, even if they haven't all been properly labeled. 

My actual use case (which is too complicated and domain specific to describe her) will be mostly about business and organizational categories, not literary genres. Moreover, the docs will be at most 1 page long, not full size books. Not sure if this changes anything for which models and approaches are suitable. 

  
Are there any NLP approaches specifically for this problem? Are they deep learning based, or more old school NLP? 

1. I thought of topic modeling (specifically hierarchical topic modeling) but that would work only if a document could be assigned to multiple sub-genres, and in my case, I have to have a hard rule of only one rule. One might solve this by getting the most important topic out of each doc, and discarding the rest. But then I fail to see how it could handle the semi-supervised issue of being able to come up with new nodes whenever necessary? 
2. Training successive deep learning based embeddings on the labels for layer could handle the new/unlabelled data node issue, but the outputs for those new nodes would end be continuous combinations of the existing topics, not semantically unique new topics. In order to enforce that last requirement, you'd have to have the neural net create new output neurons on the fly I think (Is that even possible?!?). ","machinelearning",76,4
"283",277,"MachineLearning","[R] Zoom In: An Introduction to Circuits (new distill.pub)","""By studying the connections between neurons, we can find meaningful algorithms in the weights of neural networks.""

https://distill.pub/2020/circuits/zoom-in/","machinelearning",77,4
"284",278,"MachineLearning","[Discussion] Are there any commercial applications of evolutionary algorithms like CMA-ES? Where have you used them or seen being used?","Most of the applications I can find online tend to be academic or toy experiments.","machinelearning",78,17
"285",279,"MachineLearning","[D] Causal Interpretability for Machine Learning - Problems, Methods and Evaluation","If you're unfamiliar with interpretability in ML, this is a worth while read. The need to build explanations for model decision making is a key step towards trusts and adoption. I'd welcome additional resources in the comments for those looking to explore this topic. [https://arxiv.org/pdf/2003.03934.pdf](https://arxiv.org/pdf/2003.03934.pdf)","machinelearning",79,2
"286",280,"MachineLearning","[P] ⏩ForwardTacotron - Generating speech in a single forward pass without any attention!","We've just open-sourced our first text-to-speech 🤖💬 project! It's also our first public PyTorch project. Inspired by Microsoft's [FastSpeech](https://www.microsoft.com/en-us/research/blog/fastspeech-new-text-to-speech-model-improves-on-speed-accuracy-and-controllability/), we modified Tacotron (Fork from fatchord's [WaveRNN](https://github.com/fatchord/WaveRNN)) to generate speech in a single forward pass without using any attention. Hence, we call the model ⏩ ForwardTacotron.

&#x200B;

The model has several advantages:

💪 Robustness: No repeats and failed attention modes for complex sentences

🚀 Speed: Generating a spectogram takes about 0.04s on a RTX2080

🕹 Controllability: You can control the speed of the speech synthesis

⚙️ Efficiency: No usage of attention so memory size grows linearly with text size

&#x200B;

We also provide a Colab notebook to try out our pre-trained model trained 100k steps on LJSpeech and also some Samples. Check it out!

🔤 Github: [https://github.com/as-ideas/ForwardTacotron](https://github.com/as-ideas/ForwardTacotron)

🔈 Samples: [https://as-ideas.github.io/ForwardTacotron/](https://as-ideas.github.io/ForwardTacotron/)

📕 Colab notebook: [https://colab.research.google.com/github/as-ideas/ForwardTacotron/blob/master/notebooks/synthesize.ipynb](https://colab.research.google.com/github/as-ideas/ForwardTacotron/blob/master/notebooks/synthesize.ipynb)","machinelearning",80,10
"287",281,"MachineLearning","[Discussion] Augmented Training Scheme Fixes CNN Texture Bias","Researchers from the University of Toronto, Mila, Nvidia and Google Brain have proposed a new training scheme that targets CNNs' bias towards textural information in the training process.

Read more: [Augmented Training Scheme Fixes CNN Texture Bias](https://medium.com/syncedreview/augmented-training-scheme-fixes-cnn-texture-bias-1aed0f8993ef)

(arXiv [here](https://arxiv.org/pdf/2003.01367.pdf))","machinelearning",81,5
"288",282,"MachineLearning","[D] From PyTorch to JAX: towards neural net frameworks that purify stateful code","https://sjmielke.com/jax-purify.htm

Jax is a new autograd library from google and author in the blog post explains the pros and cons of Jax over PyTorch.","machinelearning",82,18
"289",283,"MachineLearning","AutoML-Zero: Evolving Machine Learning Algorithms From Scratch","","machinelearning",83,7
"290",284,"MachineLearning","[R] StyleGAN2 Distillation for Feed-forward Image Manipulation","","machinelearning",84,3
"291",285,"MachineLearning","[Discussion] Good video resources to get into 3D Computer Vision?","Are there any good \*video\* playlists and resources to get started into 3D computer vision, perhaps starting with 3D geometry basics and working up recent deep learning approaches? All i could find was lecture slides so far but not any lecture videos. Thanks in advance!","machinelearning",85,1
"292",287,"MachineLearning","[P] Does Experience Replay work with External Memory?","In an RL agent with actions to read/write an external memory, it's not practical to represent the entire memory in the state/observation variable - so the agent is operating in an imperfect information setting.

Does experience replay work in situations like these? You would have to copy and store the entire memory contents at every timestep right? 

Re: external memory, it's hard to believe a model can learn to do a mem-write, without observing a direct state change after, and later a mem-read for some result. If an agent sees a random object early in a episode, and at the end has to recall what the object was, in an episode of 100 steps, how could it ever learn by sampling trajectories of length 5 to save that info early on? It seems easier for a controller hidden state to capture that info than through explicit disconnected actions, but is that an accurate thought / why?","machinelearning",87,4
"293",288,"MachineLearning","[D] Latent space disentanglement with hierarchical and correlated attributes","Latent space disentanglement should make each dimension in z correspond to one attribute of the data distribution x. However, how does this work in the case of attributes that are hierarchical or correlated to begin with?

For example:

Suppose we have a large enough latent space z, and that we want to learn a generative model of dogs. A perfectly disentangled z should allow us to find one dimension in z that corresponds to dog breed, and another that corresponds to fur color. However, there is a correlation between the two, and even assuming each breed will have each fur color in some portion of the population, the attributes are still correlated / hierarchical to some degree.

Assuming our latent space is large enough to encode both breed and fur color changes, how would that look? Would each attribute be in a different, uncorrelated dimension, or would there be some implicit representation of the relationship between the two?","machinelearning",88,3
"294",289,"MachineLearning","[D] Deep Learning for Paraphrasing (NLP)","Can you please tell me some of the commonly used deep learning approaches for paraphrasing? And are there any modern solutions like BERT, GPT for this particular problem?  
The use case I'm interested in is similar to [this](https://pdfs.semanticscholar.org/101c/0e09d533b738d83a3740f1f6e49ab2984e55.pdf?_ga=2.157846266.1183672682.1583870958-530381807.1583870958).","machinelearning",89,2
"295",290,"MachineLearning","[D] Are there learning rate schedulers based on training, validation or any other metrics?","Hi, many of the existing LR schedulers seems to be a function of the training iteration *t* (see for example this paper [1908.06477](https://arxiv.org/pdf/1908.06477.pdf) for benchmarks of various methods). However, when working with multiple datasets where each one contains different types of images, may vary in number of photos (from hundreds to thousands) and classes (from tens to hundreds), I often have to manually tune scheduling parameters separately for each problem e.g. the number of warmup epochs, base learning rate etc. To deal somehow with these various scenarios I use a simple heuristic which is based on the observation of training metrics like classification accuracy, but this requires at least one run for new project. 

I think my naive heuristic could be easily automated, but I wonder if there are already off-of-shelf solutions which allow to automate LR scheduling to avoid human supervision. I'm aware of [1506.01186](https://arxiv.org/pdf/1506.01186.pdf) paper,  but this method still requires some supervision and I had problem to make it work on our problems.","machinelearning",90,3
"296",291,"MachineLearning","[R] ‘Train Large, Then Compress’ — UC Berkeley BAIR Improves Large Transformer Model Training and Inference","Researchers from the Berkeley Artificial Intelligence Research (BAIR) Lab at UC Berkeley explored the effect of Transformer model size on training and inference efficiency. Their new paper shows that with limited resources, training and inference efficiency can be improved by significantly increasing the size of the Transformer models and heavily compressing them. 

Short read: [‘Train Large, Then Compress’ — UC Berkeley BAIR Improves Large Transformer Model Training and Inference](https://medium.com/syncedreview/train-large-then-compress-uc-berkeley-bair-improves-large-transformer-model-training-and-cde86f3fe16f)

The original paper is [here](https://arxiv.org/pdf/2002.11794.pdf)","machinelearning",91,1
"297",292,"MachineLearning","[N] Tensorflow Quantum is published.","[https://scirate.com/arxiv/2003.02989?fbclid=IwAR3lbFQuPTpffZYdNh6HlIdoRQdVtDVaUtGCjT2rALt-3F1W-TiLMZjjXWs](https://scirate.com/arxiv/2003.02989?fbclid=IwAR3lbFQuPTpffZYdNh6HlIdoRQdVtDVaUtGCjT2rALt-3F1W-TiLMZjjXWs)

[https://github.com/tensorflow/quantum](https://github.com/tensorflow/quantum)  


An open source library for the rapid prototyping of hybrid quantum-classical models for classical or quantum data.","machinelearning",92,52
"298",293,"MachineLearning","[Discussion] Convolutional Variational Autoencoders","I have a few questions concerning the application of Convolutional layers to Variational Autoencoders:

- Do the two networks -encoder and decoder- need to be symmetrical?
- Should I use MaxPooling layers in the encoder? And how should I set the correspondent layer in the decoder?
- Should the encoder network be constantly decreasing in number of filters for each convolutional layer?","machinelearning",93,4
"299",294,"MachineLearning","[N] University of Hertfordshire and Goonhilly hail deep learning-led UK mapping data breakthrough","A deep learning technique that is able to remove cloud cover from satellite imagery data:

[https://www.computerweekly.com/news/252479772/University-of-Hertfordshire-and-Goonhilly-hail-deep-learning-led-UK-mapping-data-breakthrough](https://www.computerweekly.com/news/252479772/University-of-Hertfordshire-and-Goonhilly-hail-deep-learning-led-UK-mapping-data-breakthrough)

&#x200B;

The article:

The University of Hertfordshire says its technology tie-up with the [Goonhilly Earth Station in Cornwall](https://www.computerweekly.com/news/252444483/Goonhilly-Earth-Station-sets-out-plans-to-open-green-colocation-datacentre-in-2018)  will open up a raft of business opportunities for retailers, insurance  firms and the agricultural industry by producing better-quality mapping  data about the UK.

The university claims that tapping into Goonhilly’s artificial intelligence (AI) and deep learning platforms has enabled it to create a  service that will provide access to satellite mapping data of the UK that is free from cloud cover for the first time.

It relies on the use of satellite radar imaging, which can pass through clouds, to produce detailed images of the Earth’s surface  regularly.

The work is being led by astrophysicist professor James Geach and his PhD student Mike Smith, whose team have used Goonhilly’s NVIDIA GPU supercomputer to train its ClearSky algorithm on a huge set of satellite  images of the Earth’s surface.

“Goonhilly’s deep learning platform has allowed us to massively accelerate time to market,” said Geach.

“The platform’s phenomenal processing speed has made it possible for  us to significantly scale up our models and increase the scope of our  analysis. It is rewarding to see how techniques developed for astrophysics can be applied to Earth observation data to deliver  real-world impact.”

Geach and his team already have a number of potential use cases in  mind for the data, including using it to monitor coastal erosion, track  the impact of climate change on crop growth patterns, and predict where flooding and wildfires might occur. These, in turn, could open up  business opportunities for retailers, insurance firms, commodity traders  and supermarkets, they said. 

They have also forged ties with agricultural technology company Agrimetrics to  provide capabilities for the firm to monitor the health and growth rate  of 2.8 million fields across the UK on a weekly basis.

The team is looking to spin out its own commercial venture, known as  DeepEO, later this year on the back of this work by creating a  continuously updated database of Earth observation data that  organisations can use to inform their decision-making around extreme  weather events.

As previously reported by Computer Weekly, the team at Goonhilly has set its sights on becoming a [major incubation hub](https://www.computerweekly.com/news/252444483/Goonhilly-Earth-Station-sets-out-plans-to-open-green-colocation-datacentre-in-2018) for UK enterprises and academic organisations looking to create machine learning, [deep learning](https://searchenterpriseai.techtarget.com/feature/How-to-solve-deep-learning-challenges-through-interoperability) and AI-based services.

The site officially went live in July 2019, and is already home to a  renewably-powered datacentre, which is where a lot of the computational  work carried out by organisations such as the University of  Hertfordshire is carried out.

As an extension to this, the Goonhilly team is now turning its  attention to building a testbed of platforms that will allow the site’s  users to tap into [edge computing](https://www.computerweekly.com/news/252476614/Computing-at-the-edge) capabilities, and conduct near real-time analysis of live satellite data streams.

Chris Roberts, [head of datacentre and cloud at Goonhilly,](https://www.computerweekly.com/blog/Ahead-in-the-Clouds/Taking-the-cloud-to-the-edge-of-space)  said it is hoped this work will lead to more research organisations  taking steps to create commercial ventures, as the University of  Hertfordshire team plans to do.

“Our wraparound service nurtures startups like DeepEO with the  resources they need on their journey from a research project to  commercial growth and profitability,” said Roberts.

“And our datacentre’s green credentials are an increasingly important  factor, ensuring that valuable environmental efforts to mitigate the  effects of climate change are not themselves creating volumes of CO2.”","machinelearning",94,1
"300",295,"MachineLearning","[R] A Generalized Training Approach for Multiagent Learning","","machinelearning",95,1
"301",296,"MachineLearning","[D] On Neural Persistence, Improved Language Models, and Narrative Complexity","Hi!

&#x200B;

I recently read an amazing paper by folks out of ETH (Paper in question: [https://openreview.net/pdf?id=ByxkijC5FQ](https://openreview.net/pdf?id=ByxkijC5FQ))

&#x200B;

The idea is that we can borrow ideas from topological data science to compute layer wise metrics on complexity. This lends itself to improved dropout and better stopping conditions.

&#x200B;

While not much work has been done pushing this approach further long, I spent few hours today explaining very basic topological data science and going over the paper mentioned above. I finally conclude with showing how it might lead to the improved dropout approaches or new loss functions via minimizing KL-Divergence between token-wise complexity vs a scaffold distribution. In the case of the latter, a good example of this is a story arc distribution if one is trying to have a language model generate stories.

&#x200B;

The blog is here:

[https://www.louiscastricato.com/post/on-neural-persistence-improved-language-models-and-narrative-complexity](https://www.louiscastricato.com/post/on-neural-persistence-improved-language-models-and-narrative-complexity)

&#x200B;

I will happily answer any questions. Thanks for your time!","machinelearning",96,8
"302",374,"MachineLearningJobs","[Hiring] Engineer II – Data Systems (Data Management)","","machinelearningjobs",74,0
"303",297,"MachineLearning","[Research] Graph, Convolutions, and Neural Networks","Network data can be conveniently modeled as a graph signal, where data values are assigned to nodes of a graph that describes the underlying network topology. Successful learning from network data is built upon methods that effectively exploit this graph structure. In this work, we overview graph convolutional filters, which are linear, local and distributed operations that ade- quately leverage the graph structure. We then discuss graph neural networks (GNNs), built upon graph convolutional filters, that have been shown to be powerful nonlinear learning architectures. We show that GNNs are permutation equivariant and stable to changes in the underlying graph topology, allowing them to scale and transfer. We also introduce GNN extensions using edge- varying and autoregressive moving average graph filters, and discuss their properties. Finally, we study the use of GNNs in learning decentralized controllers for robot swarm and in addressing the recommender system problem.

Link: [https://arxiv.org/pdf/2003.03777.pdf](https://arxiv.org/pdf/2003.03777.pdf)","machinelearning",97,0
"304",298,"MachineLearning","[R] The importance of transparency and reproducibility in artificial intelligence research","","machinelearning",98,3
"305",299,"MachineLearning","[D] Did your PhD acutally improve your software engineering skills?","Or did you end up doing predominantly  theoretical work?","machinelearning",99,27
"306",300,"MachineLearningJobs","[HIRING][REMOTE]Coding Specialist III at Navient @ Navient","What kind of candidates do we need?

 **Tools**:[Express.js](https://bestremotejob.com/tool/Express.js?&utm_source=reddit&utm_medium=MachineLearningJobs).

Interested in this job? Please **[apply here](https://bestremotejob.com/job/coding-specialist-iii-2?&utm_source=reddit&utm_medium=MachineLearningJobs)**","machinelearningjobs",0,0
"307",301,"MachineLearningJobs","[HIRING][REMOTE]Support Engineer","What kind of candidates do we need?

 **Tools**:[Amazon_Web_Services](https://bestremotejob.com/tool/Amazon_Web_Services?&utm_source=reddit&utm_medium=MachineLearningJobs).[Kubernetes](https://bestremotejob.com/tool/Kubernetes?&utm_source=reddit&utm_medium=MachineLearningJobs).[Google_Cloud_Platform](https://bestremotejob.com/tool/Google_Cloud_Platform?&utm_source=reddit&utm_medium=MachineLearningJobs).

**Languages**:[Python](https://bestremotejob.com/language/Python?&utm_source=reddit&utm_medium=MachineLearningJobs).[Bash](https://bestremotejob.com/language/Bash?&utm_source=reddit&utm_medium=MachineLearningJobs).[SQL](https://bestremotejob.com/language/SQL?&utm_source=reddit&utm_medium=MachineLearningJobs).

**Skills**:[devops](https://bestremotejob.com/skill/devops?&utm_source=reddit&utm_medium=MachineLearningJobs).[Linux](https://bestremotejob.com/skill/Linux?&utm_source=reddit&utm_medium=MachineLearningJobs).

Interested in this job? Please **[apply here](https://bestremotejob.com/job/landingjobssupport-engineer-in-lisbon-2020?&utm_source=reddit&utm_medium=MachineLearningJobs)**","machinelearningjobs",1,0
"308",302,"MachineLearningJobs","[Hiring][Internship] Internship Active Learning in Probabilistic Machine Learning","","machinelearningjobs",2,0
"309",303,"MachineLearningJobs","What is Machine Learning with its Types and Algorithms","&#x200B;

Machine Learning is an aspect of Artificial Intelligence that uses different algorithms to enable a system to learn from the training data instead of learning through explicit programming. Thus, rather than you doing the programming or even composing the code, what you should do is you train the generic algorithm and according to the training data, the algorithm/machine/model builds the logic.

**Types of Machine Learning**

* Supervised Learning
* Unsupervised Learning
* Reinforcement Learning

**There are various algorithms used in Machine Learning:**

1. Linear regression
2. Nearest neighbor
3. Decision tree
4. Gaussian Naive Bayes
5. Random forest
6. Support vector machines(SVM)

**Applications of Machine Learning**

* Classification
* Regression
* Clustering","machinelearningjobs",3,0
"310",304,"MachineLearningJobs","[Hiring] Senior Scala Software Engineer","","machinelearningjobs",4,0
"311",305,"MachineLearningJobs","[Hiring] Senior Machine Learning Engineer","","machinelearningjobs",5,0
"312",306,"MachineLearningJobs","[Hiring] Senior Data Engineer (Streaming)","","machinelearningjobs",6,0
"313",307,"MachineLearningJobs","[Hiring] Senior Data Engineer (Machine Learning & Analytics)","","machinelearningjobs",7,0
"314",308,"MachineLearningJobs","[Hiring] Senior Scala Software Engineer","","machinelearningjobs",8,0
"315",309,"MachineLearningJobs","[Hiring] Senior Machine Learning Engineer","","machinelearningjobs",9,0
"316",310,"MachineLearningJobs","[Hiring] Senior Data Engineer (Streaming)","","machinelearningjobs",10,0
"317",311,"MachineLearningJobs","[Hiring] Data Platform Engineer","","machinelearningjobs",11,0
"318",312,"MachineLearningJobs","[HIRING][REMOTE]Prestructure Washington DC REMOTE - FULLTIME Fulls ... @ Prestructure","What kind of candidates do we need?

 **Tools**:[Mongodb](https://bestremotejob.com/tool/Mongodb?&utm_source=reddit&utm_medium=MachineLearningJobs).[Amazon_Web_Services](https://bestremotejob.com/tool/Amazon_Web_Services?&utm_source=reddit&utm_medium=MachineLearningJobs).[Google_Cloud_Platform](https://bestremotejob.com/tool/Google_Cloud_Platform?&utm_source=reddit&utm_medium=MachineLearningJobs).[Angular](https://bestremotejob.com/tool/Angular?&utm_source=reddit&utm_medium=MachineLearningJobs).

**Languages**:[Java](https://bestremotejob.com/language/Java?&utm_source=reddit&utm_medium=MachineLearningJobs).

**Skills**:[devops](https://bestremotejob.com/skill/devops?&utm_source=reddit&utm_medium=MachineLearningJobs).

Interested in this job? Please **[apply here](https://bestremotejob.com/job/hn22264175?&utm_source=reddit&utm_medium=MachineLearningJobs)**","machinelearningjobs",12,0
"319",313,"MachineLearningJobs","[Hiring] Senior Data Engineer","","machinelearningjobs",13,0
"320",314,"MachineLearningJobs","[Hiring][Internship, Temporary] Master’s student position or internship Machine learning / Deep learning","","machinelearningjobs",14,0
"321",315,"MachineLearningJobs","[HIRING][REMOTE] Python Data Engineer at Overloop () (allows remote) - 100000 USD","We are hiring! Pay scales with experience. Find out more here https://underwearworker.com/jobs/11368","machinelearningjobs",15,0
"322",316,"MachineLearningJobs","[Hiring] Data Scientist at MobilizeAmerica - New York, NY","","machinelearningjobs",16,0
"323",317,"MachineLearningJobs","[Hiring] Software Engineer - Machine Learning at Brightest - New York, NY","","machinelearningjobs",17,0
"324",318,"MachineLearningJobs","[Hiring] Data Scientist, Bot Management","","machinelearningjobs",18,0
"325",319,"MachineLearningJobs","[Hiring] Quantitative Researcher (Data Science/Machine Learning/Mathematical Modelling)","","machinelearningjobs",19,0
"326",320,"MachineLearningJobs","[HIRING][REMOTE] 120000 USD - Data Engineer at Exputec GmbH () (allows remote)","We are hiring! Pay scales with experience. Find out more here https://underwearworker.com/","machinelearningjobs",20,0
"327",321,"MachineLearningJobs","[HIRING][REMOTE]Junior Manual Quality Assurance Engineer at Mindojo @ Mindojo","What kind of candidates do we need?

 **Tools**:[Jenkins](https://bestremotejob.com/tool/Jenkins?&utm_source=reddit&utm_medium=MachineLearningJobs).[Selenium](https://bestremotejob.com/tool/Selenium?&utm_source=reddit&utm_medium=MachineLearningJobs).

**Languages**:[Python](https://bestremotejob.com/language/Python?&utm_source=reddit&utm_medium=MachineLearningJobs).

Interested in this job? Please **[apply here](https://bestremotejob.com/job/junior-manual-quality-assurance-engineer?&utm_source=reddit&utm_medium=MachineLearningJobs)**","machinelearningjobs",21,0
"328",322,"MachineLearningJobs","[Hiring] Research Scientist – Computer Vision and Machine Learning","","machinelearningjobs",22,0
"329",323,"MachineLearningJobs","[Hiring] Senior Software Engineer, Data Pipelines","","machinelearningjobs",23,0
"330",324,"MachineLearningJobs","[Hiring] Automotive Computer Vision&Machine Learning Engineer","","machinelearningjobs",24,0
"331",325,"MachineLearningJobs","[HIRING][REMOTE] Senior Data Engineer at Tilda Research () (allows remote) - 130000 USD","We are hiring! Pay scales with experience. Find out more here https://underwearworker.com/jobs/11197","machinelearningjobs",25,0
"332",326,"MachineLearningJobs","[Hiring] Lead, Content Machine Learning Engineer – Data Scientist – HBO Max","","machinelearningjobs",26,0
"333",327,"MachineLearningJobs","[HIRING][REMOTE] 130000 USD - Business Data Analyst, Salesforce Innovation Center at Salesforce () (allows remote)","We are hiring! Pay scales with experience. Find out more here https://underwearworker.co","machinelearningjobs",27,0
"334",328,"MachineLearningJobs","Have up-to 6 positions on RL","Please have a look and apply here: [https://www.linkedin.com/posts/haitham-bou-ammar-a723a932\_call-for-positions-in-my-team-feel-free-activity-6626038992628527105-S5Av](https://www.linkedin.com/posts/haitham-bou-ammar-a723a932_call-for-positions-in-my-team-feel-free-activity-6626038992628527105-S5Av)","machinelearningjobs",28,0
"335",329,"MachineLearningJobs","[Hiring] Machine Learning Engineer","","machinelearningjobs",29,0
"336",330,"MachineLearningJobs","[Hiring] Machine Learning Engineer – Special Projects Team","","machinelearningjobs",30,0
"337",331,"MachineLearningJobs","[HIRING][REMOTE] 120000 USD - Big Data Engineer at Infiot (San Jose, CA) (allows remote)","We are hiring! Pay scales with experience. Find out more here https://underwearworker.com/jobs/11058","machinelearningjobs",31,0
"338",332,"MachineLearningJobs","[Hiring] Software Engineer – Data Platform","","machinelearningjobs",32,0
"339",333,"MachineLearningJobs","[Hiring] Lead Data Scientist","","machinelearningjobs",33,0
"340",334,"MachineLearningJobs","[Hiring] Principal Data Scientist Artificial Intelligence Machine Learning Scientist – Financial Advice","","machinelearningjobs",34,0
"341",335,"MachineLearningJobs","[HIRING][REMOTE] Data Engineer at Brightfield Group (Chicago, IL) (allows remote) - 120000 USD","We are hiring! Pay scales with experience. Find out more here https://underwearworker.com/jo","machinelearningjobs",35,0
"342",336,"MachineLearningJobs","[Hiring] Staff Machine Learning Engineer – Autopilot","","machinelearningjobs",36,0
"343",337,"MachineLearningJobs","[HIRING][REMOTE]Senior Test Automation Developer, Testing Strategy and Automation at Elevate Security @ Elevate Security","What kind of candidates do we need?

 **Tools**:[Flask](https://bestremotejob.com/tool/Flask?&utm_source=reddit&utm_medium=MachineLearningJobs).[Redis](https://bestremotejob.com/tool/Redis?&utm_source=reddit&utm_medium=MachineLearningJobs).[Amazon_Web_Services](https://bestremotejob.com/tool/Amazon_Web_Services?&utm_source=reddit&utm_medium=MachineLearningJobs).[Docker](https://bestremotejob.com/tool/Docker?&utm_source=reddit&utm_medium=MachineLearningJobs).[Reactjs](https://bestremotejob.com/tool/Reactjs?&utm_source=reddit&utm_medium=MachineLearningJobs).[Django](https://bestremotejob.com/tool/Django?&utm_source=reddit&utm_medium=MachineLearningJobs).[Redux](https://bestremotejob.com/tool/Redux?&utm_source=reddit&utm_medium=MachineLearningJobs).[Express.js](https://bestremotejob.com/tool/Express.js?&utm_source=reddit&utm_medium=MachineLearningJobs).

**Languages**:[Python](https://bestremotejob.com/language/Python?&utm_source=reddit&utm_medium=MachineLearningJobs).

**Skills**:[CI/CD](https://bestremotejob.com/skill/CI/CD?&utm_source=reddit&utm_medium=MachineLearningJobs).[ETL](https://bestremotejob.com/skill/ETL?&utm_source=reddit&utm_medium=MachineLearningJobs).

Interested in this job? Please **[apply here](https://bestremotejob.com/job/senior-test-automation-developer-testing-strategy-and-automation?&utm_source=reddit&utm_medium=MachineLearningJobs)**","machinelearningjobs",37,0
"344",338,"MachineLearningJobs","[Hiring] Senior Machine Learning Engineer, Bot Management","","machinelearningjobs",38,0
"345",339,"MachineLearningJobs","[HIRING][REMOTE] REMOTE Sr. Big Data/AWS Opening at Surge () (allows remote) - 130000 USD","We are hiring! Pay scales with experience. Find out more here https://underwearworker.com/jobs/10337","machinelearningjobs",39,0
"346",340,"MachineLearningJobs","[HIRING][REMOTE]Security Engineer - Remote @ Numbrs Personal Finance AG","What kind of candidates do we need?

 **Tools**:[Amazon_Web_Services](https://bestremotejob.com/tool/Amazon_Web_Services?&utm_source=reddit&utm_medium=MachineLearningJobs).

**Languages**:[Java](https://bestremotejob.com/language/Java?&utm_source=reddit&utm_medium=MachineLearningJobs).[C++](https://bestremotejob.com/language/C++?&utm_source=reddit&utm_medium=MachineLearningJobs).

Interested in this job? Please **[apply here](https://bestremotejob.com/job/security-engineer-remote-numbrs-personal-finance-ag-29779?&utm_source=reddit&utm_medium=MachineLearningJobs)**","machinelearningjobs",40,0
"347",341,"MachineLearningJobs","[Hiring][Full Time, Temporary] Neural Machine Translation Engineer","","machinelearningjobs",41,0
"348",342,"MachineLearningJobs","[Hiring] Siri - Software Engineer in Test (Machine Learning Systems) at Apple (Cambridge, Cambridgeshire, United Kingdom)","","machinelearningjobs",42,0
"349",343,"MachineLearningJobs","[HIRING][REMOTE] Senior Big Data Scalability Engineer (Remote US Based) at VividCortex: Database Performance Monitoring () (allows remote) - 130000 USD","We are hiring! Pay scales with experience. Find out more here https://underwearworker.com/jobs/10776","machinelearningjobs",43,0
"350",344,"MachineLearningJobs","[Hiring] Machine Learning (ML) Solutions Engineer","","machinelearningjobs",44,0
"351",345,"MachineLearningJobs","[Hiring] Machine Learning Engineer – Autonomous Driving","","machinelearningjobs",45,0
"352",404,"learnmachinelearning","Data Analysis with Python on real problems","I’m making a video series on Kaggle’s M5 forecasting competition and thought this would be a good example of a real world problem to learn from. This is the link to the first coding video if you are interested: https://youtu.be/7FwITPrBvLI","learnmachinelearning",4,0
"353",346,"MachineLearningJobs","[HIRING][REMOTE]Senior Python Software Engineer","What kind of candidates do we need?

 **Tools**:[Flask](https://bestremotejob.com/tool/Flask?&utm_source=reddit&utm_medium=MachineLearningJobs).[Reactjs](https://bestremotejob.com/tool/Reactjs?&utm_source=reddit&utm_medium=MachineLearningJobs).

**Languages**:[Python](https://bestremotejob.com/language/Python?&utm_source=reddit&utm_medium=MachineLearningJobs).[JavaScript](https://bestremotejob.com/language/JavaScript?&utm_source=reddit&utm_medium=MachineLearningJobs).[NoSQL](https://bestremotejob.com/language/NoSQL?&utm_source=reddit&utm_medium=MachineLearningJobs).

**Skills**:[Rest](https://bestremotejob.com/skill/Rest?&utm_source=reddit&utm_medium=MachineLearningJobs).

Interested in this job? Please **[apply here](https://bestremotejob.com/job/senior-python-software-engineer-sscs-inc?&utm_source=reddit&utm_medium=MachineLearningJobs)**","machinelearningjobs",46,0
"354",347,"MachineLearningJobs","[HIRING][REMOTE] 130000 USD - Senior Data Engineer at Tilda Research () (allows remote)","We are hiring! Pay scales with experience. Find out more here https://underwearworker","machinelearningjobs",47,0
"355",348,"MachineLearningJobs","[Hiring] Data Scientist","","machinelearningjobs",48,0
"356",349,"MachineLearningJobs","[Hiring] Senior Software Engineer – Data Science Platform","","machinelearningjobs",49,0
"357",350,"MachineLearningJobs","[Hiring] Senior Data Scientist","","machinelearningjobs",50,0
"358",351,"MachineLearningJobs","[Hiring] Data Engineer","","machinelearningjobs",51,0
"359",352,"MachineLearningJobs","[Hiring] Data Scientist, People Analytics","","machinelearningjobs",52,0
"360",353,"MachineLearningJobs","[HIRING][REMOTE] 110000 USD - Data Engineer at 7Bridges () (allows remote)","We are hiring! Pay scales with experience. Find out more here https://underwearworker.com/jobs/","machinelearningjobs",53,0
"361",354,"MachineLearningJobs","[Hiring] Data Scientist","","machinelearningjobs",54,0
"362",355,"MachineLearningJobs","[HIRING][REMOTE] Data Engineer - Porto or Lisbon at 7Bridges () (allows remote) - 110000 USD","We are hiring! Pay scales with experience. Find out more here https://underwearworker.co","machinelearningjobs",55,0
"363",356,"MachineLearningJobs","[HIRING][REMOTE]Content Writer at Dialpad @ Dialpad","What kind of candidates do we need?

 **Skills**:[SEO](https://bestremotejob.com/skill/SEO?&utm_source=reddit&utm_medium=MachineLearningJobs).

Interested in this job? Please **[apply here](https://bestremotejob.com/job/content-writer-48?&utm_source=reddit&utm_medium=MachineLearningJobs)**","machinelearningjobs",56,0
"364",357,"MachineLearningJobs","[Hiring] Computer Vision and Machine Learning Expert","","machinelearningjobs",57,0
"365",358,"MachineLearningJobs","[Hiring] Research Scientist at Thomson Reuters Labs","","machinelearningjobs",58,0
"366",359,"MachineLearningJobs","[HIRING][REMOTE] Senior Data Engineer at Backblaze, Inc. () (allows remote) - 100000 USD","We are hiring! Pay scales with experience. Find out more here https://underwearworker.com/jobs/1","machinelearningjobs",59,0
"367",360,"MachineLearningJobs","[Hiring][Internship] Software Engineer Internship – Summer 2020","","machinelearningjobs",60,0
"368",361,"MachineLearningJobs","[Hiring] Senior Data Scientist","","machinelearningjobs",61,0
"369",362,"MachineLearningJobs","[Hiring] Applied Scientist – AWS ML Platforms","","machinelearningjobs",62,0
"370",363,"MachineLearningJobs","[Hiring] Machine Learning Engineering Manager","","machinelearningjobs",63,0
"371",364,"MachineLearningJobs","[Hiring] Senior Machine Learning Applied Scientist","","machinelearningjobs",64,0
"372",365,"MachineLearningJobs","[HIRING][REMOTE] Business Data Analyst, Salesforce Innovation Center at Salesforce () (allows remote) - 130000 USD","We are hiring! Pay scales with experience. Find out more here https://underwearworker.c","machinelearningjobs",65,0
"373",366,"MachineLearningJobs","[Hiring] SCHEDULING SYSTEM ASSOCIATE (DATA ANALYTICS)","","machinelearningjobs",66,0
"374",367,"MachineLearningJobs","[HIRING][REMOTE]Senior Full Stack Engineer @ CB Insights","What kind of candidates do we need?

 **Tools**:[PostgreSQL](https://bestremotejob.com/tool/PostgreSQL?&utm_source=reddit&utm_medium=MachineLearningJobs).[Mysql](https://bestremotejob.com/tool/Mysql?&utm_source=reddit&utm_medium=MachineLearningJobs).[Reactjs](https://bestremotejob.com/tool/Reactjs?&utm_source=reddit&utm_medium=MachineLearningJobs).[Angular](https://bestremotejob.com/tool/Angular?&utm_source=reddit&utm_medium=MachineLearningJobs).[Vuejs](https://bestremotejob.com/tool/Vuejs?&utm_source=reddit&utm_medium=MachineLearningJobs).[Nodejs](https://bestremotejob.com/tool/Nodejs?&utm_source=reddit&utm_medium=MachineLearningJobs).[Amazon_Aurora](https://bestremotejob.com/tool/Amazon_Aurora?&utm_source=reddit&utm_medium=MachineLearningJobs).

**Languages**:[Python](https://bestremotejob.com/language/Python?&utm_source=reddit&utm_medium=MachineLearningJobs).

**Skills**:[Rest](https://bestremotejob.com/skill/Rest?&utm_source=reddit&utm_medium=MachineLearningJobs).[Linux](https://bestremotejob.com/skill/Linux?&utm_source=reddit&utm_medium=MachineLearningJobs).

Interested in this job? Please **[apply here](https://bestremotejob.com/job/2023360?&utm_source=reddit&utm_medium=MachineLearningJobs)**","machinelearningjobs",67,0
"375",368,"MachineLearningJobs","[HIRING][REMOTE]Associate Faculty – Bachelor of Science in Information Technology at Ashford University @ Ashford University","What kind of candidates do we need?

 **Tools**:[Mysql](https://bestremotejob.com/tool/Mysql?&utm_source=reddit&utm_medium=MachineLearningJobs).[Amazon_Web_Services](https://bestremotejob.com/tool/Amazon_Web_Services?&utm_source=reddit&utm_medium=MachineLearningJobs).[Bootstrap](https://bestremotejob.com/tool/Bootstrap?&utm_source=reddit&utm_medium=MachineLearningJobs).

**Languages**:[Python](https://bestremotejob.com/language/Python?&utm_source=reddit&utm_medium=MachineLearningJobs).[Java](https://bestremotejob.com/language/Java?&utm_source=reddit&utm_medium=MachineLearningJobs).[JavaScript](https://bestremotejob.com/language/JavaScript?&utm_source=reddit&utm_medium=MachineLearningJobs).[html](https://bestremotejob.com/language/html?&utm_source=reddit&utm_medium=MachineLearningJobs).[CSS](https://bestremotejob.com/language/CSS?&utm_source=reddit&utm_medium=MachineLearningJobs).[C++](https://bestremotejob.com/language/C++?&utm_source=reddit&utm_medium=MachineLearningJobs).[PHP](https://bestremotejob.com/language/PHP?&utm_source=reddit&utm_medium=MachineLearningJobs).

**Skills**:[Android](https://bestremotejob.com/skill/Android?&utm_source=reddit&utm_medium=MachineLearningJobs).

Interested in this job? Please **[apply here](https://bestremotejob.com/job/associate-faculty-bachelor-of-science-in-information-technology?&utm_source=reddit&utm_medium=MachineLearningJobs)**","machinelearningjobs",68,0
"376",369,"MachineLearningJobs","[HIRING][REMOTE] Senior Machine Learning - Series A Funded Startup - Onsite (SF or NYC) or Remote at Source Coders Inc (San Francisco, CA) (allows re","Wmeo taer)e  -h i1r1i0n0g0!0  PUaSyD scales with experience. Find out more here https://underwearworker.com/jobs/","machinelearningjobs",69,0
"377",375,"MachineLearningJobs","[HIRING][REMOTE]AWS Certification Content Creator at Cloud Academy @ Cloud Academy","What kind of candidates do we need?

 **Tools**:[Amazon_Web_Services](https://bestremotejob.com/tool/Amazon_Web_Services?&utm_source=reddit&utm_medium=MachineLearningJobs).[Puppet](https://bestremotejob.com/tool/Puppet?&utm_source=reddit&utm_medium=MachineLearningJobs).[Azure](https://bestremotejob.com/tool/Azure?&utm_source=reddit&utm_medium=MachineLearningJobs).[Git](https://bestremotejob.com/tool/Git?&utm_source=reddit&utm_medium=MachineLearningJobs).[Google_Cloud_Platform](https://bestremotejob.com/tool/Google_Cloud_Platform?&utm_source=reddit&utm_medium=MachineLearningJobs).[Chef](https://bestremotejob.com/tool/Chef?&utm_source=reddit&utm_medium=MachineLearningJobs).[Ansible](https://bestremotejob.com/tool/Ansible?&utm_source=reddit&utm_medium=MachineLearningJobs).

**Languages**:[Python](https://bestremotejob.com/language/Python?&utm_source=reddit&utm_medium=MachineLearningJobs).[Java](https://bestremotejob.com/language/Java?&utm_source=reddit&utm_medium=MachineLearningJobs).[C#](https://bestremotejob.com/language/C#?&utm_source=reddit&utm_medium=MachineLearningJobs).[Ruby](https://bestremotejob.com/language/Ruby?&utm_source=reddit&utm_medium=MachineLearningJobs).[PHP](https://bestremotejob.com/language/PHP?&utm_source=reddit&utm_medium=MachineLearningJobs).

**Skills**:[devops](https://bestremotejob.com/skill/devops?&utm_source=reddit&utm_medium=MachineLearningJobs).[Linux](https://bestremotejob.com/skill/Linux?&utm_source=reddit&utm_medium=MachineLearningJobs).

Interested in this job? Please **[apply here](https://bestremotejob.com/job/aws-certification-content-creator?&utm_source=reddit&utm_medium=MachineLearningJobs)**","machinelearningjobs",75,0
"378",376,"MachineLearningJobs","[Hiring] Machine Learning Engineer at Calico Labs - South San Francisco, CA","","machinelearningjobs",76,0
"379",377,"MachineLearningJobs","[HIRING][REMOTE] Senior Data Analyst (Remote) at komoot (Berlin, Germany) (allows remote) - 110000 USD","We are hiring! Pay scales with experience. Find out more here https://underwearworker.com/jobs/1","machinelearningjobs",77,0
"380",378,"MachineLearningJobs","[Hiring] Security – Data Engineer","","machinelearningjobs",78,0
"381",379,"MachineLearningJobs","[Hiring] Big Data Developer","","machinelearningjobs",79,0
"382",380,"MachineLearningJobs","[Hiring][Internship] Summer 2020 Machine Learning Co-Op/Intern","","machinelearningjobs",80,0
"383",381,"MachineLearningJobs","[Hiring] Manufacturing Engineer – Process Development & Data Science","","machinelearningjobs",81,0
"384",382,"MachineLearningJobs","[Hiring] Data Scientist, Ranking Engagement","","machinelearningjobs",82,0
"385",383,"MachineLearningJobs","[Hiring] Pinterest Labs Applied Scientist","","machinelearningjobs",83,0
"386",384,"MachineLearningJobs","[HIRING][REMOTE] Data Engineer at Mahisoft Inc () (allows remote) - 110000 USD","We are hiring! Pay scales with experience. Find out more here https://underwearworker.com/jobs/10651","machinelearningjobs",84,0
"387",385,"MachineLearningJobs","[Hiring] AI/ML Software Engineer","","machinelearningjobs",85,0
"388",386,"MachineLearningJobs","[Hiring] Siri End2End Team – Software Engineer","","machinelearningjobs",86,0
"389",387,"MachineLearningJobs","[Hiring] Research Scientist, AI & Fairness","","machinelearningjobs",87,0
"390",388,"MachineLearningJobs","[Hiring] Data Scientist – Digital Workplace Insights","","machinelearningjobs",88,0
"391",389,"MachineLearningJobs","[Hiring] Data Engineering Manager – Home","","machinelearningjobs",89,0
"392",390,"MachineLearningJobs","[Hiring] Data Scientist, Marketplace","","machinelearningjobs",90,0
"393",391,"MachineLearningJobs","[HIRING][REMOTE] 130000 USD - REMOTE Sr. Big Data/AWS Opening at Surge () (allows remote)","We are hiring! Pay scales with experience. Find out more here https://underwearworker.com/jobs/103","machinelearningjobs",91,0
"394",392,"MachineLearningJobs","[HIRING][REMOTE]Security Analyst, Senior Cybersecurity Threat Modeling @ Leidos","What kind of candidates do we need?

 **Skills**:[Blockchain](https://bestremotejob.com/skill/Blockchain?&utm_source=reddit&utm_medium=MachineLearningJobs).[SDLC](https://bestremotejob.com/skill/SDLC?&utm_source=reddit&utm_medium=MachineLearningJobs).

Interested in this job? Please **[apply here](https://bestremotejob.com/job/4924100-security-analyst-senior-cybersecurity-threat-modeling?&utm_source=reddit&utm_medium=MachineLearningJobs)**","machinelearningjobs",92,0
"395",393,"MachineLearningJobs","[HIRING][REMOTE]Marketing and Events Manager at House of Kaizen @ House of Kaizen","What kind of candidates do we need?

 **Tools**:[Google_Analytics](https://bestremotejob.com/tool/Google_Analytics?&utm_source=reddit&utm_medium=MachineLearningJobs).

**Skills**:[SEO](https://bestremotejob.com/skill/SEO?&utm_source=reddit&utm_medium=MachineLearningJobs).

Interested in this job? Please **[apply here](https://bestremotejob.com/job/marketing-and-events-manager?&utm_source=reddit&utm_medium=MachineLearningJobs)**","machinelearningjobs",93,0
"396",394,"MachineLearningJobs","[Hiring] Machine Learning Engineer, Bot Management","","machinelearningjobs",94,0
"397",395,"MachineLearningJobs","[HIRING][REMOTE] Big Data Engineer at Infiot (San Jose, CA) (allows remote) - 120000 USD","We are hiring! Pay scales with experience. Find out more here https://underwearworker.co","machinelearningjobs",95,0
"398",396,"MachineLearningJobs","[Hiring] Data Scientist","","machinelearningjobs",96,0
"399",397,"MachineLearningJobs","[HIRING][REMOTE]eLearning Copy Editor and QA Specialist at CoreAxis @ CoreAxis","What kind of candidates do we need?

 **Skills**:[SEO](https://bestremotejob.com/skill/SEO?&utm_source=reddit&utm_medium=MachineLearningJobs).

Interested in this job? Please **[apply here](https://bestremotejob.com/job/elearning-copy-editor-and-qa-specialist-2?&utm_source=reddit&utm_medium=MachineLearningJobs)**","machinelearningjobs",97,0
"400",398,"MachineLearningJobs","[Hiring] Machine Learning Engineer, Visual Search","","machinelearningjobs",98,0
"401",399,"MachineLearningJobs","[HIRING][REMOTE] Business Data Analyst, Salesforce Innovation Center at Salesforce () (allows remote) - 130000 USD","We are hiring! Pay scales with experience. Find out more here https://underwearworker","machinelearningjobs",99,0
"402",400,"learnmachinelearning","The most important papers on Human Pose Estimation","","learnmachinelearning",0,2
"403",401,"learnmachinelearning","Coronavirus (COVID-19) Pandemic: Initial Results for Automated Detection & Patient Monitoring using Deep Learning CT Image Analysis","","learnmachinelearning",1,3
"404",402,"learnmachinelearning","Data types in DS","","learnmachinelearning",2,0
"405",403,"learnmachinelearning","A Geometric Intuition to Dimensionality Reduction (LDA)","","learnmachinelearning",3,15
"406",405,"learnmachinelearning","Kaggle M5 forecasting competition evaluation","I made a video on how to write the WRMSSE evaluation metrics into code, using a naive forecast as example. Here’s the link to it if anyone’s interested: https://youtu.be/7FwITPrBvLI

And this is the Notebook where the code is stored: https://www.kaggle.com/qcw171717/naive-baseline/

My understanding is that we are only given the level 12 series and were to infer all the information regarding higher level series. If anything in the video felt wrong to you please let me know, that would really help.","learnmachinelearning",5,0
"407",406,"learnmachinelearning","how does tensorflow convert a picture into tensors ?","Can you explain to me how tensorflow or other librarys convert  a picture into a bunch of numbers ?","learnmachinelearning",6,0
"408",407,"learnmachinelearning","[Tutorial] Implementing the Levenshtein distance in Python for word autocorrection and autocompletion","Tutorial link:  [https://blog.paperspace.com/implementing-levenshtein-distance-word-autocomplete-autocorrect/](https://blog.paperspace.com/implementing-levenshtein-distance-word-autocomplete-autocorrect/)","learnmachinelearning",7,0
"409",408,"learnmachinelearning","Bus Network routing using Genetic Algorithm","Hi,

I am an undergrad currently developing a project to reroute an existing bus network using a genetic algorithm to plot more efficient routes to the existing bus stops. Does anyone have any advice on how to achieve this or reading material to help me with this project. 

Any advise or suggestion is appreciated

Thanks","learnmachinelearning",8,1
"410",409,"learnmachinelearning","Learning from Imbalanced Datasets","","learnmachinelearning",9,0
"411",410,"learnmachinelearning","Data preparation for predicting distance travelled by bus","I'm making a project where I want to predict the location of a bus at a  specific hour and day of week. My raw data looks like this: 

    line, brigade, signal_datetime   , latitude, longitude
    100 , 5      , 2020-1-22 12:33:20, 50.2125 , 22.1245
    100 , 5      , 2020-1-22 12:34:20, 51.2456 , 23.1245
    100 , 2      , 2020-1-22 12:33:20, 52.1246 , 21.1245

 From this I make a time series for every  bus looking like this: 

    line, brigade, signal_time, signal_dayofweek, distance_travelled
    100 , 5      , 12:30:14   , 1               , 1001
    100 , 5      , 12:31:14   , 1               , 1010

The problem with this approach is that I will end up with multiple time series for a specific day of the week *(eg. the bus travelled 1001 meters at 12:30:14 this monday, but the previous week it had travelled 995 meters at that time)*.  I'm not sure what would be the best way to feed this data into a machine learning model so that it can learn by going through all of the  collected time series. Any help or recommended reading would be  appreciated since I'm a machine learning beginner.

Thank You in advance!","learnmachinelearning",10,0
"412",411,"learnmachinelearning","What is a Neural Network? ANNs explained for EVERYONE in a minute!","","learnmachinelearning",11,0
"413",412,"learnmachinelearning","Sharing some informative blog posts on deep learning","Stepping into the field of deep learning, I've realized that sometimes an **informative blog post** could serve as an extremely helpful friend to guide you through *learning* and *researching*. So I decided to **gather** all the **informative** and **well-explained** blog posts I've ever read and hoping to get some more from you guys :)

**Sources link**: [https://ckli.xyz/sourcehub/deep-learning/](https://ckli.xyz/sourcehub/deep-learning/)","learnmachinelearning",12,0
"414",413,"learnmachinelearning","I want to form a 3 to 4 person team of ML learners","**THIRD EDIT**

Here is the discord channel. [https://discord.gg/qxzaS3](https://discord.gg/qxzaS3) If you have pm'd me and I haven't responded, please know that I'm getting rate limited by reddit or something... I can't message you back. Once you're on there, say hi and introduce yourself!

**SECOND EDIT**

Lol. Currently overwhelmed by the number of messages. I've started a discord server and am inviting people. Discord allows for more fluid conversation although in the end it will still end up being a crowd of people, and will lack the personal feel of a 3\~4 person team.

Nevertheless, it's very interesting to see how many people are looking for this. So, if this post interests you I'll suggest the following:

Treat it is a mega-thread and post your level and topic of interest. Look for other people who have done the same. And try to form a team

My level is beginner-intermediate (but with physics and mathematical background) and I'm mostly interested in computer vision.

PM me if you want to check out the discord server, or if you're directly interested in forming a small team for a computer vision competition or paid gig.

========

Last year in October I quit my well paying job and decided to go full throttle learning AI. I spend some of my time doing quick programming jobs on Upwork to make some money on the side, but most of my time I spend gobbling up everything I can in deep learning and at the moment computer vision (last week I read all three RCNN papers then used Detectron to locate and classify statues in images).

I'm super passionate about it and having a great time. I have a technical background, so I'm picking it up quickly.

The only problem is I have no one to team up with. I live alone in a hypothetical cave and I absolutely spam the hell out of stack exchange. The rare chances I get to talk to someone who knows anything about AI it's a relief, and I'm sad to end the conversation.

If you're in a similar place to me, let's form a team. We can spur each other on, learn from each other, and team up for Kaggle competitions and jobs. Or just a bit of that... I'm chill.

PM me or/and upvote if you're interested.

**EDIT**

It's awesome that this is getting so much traction. Please send me an actual PM if you'd really like to join the group. Bit challenging keeping track of the comments on the thread.","learnmachinelearning",13,63
"415",414,"learnmachinelearning","AI Learns To Play Super Mario Bros Using A Genetic Algorithm And Neural Network","","learnmachinelearning",14,1
"416",415,"learnmachinelearning","Unconstrained vs. Constrained","Hi! Can anyone explain to me (in Layman's terms) how a problem is classified into the two categories? I'm currently learning about optimization methods and this would help me greatly in understanding how to solve a problem.","learnmachinelearning",15,1
"417",416,"learnmachinelearning","First ML Submission on Kaggle ML Titanic Challenge — 77% accuracy! (: Any ideas how I could improve to get better?","I’m at a break point between considering my self a complete newbie and having a general idea of what I’m doing when it comes to ML with python. 

This last week I finished up my ML Titanic challenge on kaggle with a decision tree training model and a logistic regression model. I’ve been hovering around 77% percent accuracy and have tried extracting as many features as possible from the data set; unfortunately it seems that the label most heavily favorited is the gender and none of the other features do much to increase accuracy (when i run the model with just gender it does not differ much when I run it with the rest of the labels).

I’m pretty happy with the results so far cause my knowledge of python and ML has improved a lot but want to get better. 


I’m curious does anyone who is familiar with this challenge have any tips on what I could do to get my accuracy higher that would help me learn new ML methods? 

Thanks!","learnmachinelearning",16,2
"418",417,"learnmachinelearning","Does pca require labels?","Can pca be done fully unsupervised? without a response variable? I am interested in using pca for outlier detection.

Thanks!","learnmachinelearning",17,2
"419",418,"learnmachinelearning","Architectural Engineering vs Feature Engineering","First time poster here.

I wanted to understand how deep learning really changes the workflow and job of a data scientist? 

I have read in places that you basically don't have to deal with feature engineering and instead architecture engineering becomes the focus for Deep Learning. Would love to hear more from those with practical experience.

P.S. any good resources to begin reading will be also be super helpful.

Thank you","learnmachinelearning",18,4
"420",419,"learnmachinelearning","A Roadmap For How To Become A Machine Learning Engineer","I have written an [article](https://megacog.com/post/ACfrUhFsg0) detailing what I think a Machine learning engineer's journey should look like. I hope it helps those who are just starting or those who are considering it. Those who are already well along in the field, what else would you contribute to this [article](https://megacog.com/post/ACfrUhFsg0)?","learnmachinelearning",19,0
"421",420,"learnmachinelearning","JSML (MACHINE LEARNING IN JAVASCRIPT)","So I created a community about machine learning. The thing is it is all about JavaScript stuff.
THIS COMMUNITY IS JUST STARTING NOW SO WE NEED SOME MODERATORS. YOU COULD BECOME ONE OF THEM.
Join r/jsml NOW!","learnmachinelearning",20,0
"422",421,"learnmachinelearning","Normalization of features with same scales","Hello,

I was developing an SVM classifier (kernel rbf) for a dataset (all the features have the same scale) when I faced the following question. When is it necessary to normalize the data? 

Most of the people suggest to normalize the data when the scale of the features is different but I don’t know if it is necessary when the features have the same scale. 

Also, if anyone knows, I have the same question for other classifiers (SVM linear kernel, 1D conv, …) and PCA.

Thank you in advance.","learnmachinelearning",21,1
"423",422,"learnmachinelearning","Shaping input for Keras LSTM","I'm working on NASA C-MAPSS  dataset which contains sensor measurements (timeseries). Dimension of the training set is  (20631, 17), the rows are measurements from 100 engines and columns are the measured 17 sensors.

I'm having a problem shaping this dataset to feed it into an LSTM model in keras. I know LSTM layer takes input with shape (batch\_size, sequence\_length, features) but I still can't make it work.

Let's say sequence\_length is 6 and batch\_size is 32, there are 17 features. How do I shape the set?

For the output, I have a value (Remaining Useful Life) for each row in the data, I want either to do many-to-one model where I outputs a single value at the end of each sequence, or many-to-many where I get 6 outputs for a sequence of 6.","learnmachinelearning",22,3
"424",423,"learnmachinelearning","Big Data Analytics with PySpark + Power BI + MongoDB","If you want to, check it out below:

[https://www.udemy.com/course/big-data-analytics-with-pyspark-power-bi-mongodb/?referralCode=F8D077DD33FFBF7B7077](https://www.udemy.com/course/big-data-analytics-with-pyspark-power-bi-mongodb/?referralCode=F8D077DD33FFBF7B7077)

https://preview.redd.it/p0kfs9hbwqm41.png?width=2560&format=png&auto=webp&s=c9548457c7e49f816e4699e4863e60f5d3074ec6","learnmachinelearning",23,1
"425",424,"learnmachinelearning","How would you preprocess features like these?","","learnmachinelearning",24,19
"426",425,"learnmachinelearning","Be an Influencer in the field of AI/ML. Make your voice heard AND get rewarded!","Hey Redditors!

Influence the future of cutting-edge technology by participating in upcoming user research opportunities with [UEGroup](https://www.uegroup.com/), a user experience research and design firm based in Silicon Valley. 

We need you to help drive the future of software development tools in Machine Learning, Deep Learning & Computer Vision!

Sign up for our database [here](https://airtable.com/shr9rSzx4a56JOyhD) and help improve the products of the future while getting paid for your time!","learnmachinelearning",25,0
"427",426,"learnmachinelearning","Colab can’t find chromedriver path","I’m trying to create datasets on Google Colab using the google\_images\_download  
 library. Despite installing the chrome driver, it’s not able to find it.

Here are my code cells:

&#x200B;

    %reload_ext autoreload
    %autoreload 2
    %matplotlib inline
    
    !pip install google_images_download
    
    !wget https://chromedriver.storage.googleapis.com/2.42/chromedriver_linux64.zip  && unzip chromedriver_linux64
    
    import os
    #Mount the drive from Google to save the dataset
    from google.colab import drive # this will be our driver
    drive.mount('/gdrive')
    root = '/gdrive/My Drive/'     # if you want to operate on your Google Drive
    
    colab_path = '/gdrive/../content/'
    
    chromedriver_path = '/gdrive/../content/chromedriver'
    
    from google_images_download import google_images_download   #importing the library
    
    keyws   = ""jaguar""
    limit   = 1000
    chromedriver = chromedriver_path
    offset  = None  # how many links to skip
    color_type  = None# color type you want to apply to the images.[full-color, black-and-white, transparent]
    size    = None  #relative size of the image to be downloaded. [large, medium, icon, >400*300, >640*480, >800*600, >1024*768, >2MP, >4MP, >6MP, >8MP, >10MP, >12MP, >15MP, >20MP, >40MP, >70MP]
    usage_rights    = 'labeled-for-reuse' #Very important! Check the doc
    
    arguments = {
            ""keywords"" : keyws,
            ""limit"" :limit,
            ""chromedriver"":chromedriver,
            ""offset"" : offset,
            ""color_type"" : color_type,
            ""size"" : size,
            ""usage_rights"" : usage_rights
            }   #creating list of arguments
    response  = google_images_download.googleimagesdownload()   #class instantiation
    response.download(arguments)  

And this is the error:

&#x200B;

    Item no.: 1 --> Item name = jaguar
    Evaluating...
    Looks like we cannot locate the path the 'chromedriver' (use the '--chromedriver' argument to specify the path to the executable.) or google chrome browser is not installed on your machine (exception: Message: Service /gdrive/../content/chromedriver unexpectedly exited. Status code was: -6
    )
    An exception has occurred, use %tb to see the full traceback.
    
    SystemExit
    /usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.
      warn(""To exit: use 'exit', 'quit', or Ctrl-D."", stacklevel=1)

This is the file structure (Sorry about the transparency. My screenfetch does that for some reason):

&#x200B;

&#x200B;

https://preview.redd.it/cbszj5wjjqm41.png?width=319&format=png&auto=webp&s=262cbca525442541b584ba10d8e97f331bb70d26","learnmachinelearning",26,0
"428",427,"learnmachinelearning","Variational Autoencoder for Novel Drug Design","I want to mimic the architecture laid out in this paper: [https://jcheminf.biomedcentral.com/articles/10.1186/s13321-018-0286-7](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-018-0286-7)

The code was posted here, but it is written using an outdated version of tensorflow: [https://github.com/jaechanglim/CVAE](https://github.com/jaechanglim/CVAE)

From what I've read, its a variational autoencoder, used to generate molecular structures that are conditioned on a few desired properties. I am having trouble coming up with the most efficient way to port this to Keras. I'm also struggling to understand how to implement stacked LSTM cells in the encoder and decoder networks, like they do in the paper.","learnmachinelearning",27,1
"429",446,"learnmachinelearning","Time Series ACF and PACF interpretation","Hello.  I am currently working on a time series dataset. Unfortunately I hesitate into putting the actual images her, but essentially, when I look at the acf and pacf plots I see spikes at lags 1 and 5. So the lag at 1 means to me that the order of the q and d is 1. However what should I do about the lag a 5? Add  seasonal component with s = 4 and P and Q equal to 1?

&#x200B;

Thanks for the help guys!","learnmachinelearning",46,0
"430",428,"learnmachinelearning","Max-margin loss not converging.","Hello everybody. I want to train a neural network to predict similarity between natural language queries and code, like CodeSearchNet. I am utilizing transformer encoders to encode queries and code, then I max pool to obtain the sentence embeddings and I compute the cosine similarity between each true pair and their negative pairs. The problem is that my loss function does not decrease bellow the margin value and all sentence embeddings and cosine similarities collapse towards a single point.

 I experimented adding a softmax layer to softmax the cosine similarities. I tried to normalize the embeddings, tweak the learning rate and batch size but without any luck. Can anybody help me and explain to me what is wrong with my implementation? 

 This is my full code: [https://colab.research.google.com/drive/1keYkHBw8SkIrM1CnaOb09ojG06TZyJW1](https://colab.research.google.com/drive/1keYkHBw8SkIrM1CnaOb09ojG06TZyJW1)","learnmachinelearning",28,0
"431",429,"learnmachinelearning","Math help","Hey everyone, I was wondering if anyone can provide resources to get familiar with matrix calculus in the context of ML?  

I am currently in taking a graduate-level machine learning course ( there is no undergraduate version at my university ) and I am finding the math and proofs rather challenging. I have previous experience using sklearn and PyTorch, I took Andrew Ngs ML course and Deep Learning Specialization;  I would say that I basic intuition of different algorithms and programming ML.

I am taking this class to learn the mathematical formulation of different algorithms, which the previous experiences mentioned did not necessarily go over in detail.

Since my undergraduate degree in CS is a BA, we did not have to take multivariable calculus( we only had to go up to Calc1, sad I know ), which is essential for this class as I soon realized. Even asking my friends who took multivariable calculus, they also said matrix calculus was not covered much.

&#x200B;

Again, any help or advice would be greatly appreciated. Thanks!","learnmachinelearning",29,2
"432",430,"learnmachinelearning","Good resources to stay up to date?","Can anyone recommend some good resources to stay up to date on advances and new trends in machine learning? I want to get into the field but I'm not really sure how to stay in-the-know.","learnmachinelearning",30,2
"433",431,"learnmachinelearning","[P] I wrote a tutorial of Stacked Hourglass network for Pose Estimation. Love to gather some feedback!","","learnmachinelearning",31,1
"434",432,"learnmachinelearning","Uppercase and Lowercase alphabets in a dataset","Training a model with 5000 uppercase images of letter 'A' and 5000 lowercase images of letter 'A'. Wont this confuse our model since the features of uppercase 'A' is totally different that lowercase 'A'.","learnmachinelearning",32,0
"435",433,"learnmachinelearning","Best strategies for data preprocessing?","I am working on a machine learning project where i am at the data preprocessing stage right now.  The dataset is composed of both continuous and categorical biomedical features.  Regarding the categorical features, i one-hot encoded them.

I don't know how to handle the continuous features.  Most of them are results from lab exams and each of them has its own range.   The rest of the continuous features are stuff like age and cigarettes per day.

Should i proceed with standardisation? Should i discretize them? Can i apply different techniques for different features? Is there any golden rule?

Thanks in advance","learnmachinelearning",33,0
"436",434,"learnmachinelearning","Commination of all my Deep RL work around Snake","","learnmachinelearning",34,2
"437",435,"learnmachinelearning","Guide on Hyperparameter Tuning and Turning Predictions Into an Application and API | Predicting Runescape Grand Exchange Prices with Machine Learning Final Video","","learnmachinelearning",35,0
"438",436,"learnmachinelearning","🎥 Video Labeling tool for Deep Learning: training data for Computer Vision with Supervisely","","learnmachinelearning",36,0
"439",437,"learnmachinelearning","Machine learning path for beginners","With so many content on machine learning and AI, it is quite easy to get overwhelmed. What's the proper guide one should follow to get into this field?","learnmachinelearning",37,37
"440",438,"learnmachinelearning","What after Machine learning Andrew Ng","It took me almost 1 month to complete ML Coursera (Andrew Ng) course, but it was in octave. Then I learner python a bit from youtube videos. 
For now, I've completed 1/4 courses of Machine learning specialization (deeplearning.in), It was on Deep NN in python. the programming assignments were more of fill in the blanks type.
I tried implementing it on Titanic Kaggle problem, but I was doing copy paste work.
I want to know what should I do now, any course or book that will help me code from scratch ?","learnmachinelearning",38,7
"441",439,"learnmachinelearning","Any Toronto based NLP PHDs I can talk to?","Have an NLP idea that would automate contract negotiations.

Hoping to bounce the idea off someone to test how feasible it is.

Let me know if you are happy to chat here or in-person :)","learnmachinelearning",39,1
"442",440,"learnmachinelearning","List of tools and frameworks for data annotation","","learnmachinelearning",40,1
"443",441,"learnmachinelearning","Advice Appreciated","I recently finished Andrew Ng's Machine Learning course on coursera and I am looking to find a new course that incorporates more Python. I was looking at the Michigan Applied Data Science with Python course but was wondering if anyone had any other recommendations or reviews for this course. Thank you!!

\*I would say I am a beginner/intermediate Python programmer, I have a taken a couple courses but I frequently look to stack overflow for guidance.","learnmachinelearning",41,2
"444",442,"learnmachinelearning","Multiple Epochs and Overfitting","I’m new to ML, so pardon the naïve question. What is the purpose of using multiple epochs if you use the same training data? Why isn’t one epoch sufficient to train a model? Also, how do I know if I am overfitting or underfitting a model? Is this determined by the test data? I’m assuming so. What metrics should I use to determine if my model is overfit?

Thank you!","learnmachinelearning",42,3
"445",443,"learnmachinelearning","Easiest approach to learn machine learning?","","learnmachinelearning",43,0
"446",444,"learnmachinelearning","Covid-19 Korea dataset with 4000 patient routes","","learnmachinelearning",44,1
"447",445,"learnmachinelearning","Object Detection: Training on cropped, not labelled images","Hi all, 

I'm basically using this [guide](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html) \- except that the images that I have are already cropped around the objects I'm training to recognize (only one label/type of object), so I made the annotation-files to use the entire image as an object.  

I have now trained around 5000 ""steps"", with a loss of 0.3433 - and when I'm testing with webcam, the whole videframe is detected as my one label.

Anything I'm doing wrong?","learnmachinelearning",45,7
"448",447,"learnmachinelearning","Weekly Status Check Meeting - Share your progress, your goals, and whatever is stopping you from achieving those goals!","Let's have a  meeting!

1. What have you accomplished since last week?
2. What are your goals for next week?
3. Do you have any blockers that need helps from the /r/LearnMachineLearning community?

Don't be pressured to fill out all three questions! If you just want to celebrate your progress, just share that. If you have been planning something, you can make this meeting your first step towards your goal. If you are stuck from making a progress, feel free to just ask a question.","learnmachinelearning",47,0
"449",448,"learnmachinelearning","The 4 Steps of Building Machine Learning Systems","","learnmachinelearning",48,0
"450",449,"learnmachinelearning","Deep learning-based Segmentation: COVID-19","","learnmachinelearning",49,1
"451",450,"learnmachinelearning","Significance and Deployment of Edge Machine Learning for Businesses","","learnmachinelearning",50,0
"452",451,"learnmachinelearning","Significance and Deployment of Edge Machine Learning for Businesses","","learnmachinelearning",51,0
"453",452,"learnmachinelearning","Coursera Pi Day Event select Data Science and ML programs going at $3.14","Consider enrolling in Data Science and ML certs on Coursera with [Pi Day event](https://www.google.com/amp/s/onlinecoursesgalore.com/coursera-pi-day-promo/amp/)","learnmachinelearning",52,4
"454",453,"learnmachinelearning","How should I implement a tangent function as Karas layer?","I have an LSTM, and output is nonlinear, it can only go up to about 0.716. Therefore, I have two dense layers to get the predictions go out to 99, where it belongs. Therefore, I want to put tangent function on the output, because I think it will increase accuracy by making it go all the way out to 99, without using a trained layer.","learnmachinelearning",53,0
"455",454,"learnmachinelearning","Question about standard deviation and variance","If I were to make a random Forest model where I have several variables as inputs, would it be unwise to include both standard deviation and variance in the training of the model? I know they are correlated but I am unsure if I should exclude one.","learnmachinelearning",54,8
"456",455,"learnmachinelearning","Respiratory patterns: COVID-19","","learnmachinelearning",55,0
"457",456,"learnmachinelearning","Diffusion Map for non-linear dimensionality reduction","I just wrote a blog post on what is a diffusion map, brief theory and its implementation in python. Hope it will be useful. 

**Blog link**: [https://randomwalk.in/python/ml/2020/03/14/Diffusion-Map.html](https://randomwalk.in/python/ml/2020/03/14/Diffusion-Map.html)

**Source Code**: [https://gist.github.com/rahulrajpl/36a5724d0c261b915292182b1d741393](https://gist.github.com/rahulrajpl/36a5724d0c261b915292182b1d741393)

**Original Paper**: [https://inside.mines.edu/\~whereman/talks/delaPorte-Herbst-Hereman-vanderWalt-DiffusionMaps-PRASA2008.pdf](https://inside.mines.edu/~whereman/talks/delaPorte-Herbst-Hereman-vanderWalt-DiffusionMaps-PRASA2008.pdf)","learnmachinelearning",56,2
"458",457,"learnmachinelearning","[Q] How to deseasonalize time-series data for LSTM","Hi I am trying to fit some LSTM networks onto time-series sales data that is over the length for two years. I've heard that deseasonalizing the data is best when trying to work with LSTM. But I'm confused as to how to actually do that?

Would that just involve setting a temporal value such as a week number or month/quarter/season value as a feature-attribute in my dataset?","learnmachinelearning",57,1
"459",458,"learnmachinelearning","MLOps: not as Boring as it Sounds","Have you heard of MLOps? When I first heard the term, I admit my first reaction was; ‘Boring!’, and I rolled my eyes like you’re supposed to when you say stuff like that.

Well, in fact MLOps is going to make your data science life a lot better. Why? Read more through the link below: https://itnext.io/mlops-not-as-boring-as-it-sounds-eaebe73e3533?source=friends_link&sk=ecc6c8749443abe2112e33faa648baab","learnmachinelearning",58,5
"460",459,"learnmachinelearning","Faster RCNN's RPN in PyTorch","While trying to implement Faster RCNN with PyTorch, I came across a great guide [here](https://medium.com/@fractaldle/guide-to-build-faster-rcnn-in-pytorch-95b10c273439), and got confused by the operations happening after the IoU calculation stage, especially what each of the resulting 3 arrays is.

I understand that positive labels are to be assigned to anchors, whose IoU:

1. is greater than 0.7 or
2. just have the closest max to the bounding box

while negative to anchors whose IoU is less than 0.3. The rest are don't cares.

Could someone please explain what's happening [here](https://i.stack.imgur.com/rkPql.png) in the following section?

>Consider the scenarios of a and b, we need to find two things here the highest iou for each gt\_box and its corresponding anchor box the highest iou for each anchor box and its corresponding ground truth box  
>  
>**case-1**  
>  
>gt\_argmax\_ious = ious.argmax(axis=0)  
>  
>print(gt\_argmax\_ious)  
>  
>gt\_max\_ious = ious\[gt\_argmax\_ious, np.arange(ious.shape\[1\])\]   
>  
>print(gt\_max\_ious)  
>  
>Out: # \[2262 5620\]   
>  
>\# \[0.68130493 0.61035156\]  
>  
>**case-2**  
>  
>argmax\_ious = iou.argmax(axis=1) print(argmax\_ious.shape) print(argmax\_ious)   max\_ious = ious\[np.arange(len(inside\_index)), argmax\_ious\] print(max\_ious) # Out: # (22500,) # \[0, 1, 0, ..., 1, 0, 0\] # \[0.06811669 0.07083762 0.07083762 ... 0.         0.         0.\]  
>  
>Find the anchor\_boxes which have this max\_ious (gt\_max\_ious)  
>  
>gt\_argmax\_ious = np.where(ious == gt\_max\_ious)\[0\] print(gt\_argmax\_ious) # Out: # \[2262, 2508, 5620, 5628, 5636, 5644, 5866, 5874, 5882, 5890, 6112, #        6120, 6128, 6136, 6358, 6366, 6374, 6382\]  
>  
>Now we have three arrays  
>  
>argmax\_ious - Tells which ground truth object has max iou with each anchor.  
>  
>max\_ious - Tells the max\_iou with ground truth object with each anchor.  
>  
>gt\_argmax\_ious - Tells the anchors with the highest Intersection-over-Union (IoU) overlap with a ground-truth box.  
>  
>Using argmax\_ious and max\_ious we can assign labels and locations to anchor boxes which satisfy \[b\] and \[c\]. Using gt\_argmax\_ious we can assign labels and locations to anchor boxes which satisfy \[a\].

Plus, are the ground-truth boxes supposed to be fed directly to the RPN?","learnmachinelearning",59,0
"461",460,"learnmachinelearning","Google’s Objectron uses AI to track 3D objects in 2D video","","learnmachinelearning",60,1
"462",461,"learnmachinelearning","Weight of Evidence (WOE) and Information Value (IV) Explained","","learnmachinelearning",61,0
"463",462,"learnmachinelearning","StyleGAN v2: notes on training and latent space exploration","","learnmachinelearning",62,11
"464",463,"learnmachinelearning","Need idea for a fleet ML project","Hello, all. I’m helping someone who manages a large fleet of vehicles and I’m thinking there’s ML opportunity there. Anyone have any case studies of hertz or greyhound or someone using ML to solve a business problem with a fleet, like predicting maintenance or reducing accidents, etc?","learnmachinelearning",63,2
"465",464,"learnmachinelearning","What Data Science course do you want to learn next?","Hi again - I am taking a quick 30 sec. survey from a random sample set of data science learners to understand their learning expectations. 

If you are interested, please feel free to fill your choice of course and also pl. feel free to circulate within your group/network. (survey is not mandatory - Pl. fill only if you are interested). 

Thanks in advance for your feedback!

[https://docs.google.com/forms/d/1wRmmrlIyanpwxbb0-heheI-vCGV4LyMXnapm\_9DgOvI](https://docs.google.com/forms/d/1wRmmrlIyanpwxbb0-heheI-vCGV4LyMXnapm_9DgOvI/edit)","learnmachinelearning",64,0
"466",465,"learnmachinelearning","Descriptive answer evaluation for computer science domain questions.","We are ssigned with a project to grade students examination answers using deep learning. The faculty would upload  key answer and the model needs to be able to grade students accordingly. To do so we thought to use semantic similarity using word2vec. I am not sure how to approach the problem though since I am brand new to NLP, can you guys help me with relevant links? Thanks.","learnmachinelearning",65,0
"467",466,"learnmachinelearning","I Needed a Tool to Search My Jupyter Notebooks, so I Wrote One. Here It Is.","[I released an open source library to search your local Jupyter Notebooks](https://github.com/gitjeff05/kapitsa). 

*The long version:*

As I have been working in Jupyter. some common problems arise:

1. I need to perform some operation (e.g., merge dataframes), but cannot recall the API. I’ve previously performed this operation in another notebook, but cannot recall its location.

2. Id like to tag Jupyter cells using my own taxonomy so that searching them is trivial.

3. I’d like to curate a set of code samples (e.g., a cheat sheet) from existing notebooks.

4. A list of all recently modified notebooks would be useful.

To address these, I built a tool in bash to query local notebooks. I have found it quite useful and have decided to release it on github.

Feedback and feature requests welcome.","learnmachinelearning",66,2
"468",467,"learnmachinelearning","Ideas for a reinforcement learning project to work on","Hi people,

So, I'm taking a graduate-level reinforcement learning course and have to start a final project. The goal and idea for the project are of my choosing. My thesis is actually in computer vision, so I'm taking this course primarily of out interest. That said, I haven't thought too heavily for what to work on, so this is where you could potentially come in.

It would be awesome if any of you suggested some ideas that have really got your head scratching recently! Additionally, I'd be really interested in reinforcement learning for computer vision tasks (object detection, segmentation, tracking, etc.) or stock trading (day trading, active portfolio management). This project is supposed to take roughly 70 hours of manpower.

I was thinking that if I do decide to puruse one of your ideas, I could update my progress on this post as I work on the project.

Thanks!","learnmachinelearning",67,11
"469",468,"learnmachinelearning","[Python] How do I know that RepeatedStratifiedKFold is actually working as it should?","Hey guys, I am trying to choose a method to split my data into train and test sets. 

According to the Scikit-Learn documentation, the RepeatedStratifiedKFold is a:

>Repeated Stratified K-Fold cross validator. Repeats Stratified K-Fold n times **with different randomization in each repetition**.

However, when I implement the CV method on a dataset of 1000 observations as so with 5 folds and 100 repetitions,

*rskf = RepeatedStratifiedKFold(n\_splits=5, n\_repeats=100, random\_state=None)*

*for train\_index, test\_index in rskf.split(X, y):*

*X\_train, \_X\_test = X\[train\_index\], X\[test\_index\]*

*y\_train, y\_test = y\[train\_index\], y\[test\_index\]*

And then take a look at the the x\_*train* set, I only see 800 observations (4 train folds). Should it not contain all 100 train sets as per the number of repetitions? 

My second question is after splitting your data using the RepeatedStratifiedKFold method, what happens when you fit your classification model on the X\_train and y\_train datasets? Does it train on all 100 repetitions? 

What if I just wanted F1-score from the model after testing it? Does it give me the average score using all 100 repetitions? 

Thanks!","learnmachinelearning",68,0
"470",469,"learnmachinelearning","Understanding research papers","Hello everyone, I am new to this field and I have been trying to read research papers but I fail to understand most of them as I lack background knowledge. Is there anything someone can advise me to do for this? Should I read some books or do a course or read articles and stuff like that?  Is there a way to go about it?

I would be really happy to hear your journey!

PS: I want to learn DL and RL with respect to Robotics.","learnmachinelearning",69,4
"471",470,"learnmachinelearning","Walkthrough of my first deep learning project. Pokemon image classification.","I recently finished working on a Pokemon classifier using CNN's. I put together a notebook describing my process. 

The notebook can be found  [here.](https://github.com/bscottnz/Projects/blob/master/PokeNet.ipynb)

Please comment any questions or suggestions for improvement.","learnmachinelearning",70,2
"472",471,"learnmachinelearning","What is the Difference Between CNN and RNN?","","learnmachinelearning",71,3
"473",472,"learnmachinelearning","Is there a special trick to avoid cut and paste programming, or should I just become more experienced?","","learnmachinelearning",72,7
"474",473,"learnmachinelearning","Feature engineering question","If a continuous feature X is insignificant (p-value > .05) in my regression model, would transforming it (i.e. log(X), e^x, etc.) make it significant or is significance relatively static regardless of transformation?","learnmachinelearning",73,0
"475",474,"learnmachinelearning","There is more to linear regression than just OLS. I tried to explain different variations of linear regression in one video.","","learnmachinelearning",74,0
"476",475,"learnmachinelearning","In tensorflow Keras, what is model.add()?","","learnmachinelearning",75,4
"477",476,"learnmachinelearning","Machine Learning path for senior CS student?","I am a senior in CS and have a minor in math (I've taken all available calculus, advanced statistics, and linear algebra). I've wanted to learn machine learning for a couple years now and would like to know the best starting path I can take given my skill level and experience currently (top student, multiple top internships, etc.). 

&#x200B;

What is the best way to start and where? Any advice is appreciated from someone who learned starting around the same time I am trying to.","learnmachinelearning",76,1
"478",477,"learnmachinelearning","What am I doing wrong here: calculating partial derivative of Cost with respect to activated neuron1","I have a perceptron with only one hidden layer. The input, hidden and output layers all have two neurons each.
 
____________


Considering the first neuron in the hidden layer: When computing the partial derivatives during back propagation, how can you calculate the partial derivative of cost with respect to the activation value of this neuron? 


Cost function explicitly depends on the activated values of the two neurons in the output layer (a3, a4), but only implicitly to a1 and a2 (activated values of two neurons in hidden layer)
 
____________


Note: weighted sum = denoted as z
 
activated value(a): value of z after applying sigmoid function
 
__________


Please see drawing here:


https://imgur.com/qE1IUHM



...and advise if we need to denote a3 and a4 in terms of a1 and a2 for the partial derivatives.","learnmachinelearning",77,0
"479",478,"learnmachinelearning","What does random_state does in sklearn.utils.resample?","","learnmachinelearning",78,3
"480",479,"learnmachinelearning","Gradient Descent for Parameter Tuning?","I have a black box function that I'm trying to minimize.  The function takes some set of real number parameters.  Right now I'm using a grid search technique to minimize the function, but that is getting to be expensive.  What I need is an some help explaining how to use something like SGD or other hill climbing method.  How does one compute the partial derivative of an unknown function? Thanks!","learnmachinelearning",79,1
"481",480,"learnmachinelearning","Graphs in ML and Label Propagation 101","","learnmachinelearning",80,0
"482",481,"learnmachinelearning","Face Touching Detector","I hacked together a site last night that watches your webcam and plays a sound when you touch your face. I used handtrack.js for the hand tracking and face-api.js for the face detection, so everything runs on the client. There were two main technical challenges..

1) Getting these two libraries to work together.

2) They are both very opinionated in how they want to use the video element

The hand tracker has a lot of ironic false positives in that it detects the face as a hand itself. I wrote a quick algorithm that tries to identify the same hand across frames and only considers things hands if they started near the bottom of the screen.

It's ugly but mostly gets the job done. Would love to hear feedback: [https://notouchchallenge.com/](https://notouchchallenge.com/)

Though I normally write in React components, I hacked this together with just regular HTML/CSS/JS as a proof of concept. The code is on [github](https://github.com/vedran/notouchchallenge.com)","learnmachinelearning",81,4
"483",482,"learnmachinelearning","Learn how to write Neural Network from scratch and train to detect Handwritten Digits in TensorFlow 2","","learnmachinelearning",82,1
"484",483,"learnmachinelearning","Derivation of winograd filter transform matrices","","learnmachinelearning",83,0
"485",484,"learnmachinelearning","Question about cross validation","Hey guys I had a question regarding GridSearchCV. Should I use train_test_split first and then past the training data from train_test_split to GridSearchCV or directly pass my original data through GridSearchCV","learnmachinelearning",84,2
"486",485,"learnmachinelearning","Need insights and guidance for my mini project for ML learning","Hello Everyone, 

After few courses and some basic ABC ML applications , I am at the step where i usually try to apply an idea I got (no matter how easy it seems , it just have to be interesting for me so I can keep engaged in learning) .  


I did generate my data which consist for each line (9500 lines) of integers (1 int value )as inputs and sequence of integers (315 int value )as output .   My DataFrame is [here](https://github.com/H-Ismael/Collatz_PandasDF) to see what I am talking about. 

I am planning on using Keras library (Tensorflow backend) for this task and still searching for convenient  data formatting and how to shape it for further ML model feeding. (I've read docs and still reading ). 

I am having trouble choosing what techniques are most used for these cases (I saw many exemples using RNN- LSTM but they are mostly time series and the output is not of high dimension ) ? . 

The general AIM is to observe if the model can predict the sequence (array ) associated to an new integer. 

Thanks in advance.","learnmachinelearning",85,0
"487",486,"learnmachinelearning","Discard pooling layers during inference, but use them to train.","","learnmachinelearning",86,1
"488",487,"learnmachinelearning","The 5 Stages of Learning Data Science (how to get ""unstuck"" when learning)","Hey Everyone! Sometimes we get ""stuck"" when learning something new. Data science is no different. These are the stages I wen't through when learning data science. I talk about where I struggled and how I leveled up!

[https://www.youtube.com/watch?v=hpMc6TgT34I&lc=z23lyrphczeds5o5p04t1aokgnq5u12wvrata0lbvjvcrk0h00410](https://www.youtube.com/watch?v=hpMc6TgT34I&lc=z23lyrphczeds5o5p04t1aokgnq5u12wvrata0lbvjvcrk0h00410&fbclid=IwAR0iLT0-U_CzOwxy6t55_R0CIo8td5LNZRoXnUW9cH3J4PJIrPYbYD9ucDQ)","learnmachinelearning",87,0
"489",488,"learnmachinelearning","My 100 Days of ML (03/12/19 - 11/03/20) Summary","","learnmachinelearning",88,64
"490",489,"learnmachinelearning","Rare event and eigenvectors from ML","Hi Everyone !!

I want to study rare events occurring in time series. Is there any dimensionality reduction technique or anything else which can give eigenvalues and eigenvectors describing this rare event mainly rather than principal motions? 

I have indicated two rare events as an example in the red ellipse in the attached figure. 

Thanks in advance

&#x200B;

[Rare event in time series is indicated by inside red ellipse.](https://preview.redd.it/1yb6ct0f1fm41.png?width=336&format=png&auto=webp&s=2901ad3e4e87d2d31ce57d6828af2ac2bcc93d8c)","learnmachinelearning",89,0
"491",490,"learnmachinelearning","Weekly Show-off!","Show off the machine learning projects that you have been working on! Whether big or small, any projects that you have built could be shared here.","learnmachinelearning",90,0
"492",491,"learnmachinelearning","Template matching uisng machine learning","Hello,

I'm trying to find associate some cropped images with a bigger sized image. This is something similar to template matching however, the cropped images here are also rotated and streatched.

So far, I've tried QATM's approach, however, the accuracy is super low and  my 6GB VRAM always is full.

How do I proceed?","learnmachinelearning",91,0
"493",492,"learnmachinelearning","Spectral clustering: defining the adjacent matrix","https://www.kaggle.com/vipulgandhi/spectral-clustering-detailed-explanation

I am confused if the user is to explicitly define the adjacent matrix, or does the computer do it for you.

Thanks!","learnmachinelearning",92,5
"494",493,"learnmachinelearning","Calculating IoU for semantic segmentation","Hello

In semantic segmentation, we calculate mIoU, or IoU averaged over classes. Now, I was wondering, let's say I have a cat class, but in one image I don't have a cat. My model doesn't see a cat, and in labels there isn't a cat. So, intersectio/union would be 0/0.

How to handle this case?

Do I just ignore this class altogether for this image?","learnmachinelearning",93,0
"495",494,"learnmachinelearning","20 Best Machine Learning Courses 2020","","learnmachinelearning",94,0
"496",495,"learnmachinelearning","To create a user delightful experience, your Amazon Alexa skills need to go through the skill certification process. Get a grip on how our Alexa developers do it.","","learnmachinelearning",95,0
"497",496,"learnmachinelearning","Correlation w. Classification problem","I'm a beginner in ML so I want to know how significant is the measure of correlation between the dependent variable and independent variables in classification problem?? Thank you.","learnmachinelearning",96,2
"498",497,"learnmachinelearning","Checkout my blog post on making ML models smaller","","learnmachinelearning",97,0
"499",498,"learnmachinelearning","Handwritten word generation with GANs!","","learnmachinelearning",98,0
"500",499,"learnmachinelearning","OCR for financial documents","Financial institutions require a ton of man power to do simple tasks like data entry. This not only consumes resources, but also is a bottleneck for following processes. In this blog we discuss how modern techniques like deep learning and OCR can help automate the process.

[https://nanonets.com/blog/ocr-financial-documents/?utm\_source=reddit&utm\_medium=social&utm\_campaign=ocr-financial-document&utm\_content=lml](https://nanonets.com/blog/ocr-financial-documents/?utm_source=reddit&utm_medium=social&utm_campaign=ocr-financial-document&utm_content=lml)","learnmachinelearning",99,2
"501",500,"learndatascience","Kaggle M5 forecasting competition evaluation","I made a video on how to write the WRMSSE evaluation metrics into code, using a naive forecast as example. Here’s the link to it if anyone’s interested: https://youtu.be/7FwITPrBvLI

And this is the Notebook where the code is stored: https://www.kaggle.com/qcw171717/naive-baseline/

My understanding is that we are only given the level 12 series and were to infer all the information regarding higher level series. If anything in the video felt wrong to you please let me know, that would really help.","learndatascience",0,0
"502",501,"learndatascience","Data Science Case Studies - Why is Data Science regarded as a revolution?","","learndatascience",1,0
"503",502,"learndatascience","The 5 Stages of Learning Data Science","","learndatascience",2,0
"504",503,"learndatascience","About to enroll in UCSD Data Science and Visualization Boot Camp, worth it??","Hello r/learndatascience

Please hear me out! This is a lot of $$$ that I am about to invest.  
I have been accepted and invited to join the [UCSD Data and Visualzation Boot Camp](https://bootcamp.extension.ucsd.edu/data/), a 6 month course on all the tools that a data scientist would need to get a decent paying job, I just want to make sure I am not about to blow a substantial amount of money on something I could otherwise learn on my own. You can find all the tools we will be learned from that link above. **This class costs $11,000**.....wow! However, it also helps you create a github with all the projects you will complete as well as have two field professionals monitor your progress and possibly help with employment when you are finished. Here is [how the curriculum is structured](https://i.imgur.com/xB2ARYh.png). Here is [what we will be able to do after completing](https://i.imgur.com/EjJFT2d.png) the course.

A little background, I come from hospitality and food service industry, so when I apply for places as a data scientist and put my bar tending & catering manager experience as past employment, companies tend to not take me seriously no matter what I can do with excel and pandas. ""Can you manage a Kubernetes Cluster?"" My response; ""wut""? One reason to attend this boot camp is that I need some sort of paper document that says, ""hey I did something and this place can prove it"". When applying to positions for data science they have basically told me if you don't have the letters BS, BA, MS or MA on your resume, you don't exist to us. This boot camp won't give me a BS or MS, but at least I will get a certificate of completion....right?

I have been attempting to self study programming (python, pandas, numpy, plotly, matplotlib, etc) as well as machine learning with tensorflow and pytorch for about 1 year now. I have several projects that I work on, but I feel like I am so far down the niche rabbit hole of several of my projects that I find myself unable to find the answers to some of my issues by myself. When I started out asking basic questions, many were able to help out and I could reason out a solution from there. Now my questions are so project specific that, unless I give you a detailed run down of why I am doing this and what I have already tried, it is hard to come up with an answer that will solve the problem. It is taking far to long to find solutions to my bottlenecks, so I started to think having a structured course work would help with that. 

Any input on this is appreciated! Have you taken this boot camp or something like it? Was it worth it, are you much better off for having done it? Are boot camps like this generally worth the cost or would I be better off buying some Udemy or Udacity classes for muuuch less than $11k?   
Thank you for reading!!","learndatascience",3,8
"505",504,"learndatascience","Accurate image classification in 3 lines of code with AutoGluon","AutoGluon is an easy-to-use AutoML toolkit for deep learning that allows you to automatically leverage state-of-the-art techniques.  Writing barely any code, we recently used AutoGluon to achieve around top 10% ranks in four Kaggle image classification competitions: 

[https://medium.com/@zhanghang0704/image-classification-on-kaggle-using-autogluon-fc896e74d7e8](https://medium.com/@zhanghang0704/image-classification-on-kaggle-using-autogluon-fc896e74d7e8)

To learn how to use AutoGluon for your own image classification problems, see our tutorial here:  [https://autogluon.mxnet.io/tutorials/image\_classification/kaggle.html](https://autogluon.mxnet.io/tutorials/image_classification/kaggle.html) 

Beyond image classification, AutoGluon also makes it easy to get started with object detection, as well as prediction tasks involving tabular/text data instead of images.  If you're already a deep learning practitioner, AutoGluon helps you automatically tune your own custom models.

AutoGluon is open-source and available on GitHub:  [https://github.com/awslabs/autogluon/](https://github.com/awslabs/autogluon/)","learndatascience",4,0
"506",505,"learndatascience","Kaggle M5 Walmart sales unit time series forecast featured competition","I’m planning to create a video document series on every step I take in this competition. Starting from understanding the competition to making the forecasts. This hopefully will push me to stay on track. If anyone starting out finds this helpful link to the first video is: https://youtu.be/K_G8GPXnouI

——— Edit ———
Second video on data file format and explaining the evaluation metric: https://youtu.be/uIDtrrEtaeQ
I hadn't looked into the files at the time I recorded this, but there seems to be some series with a lot of leading 0s and others not. So if we are theoretically ""equally accurate"" on 2 series, A with leading 0s and B without, denominator of A will be very small and therefore be assigned with a higher loss.","learndatascience",5,2
"507",506,"learndatascience","Data Science in Education – A much-awaited revolution","The broad availability of educational data has led to an interest in analyzing useful knowledge to inform policy and practice with regard to education. A data science research methodology is becoming even more important in an educational context. More specifically, this field urgently requires more studies, especially related to outcome measurement and prediction and linking these to specific interventions. Consequently, the purpose of this paper is first to incorporate an appropriate data-analytic thinking framework for pursuing such goals.

 The well-defined model presented in this work can help ensure the quality of results, contribute to a better understanding of the techniques behind the model, and lead to faster, more reliable, and more manageable knowledge discovery. Second, a case study of social-emotional learning is presented. We hope the issues we have highlighted in this paper help stimulate further research and practice in the use of data science for education. [Read More](https://techvidvan.com/tutorials/data-science-in-education/)","learndatascience",6,0
"508",507,"learndatascience","Real-time Tableau (public) graphs with Python?","I'm doing a project where I would like to visualize price data for a stock in real-time, or at least daily movement. Is there a way to connect Tableau public with python, in order to visualize a real-time graph in Tableau?","learndatascience",7,0
"509",508,"learndatascience","Data Science in Banking - 8 Remarkable Applications with Case Study!","","learndatascience",8,0
"510",509,"learndatascience","API for economic data?","I'm looking for an API to source real-time data about economics, such as yield curve data, household debt, etc. Does anyone know if there's an API for this?","learndatascience",9,1
"511",510,"learndatascience","Data Science in Finance - Explore 7 astonishing use cases of finance","","learndatascience",10,1
"512",511,"learndatascience","Top 5 Data Science Projects with Source Code to kick-start your Career","*Are you a Data Science aspirant and looking forward to some challenging and real-time Data Science projects?* Then you are at the right place to gain mastery in the field of Data Science. In this article, we will discuss the ***best Data Science projects that will boost your knowledge, skills and your Data Science career*** too!!

These real-world Data Science projects with source code offer you a propitious way to gain hands-on experience and start your journey with your dream Data Science job. Now let’s quickly jump to our best Data Science project examples with source code.

## 5 Best Data Science Projects for Beginners

Below are the top Data Science project ideas to master the technology:

* [**Movie Recommendation System Project**](https://data-flair.training/blogs/data-science-r-movie-recommendation/)
* [**Customer Segmentation using Machine Learning**](https://data-flair.training/blogs/r-data-science-project-customer-segmentation/)
* [**Sentiment Analysis Model in R**](https://data-flair.training/blogs/data-science-r-sentiment-analysis-project/)
* [**Uber Data Analysis Project**](https://data-flair.training/blogs/r-data-science-project-uber-data-analysis/)
* [**Credit Card Fraud Detection Project in R**](https://data-flair.training/blogs/data-science-machine-learning-project-credit-card-fraud-detection/)

### 1. Movie Recommendation System Project

📷

The aim of this interesting Data Science project including code is to build a recommendation system that recommends movies to the users.

Let’s understand this with an example. Have you ever been on an online streaming platform like Netflix or Amazon Prime? If yes, then you must have noticed that after some time these platform starts recommending you different movies and TV shows according to your genre preference. This project in R programming is designed to help you understand the functioning of how a recommendation system works.[Read More](https://data-flair.training/blogs/data-science-projects-code/)","learndatascience",11,0
"513",593,"learndatascience","Picking The Right BI Tool For Your Business - Looker vs Tableau vs Chartio Comparison","The comparison analyzes each of the three software vendor’s (Looker, Tableau, Chartio) various weaknesses and strengths, and see how the  software vendors stack up - to help you identify the best one for your business to visualize your data, see patterns and correlations, trends, statistics, and even ask specific questions: [How To Pick The Right BI Tool For Your Business](https://blog.panoply.io/how-to-pick-the-right-bi-tool-for-your-business)","learndatascience",93,0
"514",512,"learndatascience","NLP (Natural Language Processing) – A Data Science Survival Guide","Natural Language Processing (NLP) is one of the most popular fields of Artificial Intelligence. In the past century, NLP was limited to only science fiction, where Hollywood films would portray speaking robots. However, with the advancements in the field of AI and computing power, NLP has become a thing of reality.

So, today we will discuss the tools and some important algorithms used in this field.

📷

## What is Natural Language Processing?

*Natural Language Processing is a field that studies and develops methodologies for interactions between computers and humans.* Basically, Natural Language Processing deals with the development of ability in computers to understand the human language **(Natural Language = Human Language)**. There are various fields in Natural Language Processing like parsing, language syntax, semantic mining, machine translation, speech recognition, and speech synthesis.

NLP has transformed the AI industry. Several industries are using NLP for developing virtual assistants and understanding their customer insights. The intelligent personal assistants like **Apple Siri, Google Assistant, Amazon Alexa** have become highly popular. The field of NLP has been in evolution since the 1950s when Alan Turing pioneered Artificial Intelligence and came up with the idea of “Turing Test” to measure the intelligence of computers. Let us understand some of the core terminologies that are utilized in Natural Language Processing. [Read More](https://data-flair.training/blogs/nlp-natural-language-processing/)","learndatascience",12,0
"515",513,"learndatascience","How do I jump back into learning statistics?","



I took AP Statistics in high school and I found it incredibly fascinating, but when I hit college I found myself having less time to keep learning it by myself. For context, I am a computer science major and I would like to include statistics in my repertoire as a software engineer. Any advice as far as learning statistics and recommendations for websites, YouTube channels, and books would be greatly appreciated!","learndatascience",13,2
"516",514,"learndatascience","Data Science in Healthcare - 6 Must Read Use Cases!","","learndatascience",14,0
"517",515,"learndatascience","Top 10 Data Science Use Cases in Retail [Case Studies Included]","","learndatascience",15,0
"518",516,"learndatascience","Data Science Tool","I have an idea of a tool that helps people implement Data Science Analysis Techniques given necessary parameters. For Example : -

* Linear Regression
* Logistic Regression
* A/B Testing
* Naive Bayes
* Time Series Analysis

It's kind of like Metasploit of Data Scientists.

1. Is it a good idea?
2. Can I sell the software for a good price?","learndatascience",16,2
"519",517,"learndatascience","About word embeddings","Here is a blog post I recently wrote I am new to machine learning and NLP so while I was picking things up I thought why not blog my learnings,

Let me know your thoughts and if anything I can improve:

[https://farhaanbukhsh.wordpress.com/2020/02/21/word-embeddings-simplified/](https://farhaanbukhsh.wordpress.com/2020/02/21/word-embeddings-simplified/)","learndatascience",17,0
"520",518,"learndatascience","6 Most Used Data Science Applications With Case Studies!","","learndatascience",18,0
"521",519,"learndatascience","Currently creating the spam classifer","Hello all I am trying to create a neural net with python and have some trouble preprocessing. With the keras `text_to_word_sequence()` I am inserting a the second column of the dataframe which contains a sentence. The trouble comes after when adding the list of numbers coming to `text_to_word_sequence()` for some odd reason I get the  `TypeError:Unhashable type'dict'`  Can some help me what I'm doing wrong with this processing??? Also here is my code with some data from my csv! [https://gist.github.com/wildaces215/57c39d4f03a885f1ab691ff85a15f1d1](https://gist.github.com/wildaces215/57c39d4f03a885f1ab691ff85a15f1d1). Thank you so much in advance!","learndatascience",19,0
"522",520,"learndatascience","Building and analyzing an updatable dataset of content for a subreddit with Git and DVC","","learndatascience",20,0
"523",521,"learndatascience","Google Maps API - Pandas","I have a dataset where the addresses are unstructured and I want to write a Python script where it can structure the addresses.

Is the API Key for free? and how can I start with this project as a basic to intermediate level Python Programmer","learndatascience",21,1
"524",522,"learndatascience","Semantic Search Help","Hey guys,  


There is a problem we are trying to solve where we want to do semantic search on our set of data,  
i.e we have a domain specific data (example: sentences talking about automobiles)  


Our data is just a bunch of sentences and what we want is to give a phrase and get back the sentences which are:  
1. Similar to that phrase  
2. Has a part of sentence that is similar to the phrase  
3. Sentence which is having contextually similar meanings  


Let me try giving you an example suppose I search for the phrase ""Buying Experience"", I should get the sentences like:  


I never thought car buying could take less than 30 minutes to sign and buy.  
I found a car that i liked and the purchase process was straightforward and easy  
I absolutely hated going car shopping, but today i’m glad i did  


I want to lay emphasis on the fact that we are looking for contextual similarity and not just a brute force word search.  
If the sentence uses different words then also it should be able to find it.  


Things that we have already tried:  


1. Open Semantic Search ([https://www.opensemanticsearch.org/](https://www.opensemanticsearch.org/)) the problem we faced here is generating ontology from the data we have, or  
   for that sake searching for available ontology from different domains of our interest.  


2. Elastic Search(BM25 + Vectors(tf-idf)), we tried this where it gave a few sentences but precision was not that great. The accuracy was bad  
as well. We tried against a human curated dataset, it was able to get around 10% of the sentences only.  


3. We tried different embeddings like the once mentioned in [https://github.com/UKPLab/sentence-transformers](https://github.com/UKPLab/sentence-transformers) and also went through the example  
[https://github.com/UKPLab/sentence-transformers/blob/master/examples/application\_semantic\_search.py](https://github.com/UKPLab/sentence-transformers/blob/master/examples/application_semantic_search.py) and tried evaluating against our human curated set  
and that also had a very low accuracy.  


4. We tried ELMO([https://towardsdatascience.com/elmo-contextual-language-embedding-335de2268604](https://towardsdatascience.com/elmo-contextual-language-embedding-335de2268604)) this was better but still lower accuracy than we expected and there is a  
cognitive load to decide the cosine value below which we shouldn't consider the sentences. This even apply to point 3.  


Any help will be appreciated. Thanks a lot for the help in advance","learndatascience",22,0
"525",523,"learndatascience","Best Data Science Books for 2020 to Become A Data Scientist!","","learndatascience",23,0
"526",524,"learndatascience","Pros and Cons of Data Science - Know why choose Data Science as a career?","","learndatascience",24,1
"527",525,"learndatascience","Need Guidance"," I am a student about to graduate with a bachelors degree and will continue to pursue a masters in applied data science. I have a decent amount of exposure to Python and plan to hone my skills in it and am now being taught Weka in a data mining class. My question is whether I should focus on mastering a technology such as Weka or should I focus on learning something else. Ive read alot about technologies such as Tensorflow and Tableu for visualization becoming popular especially for jobs. I am looking for a little guidance on what I can deep dive into so that when I finish my masters I will have the best chances for landing a decent job. Any feedback is greatly appreciated. Thank you.","learndatascience",25,2
"528",526,"learndatascience","Feed new data into Pandas df when date changes?","I've scraped a website into json, and transformed the json to a pandas dataframe. So I have a df looking like this: 

&#x200B;

|location|measure|weather|
|:-|:-|:-|
|X|10|rain|
|Y|12|rain|
|Z|8|sun|

  
What I'd like to do now is create an additional variable with a timestamp, and I would like for my scrape to initiate every time the timestamp moves into the following day. When the scrape is performed that next day, I would like the new data to appear as rows below my current data frame, as displayed below: 

&#x200B;

|timestamp |location|measure|weather|
|:-|:-|:-|:-|
|01/01/2020|X|10|rain|
|01/01/2020|Y|12|rain|
|01/01/2020|Z|8|sun|
|**01/02/2020**|**X**|**7**|**cloudy**|
|**01/02/2020**|**Y**|**7**|**sun**|
|**01/02/2020**|**Z**|**5**|**sun**|

As you see above, the bold rows have been added for the next day, with new measures for location X, Y, and Z.

What would be the best way to do this with Pandas in Python? 

I am thinking that I should:  
1. Create a timestamp variable using datetime-package  
2. Write an IF-statement so that when day-count in timestamp increases by 1, I do the scrape again  
**3. Now, how do I get the new data underneath my current rows?**

I would really appreciate some qualified guidance. Thanks a lot!","learndatascience",26,0
"529",527,"learndatascience","Making a one-page splash screen for your Data Science portfolio","So recently I discovered the possibilities of **GitHub Pages** and that you can use them to create an interactive portfolio of your *Data Science projects* or *resumé*. As someone with next to no web development experience it was incredibly easy!

I wrote a short guide on how to set it up which you can read here https://towardsdatascience.com/making-a-free-personal-one-page-splash-screen-60344f243dfd

Hopefully this can help some of you :)","learndatascience",27,0
"530",528,"learndatascience","Multi Matrix Deep Learning with GPUs","","learndatascience",28,0
"531",529,"learndatascience","Your Data Science Dream Journey Unlocked","","learndatascience",29,0
"532",530,"learndatascience","K-means vs Spherical K-means","Can someone explain the difference between k-means and spherical k-means? When would using spherical k-means be more beneficial?","learndatascience",30,1
"533",531,"learndatascience","Playing with my first data set and have a weird cut off error for seaborn, how do I fix this?? For reference please look at the first row, I would like to have color behind it.... thank you in advance!","","learndatascience",31,1
"534",532,"learndatascience","Starting my journey to become a DS","I don't give a damn about my career anymore (civil engineering) but I will finish it because it's only one more year. 

The thing is that I want to be a DS, and I have no Computer science background etc. 

I took this two courses: Probability and Statistics by Stanford Online,  Linear Algebra by MIT 

And now I'm learning Tableau and playing with some datasets, but I don't know if I'm in the right direction or what to do after I become good at Tableau... Maybe learn R and Python? I'm not sure and I don't know what's the demand or trends on 2020. Any guidance or tip given will be much appreciated.","learndatascience",32,9
"535",533,"learndatascience","Question about normalizing data when using cosine similarity","I put together a bit of code to test my understanding of cosine similarity...

Given the following data (rough measures of things on my desk), does the cosine similarity value make sense?

```
items = {
    'phone': [1, 1/2, 1/12],
    'mouse': [3/4, 1/3, 1/4],
    'kindle': [13/12, 10/12, 1/12],
    'water': [1/2, 1/2, 7/4],
    'pen': [1, 1/20, 1/20]
}

# Cosine similarity between pen and other items

('pen', 1.0)
('phone', 0.9156819201892902)
('mouse', 0.9058903792082271)
('kindle', 0.8225728713106082)
('water', 0.3237021810765124)
```

While the relative order of the results makes sense to me... the dimensions of the pen are most similar to the dimensions of the phone... the magnitude of the similarity seems high.

I'm wondering if people who work with datasets like this usually normalize the dataset to get a more accurate range... but then...

1. What if one of your values is an extreme outlier... does it skew the rest of the values?
2. What if you feel one feature is more important than other features... do you normalize that value less?
3. By normalize I was just thinking of dividing all values by the largest value in the vector index. Is there a better or more accepted approach?","learndatascience",33,0
"536",534,"learndatascience","Please help in understanding instance methods of matplotlib fig.add_subplot objects.","Hey folks, learning Data Science with Wes McKinneys book  on Python Data Wrangling as a resource, and in the data visualization chapter, came across a bit of code I don't understand.

    fig = plt.figure()
    ax1 = fig.add_subplot(2, 2, 1)
    ax2 = fig.add_subplot(2, 2, 2)
    ax3 = fig.add_subplot(2, 2, 3)
    ax4 = fig.add_subplot(2, 2, 4)
    
    _ = ax1.hist(np.random.randn(100), bins=20, color='r', alpha=0.3)
    ax2.scatter(np.arange(30), np.arange(30) + 3 * np.random.randn(30))
    plt.plot(np.random.randn(50).cumsum(), 'k--')

with the description:

> ...The objects returned by fig.add_subplot here are AxesSubplot objects, on which you
> can directly plot on the other empty subplots by calling each one’s instance method...

Could you please explain this in a simpler manner? What's happening in this line:

    _ = ax1.hist(np.random.randn(100), bins=20, color='r', alpha=0.3)

My first post in this sub, please let me know if this is not the correct sub for these questions. Thanks for taking a look.","learndatascience",34,0
"537",535,"learndatascience","Think Philosophically, If you're struggling to learn Data Science","","learndatascience",35,1
"538",536,"learndatascience","Making road traffic counting app","","learndatascience",36,0
"539",537,"learndatascience","Speeding up model with fusing batch normalization and convolution","","learndatascience",37,0
"540",538,"learndatascience","What should I learn to get Data Science job in BioTech industry?","I am self-thought software engineer with 20 years of experience mainly in systems programming on Linux and C/C++. I would like to move towards Data Science and Machine Learning, specifically in BioTech industry.

I have self-studied a lot of Biology in past few years, so I feel relatively confident on that front. Now the time came to get more into the Data Science & Machine Learning part.

I have taken the Andrew Ng course on Coursera but that is extremely basic. The whole field, even when narrowed down ""only"" to the BioTech industry is still very huge and I feel like I do not know what I do not know.

I am currently going through the job-specs with keywords like ""Machine Learning"", ""Data Science"", ""Bioinformatics"", ""Genomics"", ""Proteomics"", etc., extracting keywords from them, trying to build a list of skills I need to learn. The plan being to first find various resources like notebooks on Kaggle and learn from them, later to come up with some relevant project on my own and learn by working on that project.

But I thought that it would be very helpful to also get some input from someone who already has that kind of background. If you do, what would be your thoughts on that?

**Edit**: I have deleted the original post by accident, so re-posting again (sorry).

**Edit**: I went through job-specs at various sources and my finding is, probably not very surprisingly, that there is just a lot of generic keywords used. On the Data Science side, there is everything, starting with linear regression through SVMs all the way to deep neural nets. On the Biology side, there is also full list of keywords from DNA sequencing, through RNA-Seq, ChIP-Seq, antibodies, proteins, microarrays to methylation and epigenetics. So not much wiser from that. In single word it says: ""Everything"". With the benefit of hind-sight, what else have I expected, especially when my question was about ""everything"".

So I have decided that spending too much time on this kind of meta-effort is not very productive and for now I will try to just go with the two notebooks from Kaggle listed below. Will dissect them so that I get to understand what do they do, how and why. By doing that, I will hopefully get some more insights into what's next and maybe I will even get someone leave a comment and share some useful thoughts in the meantime... :)

* https://www.kaggle.com/raoulma/cancer-image-tensorflow-cnn-80-valid-acc
* https://www.kaggle.com/mathzero/breast-cancer-classification-using-proteomic-data

**Edit**: It looks like 25% of people has downvoted this post, especially after the previous edit. This is my very first post on Reddit, I have created my account just couple of days ago specifically for this reason. So if there is something wrong with it, please leave feedback, so that I can learn from it. Thank you!","learndatascience",38,0
"541",539,"learndatascience","14 Most Used Data Science Tools for 2020 – Essential Data Science Ingredients!!","A Data Scientist is responsible for extracting, manipulating, pre-processing and generating predictions out of data. In order to do so, he requires various statistical tools and programming languages. In this article, we will share some of the Data Science Tools used by Data Scientists to carry out their data operations. We will understand the key features of the tools, benefits they provide and comparison of various data science tools.

**You must check –** [**Top skills to boost Data Science Career**](https://data-flair.training/blogs/data-science-skills/)

## Introduction to Data Science

Data Science has emerged out as one of the most popular fields of 21st Century. Companies employ Data Scientists to help them gain insights about the market and to better their products. Data Scientists work as decision makers and are largely responsible for analyzing and handling a large amount of unstructured and structured data. In order to do so, he requires various tools and[ **programming languages for Data Science to mend the day**](https://data-flair.training/blogs/data-science-programming-languages/) in the way he wants. We will go through some of these data science tools utilizes to analyze and generate predictions. 

## Top Data Science Tools

Here is the list of 14 best data science tools that most of the data scientists used.

### 1. SAS

It is one of those data science tools which are specifically designed for statistical operations. [**SAS is a closed source proprietary software**](https://data-flair.training/blogs/sas-software/) that is used by large organizations to analyze data. SAS uses base SAS programming language which for performing statistical modeling. It is widely used by professionals and companies working on reliable commercial software. **SAS offers numerous statistical libraries** and tools that you as a Data Scientist can use for modeling and organizing their data. [Read More](https://data-flair.training/blogs/data-science-tools/)","learndatascience",39,1
"542",540,"learndatascience","Which of these books is the best starting point?","This is my first post on this sub.

&#x200B;

My background is as follows: I am a first-year Data Science BS student at a local university. I have not taken any computer science courses yet, but I have read John Zelle's Python Programming: An Introduction to Computer Science and gone through MIT OCW's Intro to CS problem sets. I have also skimmed through a book on Go and have a bit of experience with Java. I have completed a few simple projects in Python and Go. I would not call my mathematical background ""strong.""

&#x200B;

A couple of months ago I purchased a bunch of O'Reilly eBooks on Humble Bundle. I started working on one, but quickly felt overwhelmed. I would like to read through one of these during my winter break. I come seeking advice on which of these books is the best logical starting point. Here are the books:

&#x200B;

* [Advanced Analytics with Spark](http://shop.oreilly.com/product/0636920035091.do)
* [Applied Text Analysis with Python](http://shop.oreilly.com/product/0636920052555.do)
* [Architecting Modern Data Platforms](http://shop.oreilly.com/product/0636920054825.do)
* [Deep Learning Cookbook](http://shop.oreilly.com/product/0636920097471.do)
* [Foundations for Architecting Data Solutions](http://shop.oreilly.com/product/0636920161417.do)
* [Getting Started with Kudu](http://shop.oreilly.com/product/0636920065739.do)
* [Graphing Data with R](http://shop.oreilly.com/product/0636920038382.do)
* [Kafka: The Definitive Guide](http://shop.oreilly.com/product/0636920044123.do)
* [Learning Apache Drill](http://shop.oreilly.com/product/0636920142898.do)
* [Learning TensorFlow](http://shop.oreilly.com/product/0636920063698.do)
* [Natural Language Processing with PyTorch](http://shop.oreilly.com/product/0636920063445.do)
* [Practical Statistics for Data Scientists](http://shop.oreilly.com/product/0636920048992.do)
* [Practical Tableau](http://shop.oreilly.com/product/0636920061977.do)
* [Streaming Systems](http://shop.oreilly.com/product/0636920073994.do)
* [Visualizing Streaming Data](http://shop.oreilly.com/product/0636920141105.do)

&#x200B;

I'd also love to hear of any of these come highly recommended or should be avoided, even if not for a beginner. Are there any open source/free resources that would be a better starting point?","learndatascience",40,1
"543",541,"learndatascience","Data Science at Netflix – A Must Read Case Study for Aspiring Data Scientists","***Data Science Case Study – How Netflix Used Data Science to Improve its Recommendation System?***

*Do you remember the last movie you watched on Netflix?* I don’t want to know the name; just think about it- after watching the movie, were you recommended of similar movies? How does Netflix know what you’d like? The secret here is Data Science. Netflix uses Data Science to cater relevant and interesting recommendations to you. So, today, in this article, we will discuss the same. Let’s start exploring Data Science at Netflix with a basic introduction to Netflix.

📷

## Data Science at Netflix

Netflix initially started as a DVD rental service in 1998. It mostly relied on a third party postal services to deliver its DVDs to the users. This resulted in heavy losses which they soon mitigated with the **introduction of their online streaming service** in 2007. In order to make this happen, Netflix invested in a lot of algorithms to provide a flawless movie experience to its users. One of such algorithms is the **recommendation system** that is used by Netflix to provide suggestions to the users. A recommendation system understands the needs of the users and provides suggestions of the various cinematographic products.

### What is a Recommendation System?

A recommendation system is a platform that provides its users with various contents based on their preferences and likings. A recommendation system takes the information about the user as an input. This information can be in the form of the past usage of product or the ratings that were provided to the product. It then processes this information to predict how much the user would rate or prefer the product. A recommendation system makes use of a variety of [**machine learning algorithms**](https://data-flair.training/blogs/machine-learning-algorithms/).  [Read more](https://data-flair.training/blogs/data-science-at-netflix/)","learndatascience",41,2
"544",542,"learndatascience","Implementation for Data Anonymization","Hi All I reposted this question because my previous question I think no one answered

I want to create a python script that can mask/anonymize the information inside each CSV column without removing its content. Because the data will be used for further analysis and doing some statistical modelling. The data mostly contain **user ID, project ID, Customer ID, address of the customer, name of the customer, order type, email address**. I'm kinda stuck on the current progress as I wanted to make this process more effective

&#x200B;

1. How could I do this process more scalable, meaning I don't need to create a script for each CSV file but more into **how could I use some technique to apply the script to every CSV files without rewriting from scratch?**

&#x200B;

My current approach: My approach right now is by dealing on each column one by one by doing something on it. For example the user ID, I replaced it with the additional string in front of the unique value ( for example since user ID 1234 in the first row, it gets replaced by user\_0).

&#x200B;

Please give me some advice and I would like to discuss so that I can do a more effective way

&#x200B;

Edit: This how the data looks like (I hope I put it in the allowable format)

&#x200B;

&#x200B;

    plantid projectid plant_name    project_name                  address         customerid projecttype
    15052.0  6496     Manufacturing ASAHI,PT-PRO/PTN/06-2012/192  streetname-city e8cfa43f   Individual
    15052.0  6458     Manufacturing CIMB NIAGA-PRO/PTN/06-2012/174 streetname-city 7b2bf5dc  Individual
    15052.0  11441    Manufacturing DM STOCK 2015                 streetname-city dc0c9893   Corporate

&#x200B;

And this is my current code

&#x200B;

&#x200B;

`data['customer_id'] = 'user_' + (pd.Series(pd.factorize(data['customer_id'])[0] + 1)).astype(str)`

`data['project_id'] = 'Project_' + (pd.Series(pd.factorize(data['project_id'])[0] + 1)).astype(str)`","learndatascience",42,0
"545",543,"learndatascience","Image segmentation for Computer Vision","Automation of Computer Vision requires image pre-processing, most important is - image segmentation. Segmentation algorithm should match image type and selection of the right segmentation does matter for better result.

For example, Automatic search through images of human parts (limbs):

Between different segmentation algorithms, like based on pixel color, on pixel brightness, combined pre-processed algorithms, - one, based on pixel color value change is the best .  But it has small negative effect - shadow is a color change (especially if image was gray-scaled before processing).

Simple attempt to improve algorithm by using colors ladder (R>G>B; R>G=B; e.t.c.) cause interesting effect. See on image

https://preview.redd.it/s8zlk7o1iz341.jpg?width=474&format=pjpg&auto=webp&s=fff0433e72d02b78a5e4fbedc314d6bebbf01b57","learndatascience",43,0
"546",544,"learndatascience","Job hunting but every job wants something different? how did you choose what to specialize?","i got my last job in Cognos because i knew machine learning in python and had a finance/analytics background.

&#x200B;

this week i interviewed for positions in tensor flow, cognos analytics, power bi, and tableau

in each case i was pretty much doing a refresher boot camp prior to the interview and the result was i didn't get past 2nd interview.

i cant be an expert in all of these or is that what being a data scientist is? 

when job searching do you only focus on one or just apply to all of them and learn as you go?

&#x200B;

I have past experience in all of them just they were minor tools in my past jobs.","learndatascience",44,2
"547",545,"learndatascience","Scrape older tweets?","Does anybody know if there is a way to scrape Tweets, e.g. between November 1 - November 10 using R? I am trying with the TwitterR module, but I won't get any result when I specify an older date than a week...

Help is much appreciated!","learndatascience",45,2
"548",546,"learndatascience","Article about the short-comings of online data science courses","Thought this was interesting and that I'd share it here:

[https://towardsdatascience.com/things-they-dont-but-should-cover-in-intro-data-science-with-python-moocs-c28550bb6c27](https://towardsdatascience.com/things-they-dont-but-should-cover-in-intro-data-science-with-python-moocs-c28550bb6c27)","learndatascience",46,4
"549",547,"learndatascience","Collecting data intersected by a GIS-layer","I am thinking about doing a project where I want to estimate the cost of rising sea levels. I have found a dataset with 2050 sea-level estimate in New York: 

[https://data.cityofnewyork.us/Environment/Sea-Level-Rise-Maps-2050s-100-year-Floodplain-/hbw8-2bah](https://data.cityofnewyork.us/Environment/Sea-Level-Rise-Maps-2050s-100-year-Floodplain-/hbw8-2bah) 

I wonder if it is somehow possible to combine that data set with another dataset that contains, for example, construction data with geospatial information, and filter out so that I only keep the data points within the flooded area? 

Thankful for advice!","learndatascience",47,3
"550",548,"learndatascience","Do you know about - NLP?","Natural Language Processing (NLP) is one of the most popular fields of Artificial Intelligence. In the past century, NLP was limited to only science fiction, where Hollywood films would portray speaking robots. However, with the advancements in the field of AI and computing power, NLP has become a thing of reality.

So, today we will discuss the tools and some important algorithms used in this field.

&#x200B;

https://preview.redd.it/8iqqv0p2kr141.jpg?width=802&format=pjpg&auto=webp&s=5d161c8f5406fa0f3f10e1de922d95df78210c64

## What is Natural Language Processing?

*Natural Language Processing is a field that studies and develops methodologies for interactions between computers and humans.* Basically, Natural Language Processing deals with the development of ability in computers to understand the human language **(Natural Language = Human Language)**. There are various fields in Natural Language Processing like parsing, language syntax, semantic mining, machine translation, speech recognition, and speech synthesis.

NLP has transformed the AI industry. Several industries are using NLP for developing virtual assistants and understanding their customer insights. The intelligent personal assistants like **Apple Siri, Google Assistant, Amazon Alexa** have become highly popular. The field of NLP has been in evolution since the 1950s when Alan Turing pioneered Artificial Intelligence and came up with the idea of “Turing Test” to measure the intelligence of computers. Let us understand some of the core terminologies that are utilized in Natural Language Processing.

***Did you check the*** [***latest Artificial intelligence guide***](https://data-flair.training/blogs/artificial-intelligence-tutorial/)***?*** 

### 1. Corpus

A corpus is a large collection of textual data that is structured in nature. There are two types of the corpus – monolingual corpus (containing text from a single language) and multilingual corpus (containing text from multiple languages). **NLTK**, which is the most popular tool in NLP provides its users with the Gutenberg dataset, that comprises of over **25,000 free e-books** that are available for analysis.

The multilingual corpus is often present in the form of a parallel corpus, meaning that there is a side-by-side translation of the text present in the data-set. This is useful for machine translation where you are required to train your model in parallel data to gain necessary insights about it. Another important extension of the corpus is with the POS (Parts of Speech) tagger where each word’s part of speech (verb, noun, adjective) are added to the corpus.

### 2. Semantic & Syntactic Analysis

A Syntactic Analyzer is tasked with validating the sentence structure present in the corpus. Context Free Grammer is an important rule for verifying the sentence structure. The sentences are presented in the form of a tree using parsers like Earley Algorithm, Cocke-Kasami-Younger (CKY), Chart Parser, etc. [Read More](https://data-flair.training/blogs/nlp-natural-language-processing/)","learndatascience",48,0
"551",549,"learndatascience","Searchtwitter API call (R) - few tweets returns","I am scraping Tesla tweets for a 7-day period, I set the query to return 1000 tweets, but I only get 84 tweets returned. The period certainly holds more than 84 #TSLA tweets. Could someone take a look at my code below and see what might be the reason?

`setup_twitter_oauth(api_key, api_secret, access_token, access_token_secret)`  
`tweets_tesla = searchTwitter(""#TSLA -filter:retweets"", since=""2019-11-15"", until=""2019-11-22"", n=1000, lang=""en"")`

I run this code and get the following warning message:

`Warning Message:`  
`In doRppAPICall(""search/tweets"", n, params = params, retryOnRateLimit = retryOnRateLimit,  :`  
`1000 tweets were requested but the API can only return 84`

I appreciate any help, thanks!","learndatascience",49,4
"552",550,"learndatascience","Taking you closer to your Data Science dream","This guide is for beginners and intermediate-level programmers alike. It will give you the knowledge necessary to be a skilled R programmer and data scientist. Instead of going through scattered resources and tutorials, we have this one-stop guide to being an R ninja. We advise you to go through this article and navigate from the links and resources provided to learn R concepts thoroughly. By following this DataFlair’s guide, you will be a master R programmer in no time.

📷

## Learn R Programming from Scratch

Here is the list of topics that we will cover in this R tutorial:

* What is R?
* Features of R
* Applications of R
* Use Cases of R
* R Career Opportunities
* R Installation
* Programming Constructs of R
* Advanced Concepts of R
* Object-Oriented Programming in R
* Data Visualization in R
* Machine Learning in R
* R Interview Questions
* Real-time Projects in R

### What is R?

R is a programming language used for statistical computing and analysis. It was created by Ross Ihaka and Robert Gentleman in 1992 at the University of Auckland, New Zealand. The main goal behind the creation of R was to make a tool that was affordable, easy-to-learn and capable of handling complex mathematical and statistical calculations.

Today, R is one of the most popular programming languages used by data analysts and data scientists in the world. It is a programming language with one of the largest user bases. Even more exciting is the fact that it is completely free as R is an open-source programming language. R’s capabilities do not end at data analysis or statistics. It is useful for many disciples like data science, machine learning, data visualization, etc.

***For more details regarding what is R, check out*** [***R Tutorial***](https://data-flair.training/blogs/r-tutorial/)

### Features of R

📷

The R programming environment comes packed up to brim with exciting features. Let’s learn some of these features:

* **Open-source:** R is an open-source programming language. It is completely free for anybody to use.
* **Variety of packages:** There are more than 15,000 packages for R on online repositories like CRAN, Bioconductor, and GitHub.
* **Powerful graphics:** R’s graphical capabilities are amazing. It can produce publication-quality graphs and plots of any kind with its base package. With added packages like ggplot2 and plotly the possibilities are endless.
* **No need for a compiler:** The R language is interpreted. It does not need a compiler to convert the code into a program.
* **Cross-platform support:** R is cross-platform supportive that is it can run on any OS and in any software environment without any hassle. [Read More](https://data-flair.training/blogs/learn-r-programming/)","learndatascience",50,1
"553",551,"learndatascience","Concepts of Data Preprocessing in Data Science","Data is truly considered a resource in today’s world. As per the World Economic Forum, by 2025 we will be generating about 463 exabytes of data globally per day! But is all this data fit enough to be used by machine learning algorithms? How do we decide that?

Read my article to find out:  [https://towardsdatascience.com/data-preprocessing-concepts-fa946d11c825](https://towardsdatascience.com/data-preprocessing-concepts-fa946d11c825)","learndatascience",51,0
"554",552,"learndatascience","Is there a way to import handmade trees into XGBoost?","I want to test if importing handmade trees has an effect on the results XGBoost returns. Is there a way to do that, prescribed or otherwise? Going about it hackily is fine, it's more about the being able to at all than being able to in a way that is easy to automate.","learndatascience",52,0
"555",553,"learndatascience","Host Python project online? (folium map)","I have created this program in Python which takes two datasets and combines them to a Pandas data frame, which is then programmed to generate a map using the Leaflet Folium module. My desire is to be able to host a live version of the map by embedding it into Wordpress or Google Sites. Is this possible? How would I do it?

The output that I currently get is a html version of the map by saving my map like this:

`base_map.save(""map.html"")`","learndatascience",53,2
"556",554,"learndatascience","How to get started with data anonymization?","Hope this is not off-topic in this group... I'm looking for some help to get started on the topic of data anonymization: tools, techniques, algorithms etc. I'm an advanced Python user, but no R skills. Appreciate any pointers.","learndatascience",54,2
"557",555,"learndatascience","An interesting introduction to Machine Learning!","","learndatascience",55,1
"558",556,"learndatascience","R Typing Tutor & Code Familiarizer","I couple years ago I built a typing tool for increasing the user's speed in typing R syntax, with a side benefit of familiarizing the user with different R packages (dplyr is the default). I never did promote it, and it's been rotting on github for years. But I just went back and played a round of dplyr and was happy to see that it still works, even the companion web app. I also remembered that it's kind of fun to just turn your brain off and type for speed. In case anyone wants to try it out:

[https://github.com/baogorek/typingtutor](https://github.com/baogorek/typingtutor)","learndatascience",56,0
"559",557,"learndatascience","Twitter API - scraping tweets in R?","I am trying to scrape tweets with R to perform sentiment analysis on some organizations, but I am only getting a fragment of the number tweets I am requesting, using this code: 

`setup_twitter_oauth(api_key, api_secret, access_token, access_token_secret)`  
`uber_tweets = searchTwitter(""#UBER"", n=1000, lang=""en"")`

The code above only returns 149 tweets. Does anyone know if this is because I am using the free standard version of Twitter's API?  or am I doing something wrong?","learndatascience",57,1
"560",558,"learndatascience","An Open Source Stack for Managing and Deploying ML Models (DVC + Cortex) - Step-By-Step Guide","In this tutorial, we’re going to use DVC to create a model capable of analyzing StackOverflow posts, and recognizing which ones are about Python. We are then going to deploy our model as a web API (using Cortex), ready to form the backend of a piece of production software: [An Open Source Stack for Managing and Deploying Models](https://towardsdatascience.com/an-open-source-stack-for-managing-and-deploying-models-c5d3b98160bc)

1. Set up your DVC project
2. Export and upload your model
3. Deploy your model with Cortex","learndatascience",58,0
"561",559,"learndatascience","Fundamentals of Computing for Data Science and Machine Learning","","learndatascience",59,1
"562",560,"learndatascience","Backpropagation","Can someone help me do a backpropagation for 1D CNN? i cant seem to find a clear explanation on it","learndatascience",60,0
"563",561,"learndatascience","Data Extraction","Hi Everyone,

I am trying to work on a project in which I need to pull a lot of data of banks from their financial documents available on their website. Is there a software that I can configure to open the website and navigate to the link and extract all the data from the financial HTML or pdf file and then create tables from it in Excel which then I can create a separate sheet and use the data I want from the tables and fix it according to my needs. So at the end of the day, all I have to do is tell it the website and it scans and extracts the data in a sheet I defined and then the next sheet updates according to the data pulled and presents data as I want.","learndatascience",61,2
"564",562,"learndatascience","71 Data Science Interview Questions and Answers – Crack Technical Interview Now!","DataFlair has published a series of top data science interview questions and answers which contains 130+ questions of all the levels. Have a look –

* [**Data Science Interview Questions for Freshers**](https://data-flair.training/blogs/data-science-interview-questions/)
* **Data Science Interview Questions for Intermediate Level**
* [**Data Science Interview Questions for Experienced** ](https://data-flair.training/blogs/r-data-science-interview-questions/)

This is the second part of the Data Science Interview Questions and Answers series. In our first part, we discussed some basic level questions which could be asked in your next interview, especially if you are a fresher in Data Science. Today, I am sharing the top 71 Data Science Interview Questions and Answers. This is the only part where you will get best scenario-based interview questions for data scientist interviews. Outline of the article –

* **Python** Data Science Interview Questions and Answers
* **Scenario-based** Data Science Interview Questions and Answers
* **ML & Statistics** Data Science Interview Questions and Answers
* **General** Data Science Interview Questions and Answers
* **Behavior-based** Data Science Interview Questions

>***A Data Science Interview is not a test of your knowledge, but your ability to do it at the right time.*** 

## Python Data Science Interview Questions

Every data science interview has many Python-related questions, so if you really want to crack your next data science interview, you need to [***master Python***](https://data-flair.training/python-course/).

**Q.1 What is a lambda expression in Python?**

**Ans.** With the help of[ ***lambda expression***](https://data-flair.training/blogs/python-lambda-expression/), you can create an anonymous function. Unlike conventional functions, lambda functions occupy a single line of code. The basic syntax of a lambda function is –

**lambda arguments: expression**

An example of lambda function in Python data science is –

**x = lambda a : a \* 5**  
**print(x(5))**

***We obtain the output of 25.***

**Q.2 How will you measure the Euclidean distance between the two arrays in numpy?**

**Ans.** In order to measure the Euclidean distance between the two arrays, we will first initialize our two arrays, then we will use the linalg.norm() function provided by the numpy library. Here, numpy is imported as np.

1. a = np.**array**(\[1,2,3,4,5\])
2. b = np.**array**(\[6,7,8,9,10\])
3. \# Solution
4. e\_dist = np.linalg.**norm**(a-b)
5. e\_dist
6. 11.180339887498949

With data integrity, we can define the accuracy as well as the consistency of the data. This integrity is to be ensured over the entire life-cycle.

**Q.3 How will you create an identity matrix using numpy?**

**Ans.** In order to create the identity matrix with numpy, we will use the identity() function. Numpy is imported as np  
np.identity(3)

We will obtain the output as –

**array(\[\[1., 0., 0.\],**  
**\[0., 1., 0.\],**  
**\[0., 0., 1.\]\])**

**Q.4 You had mentioned Python as one of the tools for solving data science problems, can you tell me the various libraries of Python that are used in Data Science?**

**Ans.** Some of the important libraries of Python that are used in Data Science are – [Read More](https://data-flair.training/blogs/data-science-interview-questions-and-answers/)","learndatascience",62,1
"565",563,"learndatascience","Concepts, Techniques, Strategies and Best Practices for Data Management in the Cloud","Applying a modernized approach to the concept of data management is a necessity in today’s cloud computing environment. This facilitates insights by embracing full transparency across your data lifecycle, allowing seamless extraction of the most useful data, all at the speed of business. This is a two-part series on the intersection of cloud computing and data management:

1. [Data Management Concepts And Techniques In A Cloud-Based World](https://blog.panoply.io/data-management-concepts-and-techniques-in-a-cloud-based-world)  (on applicable concepts and techniques for data management in an increasingly cloud-based world)
2. [Data Management Strategy And Best Practices In The Cloud](https://blog.panoply.io/data-management-strategy-and-best-practices-in-the-cloud) (on data management strategy and best practices)","learndatascience",63,0
"566",564,"learndatascience","What Is Data Profiling? Process, Best Practices and Tools","Data profiling is a process of reviewing source data for content and quality. As data gets bigger and infrastructure moves to the cloud, data profiling is increasingly important. The following overview explains how to achieve big data profiling with limited time and resources: [What Is Data Profiling? Process, Best Practices and Tools](https://panoply.io/analytics-stack-guide/data-profiling-best-practices/)","learndatascience",64,0
"567",565,"learndatascience","Collecting particular Tweets","What would be the best method (broadly, step by step) if I want to collect Tweets in real-time that contains a certain word, for example, ""Harvard University"". Ultimately, what I want to do is to perform sentiment analysis on Tweets in order to create a sort of real-time sentiment-indicator. 

I am using R for this project, and I know the basics of using APIs. Is it possible to run RegEx or something on all Tweets to mine the out the ones that contain the keywords I am looking for?","learndatascience",65,2
"568",566,"learndatascience","Data Science Tutorial - Learn Data Science from Scratch","","learndatascience",66,1
"569",567,"learndatascience","Take a sneak peek to 11 cool Data Science Project Ideas with source code!!","","learndatascience",67,0
"570",568,"learndatascience","Network analysis questions","I have data for a startup company. My nodes are: people, department (sales, marketing, etc.), knowledge (python, java, c++, etc.). Would it make sense to create a network visualization with all these nodes and the connection relevant to each other?  Or would I have to do one individuals network analysis for people, one for departments, and one for knowledge?

&#x200B;

Thanks!","learndatascience",68,0
"571",569,"learndatascience","Listing Tables And Columns In Postgres (Tutorial)","Data exploration, or data profiling, is the first step in sound data analysis. The point here is to get familiar with and understand the data you are working with. The following tutorial walks you through the steps of exploring your data using PostgreSQL: [Listing Tables And Columns In Postgres: A PG_TABLE_DEF Tutorial](https://blog.panoply.io/exploring-data-in-postgres)

PG_TABLE_DEF is a table (actually a view) that contains metadata about the tables in a database. It is kind of like a directory for all of the data in your database and gives you all of the schemas, tables and columns and helps you to see the relationships between them.","learndatascience",69,0
"572",570,"learndatascience","Comparing 5 Data Preparation Tools vs. Automated Data Platform","Data preparation, part of the data management process, involves collecting raw data from multiple sources and consolidating it into a file or database for analysis. Data preparation is an initial step in data warehousing, data mining, and machine learning projects.

The data preparation process includes the following activities:

* Data ingestion—copying or loading data from different data sources.
* Data fusion—integrating multiple data sources to create one consistent representation.
* Data cleansing—ensuring data is valid, complete, consistent, uniform, and accurate.
* Data augmentation—adding information that increases value—for example, enriching sales leads data with contact details.

Full article: [5 Data Preparation Tools & 1 Automated Data Platform](https://blog.panoply.io/5-data-preparation-tools-1-automated-data-platform)","learndatascience",70,0
"573",571,"learndatascience","Leaflet (Folium) visualization using Pandas dataframe","I have a large Pandas dataframe in Python looking like this:

city, longitude, latitude, price

There are a lot of rows, and I would like to map out the rows using my long and lat data as a geographical visualization using Leaflet (Folium). Then, for every data point (long, lat) I would like the price to determine the size of the point on the map, alternatively create a heatmap.

I would much appreciate some guidance for someone who's got experience from Folium, how do I write the code for this is?

Thanks!","learndatascience",71,3
"574",572,"learndatascience","Network Analysis on sales data?","If I wanted to perform network analysis on a dataset with e-commerce sales data, how would this be carried out the best way? Say the data was:

customer\_id, product\_purchased, price, date\_purchased, product\_category

Could I use the customer\_id as connections between product\_category being the nodes? The product category defines if the product is clothes, jewelry, shoes, etc.

Would this be a logical analysis that would yield a network visualization of which products were most often co-purchased, etc? Or am I thinking wrong?","learndatascience",72,2
"575",573,"learndatascience","Approach to create this program? Data on maps","I am doing a project in python where I am  combining to datasets to map out hotel price information, the code is written so that the data will be refreshed when someone runs the code. My issue is that I don't know how I would proceed to create an interactive map for the end product. I have done all the data programming, and I have all the information needed in a pandas data frame (long/lat/price info/etc.). My question is: 

How do I get the data from the Python data frame onto a map platform, without having to export the data as a file to insert in Tableau or similar? Also, where do I host such an interactive map/platform?","learndatascience",73,2
"576",574,"learndatascience","Data Engineer Vs Data Scientist: What's The Difference? - Comparison","There is a significant overlap between data engineers and data scientists when it comes to skills and responsibilities. Data engineers are focused on building infrastructure and architecture for data generation. Data scientists are focused on advanced mathematics and statistical analysis on that generated data: [Data Engineer Vs Data Scientist: What's The Difference?](https://blog.panoply.io/what-is-the-difference-between-a-data-engineer-and-a-data-scientist)","learndatascience",74,0
"577",575,"learndatascience","If statements with pandas? (python)","I have written a function in Python that will multiply a pandas data column with a variable (float), to then generate a new column. The problem is that I want the float variable to change based on some information from another column, I tried to do this with if-statements, but I couldn't get it to work. Could someone help me out?I made a visual example below:

city, unitslondon, 3new york, 5new york, 3boston, 2....., ......

price\_london = 10price\_newyork = 12price\_boston = 8

When city == ""london"", I want to multiply with price\_london, and so on. So that I later can add a column to the data called ""total\_price"".

I tried to write the code this way:

`#define column 1`  
`column1 = df[""units""]`  
`#define column 2`  
`if df[""city""] == ""London"":`  
`column2 = price_london`  
`elif df[""city""] == ""New York"":`  
`column2 = price_newyork`  
`elif df[""city""] == ""Boston"":`  
`column2 = price_boston`

`#function to multiply columns`  
`def multiplier(column1, column2):`  
`multiplied_column = column1 * column2`  
`return multiplied_column`  
`#print(multiply(column1, column2))`  
`#add new mutliplied column to pandas dataframe`  
`df[""total_price""] = multiplier(column1, column2)`

when I run the code I get this error message:

`Traceback (most recent call last):File ""C:/Users/xxx.py"", line 39, in <module>if df[""city""] == ""London"":File ""C:\Users\zxxxxx\`[`generic.py`](https://generic.py)`"", line 1555, in __nonzero__self.__class__.__name__ValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().`

I would be sooo thankful if someone could help me out! Also, I guess there is probably a way to do this multiplication and add column in an easier way with Panda tools. But I really would like to write the code in this way with a function, if possible.","learndatascience",75,6
"578",576,"learndatascience","Stitch' Singer ETL tutorial - data extraction and consolidation for all of your organization’s tools","[Singer](https://www.singer.io/), developed by [Stitch](https://www.stitchdata.com/), is an open source tool that is set up to allow users to mix and match inputs and outputs, making their ETL processes much more modular, and therefore easier to run and maintain. It’s also designed to use JSON to move all data between sources and destinations: [ETL With Singer: A Tutorial](https://blog.panoply.io/etl-with-singer-a-tutorial)","learndatascience",76,0
"579",577,"learndatascience","CSV download to pandas dataframe automation?","I want to automate the process of downloading a CSV file from the web, and storing it in a Pandas dataframe. How would you do this in the easiest way? I have tried the code below, but I feel like there must be a way to do this without first downloading the csv to my computer, and then opening it up like I've done here? 

def download\_construction\_data(csv\_url):  
response = request.urlopen(csv\_url)  
csv = response.read()  
csv\_str = str(csv)  
lines = csv\_str.split(""\\\\n"")  
dest\_url = ""const\_data.csv""  
 fx = open(dest\_url, ""w"")  
 for line in lines:  
fx.write(line + ""\\n"")  
fx.close()  
download\_construction\_data(const\_csv\_url)  


const = pd.read\_csv(""C:/xxx/const\_data.csv"")

&#x200B;

Thanks!","learndatascience",77,6
"580",578,"learndatascience","Help with this Python data calculation","I would much appreciate some guidance for this thing I am working on. I have a Pandas dataset in Python with this structure:

borough, price, type  
manhattan, 80, room  
brooklyn, 65, room  
brooklyn, 100, apartment  
queens, 55, room  
....., ......, .......

&#x200B;

What I want to do is create a list of variables which hold mean price for type in each borough, i.e. like this:

avg\_manhattan\_room = 85.6  
avg\_manhattan\_apartment = 120  
avg\_brooklyn\_room = 72  
avg\_brooklyn\_apartment = 113  
avg\_queens\_.....  
etc....

&#x200B;

Could anyone help me out with the best method to proceed for this job? 

Thanks a lot!","learndatascience",78,2
"581",579,"learndatascience","Defining The Data Warehouse: Applications In The Real World","The following overview defines data warehousing, shows some use-cases, and discusses best practices: [Defining The Data Warehouse: Applications In The Real World](https://blog.panoply.io/data-warehouse-applications-use-cases)

Unlike databases and other systems which simply ‘store’ data, data warehousing takes an entirely different approach, it normally use a denormalized data structure, which uses fewer tables because it groups data and doesn’t exclude data redundancies. Denormalization offers better performance when reading data for analytical purposes. On that note, data warehouses are used for business analysis, data and market analytics, and business reporting. Data warehouses typically store historical data by integrating copies of transaction data from disparate sources and can also use real-time data feeds for reports that use the most current, integrated information.

Coupled with solutions around data analytics and big data processing, data warehousing allow businesses gather, quantify, and actually analyze its information and take its information to an entirely new level by helping you create data visualization to make better decisions around your business and the market.","learndatascience",79,0
"582",580,"learndatascience","Postgres CASE Statement Basics By Example","The following overview introduces to the basics of using CASE statements/expressions and also cover comparison operators (greater than, less than, equal to) and BETWEEN: [Postgres CASE Statement Basics By Example](https://blog.panoply.io/postgres-case-statement-basics-by-example)

Boolean expressions and comparison operators also provide utility beyond their functions within CASE statements. And the overview helps gain a deeper understanding of CASE statements as well as the practical tools to put them to use.","learndatascience",80,0
"583",581,"learndatascience","Data Warehouse Applications For Business","The following overview defines data warehousing, look at some use-cases, and discuss a few best practices: [Defining The Data Warehouse: Applications In The Real World](https://blog.panoply.io/data-warehouse-applications-use-cases)

Unlike databases and other systems which simply ‘store’ data, data warehousing takes an entirely different approach, it normally use a denormalized data structure, which uses fewer tables because it groups data and doesn’t exclude data redundancies. Denormalization offers better performance when reading data for analytical purposes. On that note, data warehouses are used for business analysis, data and market analytics, and business reporting. Data warehouses typically store historical data by integrating copies of transaction data from disparate sources and can also use real-time data feeds for reports that use the most current, integrated information.

Coupled with solutions around data analytics and big data processing, data warehousing allow businesses gather, quantify, and actually analyze its information and take its information to an entirely new level by helping you create data visualization to make better decisions around your business and the market.","learndatascience",81,0
"584",582,"learndatascience","A Step By Step Guide To Prepare A Business For Big Data","More organizations are investing in their own data platforms to really gain as much value as they can out of the information they’re creating. The following overview looks at these 7 simple steps to prepare for big data: [7 Simple Steps To Prepare For Big Data](https://blog.panoply.io/7-simple-steps-to-prepare-for-big-data)

1. Understand your data sources and the type of data you’re creating
2. Make sure you have an infrastructure that can support big data
3. Understand how to store and process big data
4. Consider data analytics is only a part of the entire solution
5. Leverage cloud for your data
6. Align your business for big data
7. Leverage a team of data scientists","learndatascience",82,1
"585",583,"learndatascience","Udacity Data science Nano degree Vs other data science","Hi Folks,

I am thinking of Udacity Data science Nano degree vs Harvard data science certificate program (R)

I am more interested in Python and leaning towards Udacity Nano degree as they have projects

Any opinions or inputs appreciated.","learndatascience",83,2
"586",584,"learndatascience","Any ideas where to begin my educational journey in learning Data Science?","I know this is a big question. And I know that DS encompasses so many different fields of technology and mathematics that getting off on the right foot while searching through MOOC's can make your head spin.

So I'll lay out my skills: I have very barebones Python experience. By ""barebones"", I mean I took one course in college that focused on Python that I ended up dropping because I was taking seven courses to graduate on time. I also used some SQL for a database course I had which mainly glossed over it. As for math, I only took one stats course that I don't really remember much about and just barely got through calc in my last semester.

If someone could just point me in the right direction, whether that be to educational resources or a different sub because you're tired of seeing this kind of post here, I'd appreciate it.","learndatascience",84,3
"587",585,"learndatascience","Boxplots using Matplotlib, Pandas, and Seaborn Libraries (Python)","[https://youtu.be/BE8CVGJuftI](https://youtu.be/BE8CVGJuftI)","learndatascience",85,0
"588",586,"learndatascience","Ways to gather or find commercially-usable data","&#x200B;

Hi,

I just started as a data analysis intern, and one problem my team encounter is that we don't have enough data for deep learning models. We are spending 50% of our time making demo versions for potential clients in the future. Right now, we're trying to find good sources of data that we could use for commercial purposes. The data could be in any format/category. It could be image, text, tabular data etc. Web scraping could be an option, but there are legal issues with web-scraped data. 

As I said, the data could be anything as long as it is okay to be used commercially. I just thought it would be great if anyone could share his/her thoughts that could lead to gathering commercially-usable data :)

Thank you!","learndatascience",86,1
"589",587,"learndatascience","7 Steps To Prepare A Business For Big Data","More organizations are investing in their own data platforms to really gain as much value as they can out of the information they’re creating. The following overview looks at these 7 simple steps to prepare for big data: [7 Simple Steps To Prepare For Big Data](https://blog.panoply.io/7-simple-steps-to-prepare-for-big-data)

1. Understand your data sources and the type of data you’re creating
2. Make sure you have an infrastructure that can support big data
3. Understand how to store and process big data
4. Consider data analytics is only a part of the entire solution
5. Leverage cloud for your data
6. Align your business for big data
7. Leverage a team of data scientists","learndatascience",87,0
"590",588,"learndatascience","MySQL As A Data Warehouse: Is It A Best Option - Pros & Cons","The following overview looks at how MySQL performs on analytics tasks, and whether it’s the best choice for a data warehousing project, and how dedicated data warehouses are better than MySQL databases when it comes to analysis: [MySQL As A Data Warehouse: Is It Really Your Best Option?](https://blog.panoply.io/mysql-as-a-data-warehouse-is-it-really-your-best-option)","learndatascience",88,0
"591",589,"learndatascience","Data Science Project Life Cycle Overview","","learndatascience",89,0
"592",590,"learndatascience","Data Analytics vs Data Science","Most people think that data analytics and data science are the same, but they really aren't.

Data science is a relatively new field in the business industry and, thus, it’s typical that most businesses who are looking to get into and take advantage of the rising field may not quite know what they want exactly. 

**“Do I want data science or data analytics in my company?”** is a question that is asked most frequently by business owners, so hopefully this article answers that question definitively: [Data Analytics vs Data Science](https://xccelerate.co/blog/data-analytics-vs-data-science)","learndatascience",90,1
"593",591,"learndatascience","How To Build Visualizations In Tableau Using A Smart Data Warehouse","In order to reduce visualization load time and enable efficient data connections, you can work with a smart data warehouse that’s capable of integrating with a data visualization engine. The following tutorial provides a single source of data that's compatible with all major business intelligence as well as data visualization tools: [How To Build Visualizations In Tableau Optimally](https://blog.panoply.io/tools-and-tips-how-to-build-visualizations-optimally-in-tableau)","learndatascience",91,1
"594",592,"learndatascience","ETL Software And Data Warehousing As Foundation For Modern Analytics - Overview","Modern analytics takes a data-oriented approach to business decision making, and uses BI tools to help make sense of the data. ETL software and data warehouses form the bedrock of an effective, data-driven decision making policy: [Why ETL Software And Data Warehousing Are Foundational To Modern Analytics](https://blog.panoply.io/why-etl-software-and-data-warehousing-are-foundational-to-modern-analytics)","learndatascience",92,1
"595",594,"learndatascience","Where should I start considering what I know?","I don't know much of anything about data science or statistics but I'm a software engineering who does a lot of ETL and data cleaning with python and pyspark. I mainly gather and prepare the data for our data science team, pretty much everything up until the 'science' part. I really want to learn more about the data science processes though. Where would be a good place for me to start? Any good websites/books that can give me a high level understanding to expand on?","learndatascience",94,3
"596",595,"learndatascience","How Data Warehouse Can Make Data Mining Easier - Overview","The article explains the benefits of how an automated data warehouse make data mining easier: [How Your Data Warehouse Can Make Data Mining Easier And More Efficient](https://blog.panoply.io/how-your-data-warehouse-can-make-data-mining-easier-and-more-efficient)

A data warehouse is a system that collates data from a wide range of sources within an organization. Data warehouses are used as centralized data repositories for analytical and reporting purposes.","learndatascience",95,1
"597",596,"learndatascience","Data Science Online Course","","learndatascience",96,0
"598",597,"learndatascience","Data science dilemma","Hi Folks,

I am learning data science and i trying to figure out the best course of action. I am seeing different courses and thought of doing Harvard Data science certification course but it's taught in R. I am learning python and if i need to do that certification I need to learn R for that course.

I am trying to decide if it's worth just for certification doing that course and again learn to implement stuff in python.

Does the Harvard Certification carry weight while applying for jobs?

Also Applied data science with [python.](https://python.is/) Is this good course?

I appreciate any help!","learndatascience",97,5
"599",598,"learndatascience","3 Ways to Understand Matrix Multiplication","","learndatascience",98,0
"600",599,"learndatascience","Gettin started with Data Science using Python","If you’ve heard of programming, you’ve probably heard of Python. By name alone it may trigger a fear of a certain snake, but Python is a powerful, general purpose programming language that has become THE language to learn if one wants to get into the world of data science. 

This is due to several reasons:

* Python is beginner friendly. It promotes clean and readable code so beginners can not only learn quickly but read code quickly as well due to its easy-to-understand syntax. Even software like Jupyter Notebook gives immediate feedback on your code so when you run it, the output is shown instantly. And if you have any problems in your code, Jupyter Notebook will even tell you where the error is.
* There are also a wide variety of libraries to choose from. This is due to the reason above; having an easy-to-learn language promotes a faster learning curve, which leads to having a greater number of Python experts quicker and therefore, having greater potential to have more libraries. And the more Python libraries, the more methods one has access to and therefore, leads to an easier time when coding.
* These reasons are all supported by the fact that Python has a great community behind it. Any question can be answered by a quick search of your problem on Google with the keyword “Python” at the end of your query. Any difficulty you may have as a beginner has most probably been well-documented and answered online.

A bit more including why its better than excel in a few examples: [https://xccelerate.co/blog/use-python-for-data-science](https://xccelerate.co/blog/use-python-for-data-science)","learndatascience",99,0
